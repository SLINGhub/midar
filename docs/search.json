[{"path":[]},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement Singapore Lipidomics Incubator. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://slinghub.github.io/midar/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://slinghub.github.io/midar/articles/00_get_started.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Getting Started with MiDAR","text":"MiDAR requires R version 4.2.0 higher, available CRAN. Using R IDE RStudio, Positron, Visual Studio Code also recommended. MiDAR’s core functionality requires R coding skills, basic familiarity R IDE needed. New R? Try online tutorials opinionated tour RStudio RStudio User Guide. Additionally, colleague familiar RStudio can helpful get started smoothly stay motivated.","code":""},{"path":"https://slinghub.github.io/midar/articles/00_get_started.html","id":"installing-midar","dir":"Articles","previous_headings":"","what":"Installing MiDAR","title":"Getting Started with MiDAR","text":"install, update, MiDAR, run following code R console:","code":"if (!require(\"pak\")) install.packages(\"pak\") pak::pkg_install(\"SLINGhub/midar\")"},{"path":"https://slinghub.github.io/midar/articles/00_get_started.html","id":"learning-midar","dir":"Articles","previous_headings":"","what":"Learning MiDAR","title":"Getting Started with MiDAR","text":"new MiDAR, please explore tutorials available via top menu bar. resources help become familiar package’s concepts functionalities. particular, tutorials Preparing importing data basic MiDAR workflow offer essential information get started smoothly. MiDAR functions, particularly plotting, many arguments allow detailed customizations. get started, use default settings (.e., without defining ), adjust suit needs. Use ?functionname search [References(reference/index.html) page detailed descriptions, check ‘Manual’ section tips tricks. common error omitting required arguments. unclear errors occur, consult Help ensure correct arguments data types. Robustness improve future package versions.","code":""},{"path":"https://slinghub.github.io/midar/articles/00_get_started.html","id":"midar-recipes","dir":"Articles","previous_headings":"","what":"MiDAR Recipes","title":"Getting Started with MiDAR","text":"build data processing workflows, ‘Recipes’ provide good starting point. Choose one recipes match application, copy-paste R script/notebook, start adapt specific data process. recipes also introduce function names argument options may typically used recipes’ context. detailed information, refer ‘Manual’ section details data structures use MiDAR functions, ‘Reference’ section comprehensive documentation functions, arguments, data classes, test datasets.","code":""},{"path":"https://slinghub.github.io/midar/articles/00_get_started.html","id":"support","dir":"Articles","previous_headings":"","what":"Support","title":"Getting Started with MiDAR","text":"happy help. Feel free contact authors directly via Github repository questions, suggestions, issues. interested contributing package, feel free contact us.","code":""},{"path":"https://slinghub.github.io/midar/articles/01_datastructure.html","id":"midarexperiment","dir":"Articles","previous_headings":"","what":"MidarExperiment","title":"Data and Metadata in MiDAR","text":"MidarExperiment object primary data container MiDAR workflow. holds experimental processed data metadata, well details applied processing steps current status data. MiDAR functions take MidarExperiment object data input. Functions process data return updated MidarExperiment object, can used subsequent steps. Data within MidarExperiment organized data metadata categories, divided tables (data.frames).","code":""},{"path":[]},{"path":[]},{"path":"https://slinghub.github.io/midar/articles/02_keydataids.html","id":"key-data-identifiers","dir":"Articles","previous_headings":"","what":"Key Data Identifiers","title":"Data Identifiers in MiDAR","text":"following key data fields essential organizing data MiDAR. data key fields used organizing data within MidarExperiment object functions MiDAR package employ fields. Certain field names differ conventional terminology (e.g., analysis_id instead  sample_id) allow flexible workflows reduce confusion identifiers. sample may measured multiple times across different methods processing replicates, necessitating distinct identifiers. Similarly, analytes can quantified multiple transitions adducts,  feature_id designated primary identifier.","code":""},{"path":"https://slinghub.github.io/midar/articles/02_keydataids.html","id":"qc-types-sample-types","dir":"Articles","previous_headings":"","what":"QC types (Sample Types)","title":"Data Identifiers in MiDAR","text":"QC types categorize samples based analytical purpose utilized throughout various functions MiDAR package. classification system combines nomenclature multiple sources: several standardized terms (SPL, BQC, TQC, LTR, RQC) introduced Broadhurst et al. (2018) “Guidelines considerations use system suitability quality control samples mass spectrometry assays,” others (LQC, MQC, HQC, CAL, NIST, SST, various blank types) derive traditional terminology analytical clinical chemistry. integration nomenclature systems provides comprehensive framework quality control analytical workflows. QC type represented consistent color scheme (fill line colors) specific point shapes plots generated MiDAR package. visual coding allows consistent identification comparison different QC types across various visualizations.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/articles/02b_keyfeaturevar.html","id":"key-feature-variables","dir":"Articles","previous_headings":"","what":"Key Feature Variables","title":"Feature Variables in MiDAR","text":"Following feature variables essential organizing data processing flow MiDAR. intensity variable corresponds raw signal (e.g. peak area) analysis, retrieved one original feature variables (see ) feature variables downstream result data processing, including available MiDAR workflow. raw, partial fully post-processed data imported MiDAR, e.g. via import_data_csv(), imported values must assigned match variables names. Many data processing plotting functions MiDAR use variables input variable. variable stored dataset table present MidarExperiment object.","code":""},{"path":"https://slinghub.github.io/midar/articles/02b_keyfeaturevar.html","id":"backup-feature-variables","dir":"Articles","previous_headings":"","what":"Backup Feature Variables","title":"Feature Variables in MiDAR","text":"Feature variables overwritten processing re-calculated values, .e., feature area interference correction, concentrations drift/batch correction reference sample-based re-calibration. cases, original feature values stored new ‘backup’ feature variable keep record allow exploring variable later stage. Furthermore, specific variables created processing functions, e.g. drift correction values curve (model fit) data points. Also variables stored dataset table. feature variable name based initial name following postfixes: f eature_conc_raw featur e_intensity_raw feat ure_conc_before feature_i ntensity_before","code":""},{"path":"https://slinghub.github.io/midar/articles/02b_keyfeaturevar.html","id":"raw-feature-variables","dir":"Articles","previous_headings":"","what":"Raw Feature Variables","title":"Feature Variables in MiDAR","text":"supported feature variables listed characterize features additional aspects. Import variables can used “feature raw intensity” data processing steps. variable copied intensity importing data, default area available, height, response intensity order. feature variable use intensity can also manually set via `set_intensity_var()` variables stored dataset_orig table, modified MiDAR function. typically available MiDAR’s data processing functions, plotting functions support . support extended upcoming versions. QC type represented consistent color scheme (fill line colors) specific point shapes plots generated MiDAR package. visual coding allows consistent identification comparison different QC types across various visualizations.","code":""},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"The `MidarExperiment` data object","text":"MidarExperiment object main data container used MiDAR workflow, see also Data Metadata MiDAR. holds experimental processed data metadata, well details. MidarExperiment S4 object following slots:","code":"MidarExperiment   ├─title:  chr \"My LCMS Assay\"   ├─analysis_type:  chr NA   ├─feature_intensity_var:  chr \"feature_area\"   ├─dataset_orig: tibble [400 × 26] (S3: tbl_df/tbl/data.frame)   ├─dataset: tibble [400 × 26] (S3: tbl_df/tbl/data.frame)   ├─dataset_filtered: tibble [0 × 14] (S3: tbl_df/tbl/data.frame)   ├─annot_analyses: tibble [25 × 13] (S3: tbl_df/tbl/data.frame)   ├─annot_features: tibble [16 × 16] (S3: tbl_df/tbl/data.frame)   ├─annot_istds: tibble [8 × 4] (S3: tbl_df/tbl/data.frame)   ├─annot_responsecurves: tibble [0 × 3] (S3: tbl_df/tbl/data.frame)   ├─annot_qcconcentrations: tibble [32 × 5] (S3: tbl_df/tbl/data.frame)   ├─annot_studysamples: tibble [0 × 0] (S3: tbl_df/tbl/data.frame)   ├─annot_batches: tibble [1 × 4] (S3: tbl_df/tbl/data.frame)   ├─metrics_qc: tibble [0 × 0] (S3: tbl_df/tbl/data.frame)   ├─metrics_calibration: tibble [4 × 15] (S3: tbl_df/tbl/data.frame)   ├─parameters_processing: tibble [0 × 1] (S3: tbl_df/tbl/data.frame)   ├─status_processing:  chr \"Calibration-quantitated data\"   ├─is_istd_normalized:  logi TRUE   ├─is_quantitated:  logi TRUE   ├─is_filtered:  logi FALSE   ├─has_outliers_tech:  logi FALSE\\   ├─is_isotope_corr:  logi FALSE   ├─analyses_excluded:  logi NA   ├─features_excluded:  logi NA   ├─var_drift_corrected:  Named logi [1:3] FALSE FALSE FALSE   ├─var_batch_corrected:  Named logi [1:3] FALSE FALSE FALSE"},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"creating-a-midarexperiment-object","dir":"Articles","previous_headings":"Overview","what":"Creating a MidarExperiment object","title":"The `MidarExperiment` data object","text":"","code":"library(midar) myexp <- MidarExperiment()"},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"using-midarexperiment-objects","dir":"Articles","previous_headings":"Overview","what":"Using MidarExperiment objects","title":"The `MidarExperiment` data object","text":"MiDAR functions take MidarExperiment object input. Data processing functions return modified MidarExperiment, can subsequent step. R pipes can also used, allowing chain multiple functions together. can clearly indicate processing workflow make code easier read.","code":"myexp <- MidarExperiment() myexp <- data_load_example(myexp, 1) myexp <- normalize_by_istd(myexp) #> ! Interfering features defined in metadata, but no correction was applied. Use `correct_interferences()` to correct. #> ✔ 20 features normalized with 9 ISTDs in 499 analyses.  save_dataset_csv(myexp, \"mydata.csv\", \"norm_intensity\", FALSE) #> ✔ Norm_intensity values for 499 analyses and 20 features have been exported to 'mydata.csv'. myexp |>    MidarExperiment() |>   data_load_example(1) |>   normalize_by_istd() |>   save_dataset_csv(\"mydata.csv\", \"norm_intensity\", FALSE) #> ! Interfering features defined in metadata, but no correction was applied. Use `correct_interferences()` to correct. #> ✔ 20 features normalized with 9 ISTDs in 499 analyses. #> ✔ Norm_intensity values for 499 analyses and 20 features have been exported to 'mydata.csv'."},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"multiple-midarexperiment-objects","dir":"Articles","previous_headings":"Overview","what":"Multiple MidarExperiment objects","title":"The `MidarExperiment` data object","text":"Multiple MidarExperiment objects can created processed independently within script.","code":"m_polars <- MidarExperiment(title = \"Polar metabolites\") m_lipids <- MidarExperiment(title = \"Non-polar metabolites\")"},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"accessing-data-and-metadata","dir":"Articles","previous_headings":"Overview","what":"Accessing data and metadata","title":"The `MidarExperiment` data object","text":"Functions starting data_get_ allow retrieve data metadat MidarExperiment object. Alternatively, $ syntax can used access data metadata tables MidarExperiment objects.","code":"myexp <- data_load_example(myexp, 1) dataset <- get_analyticaldata(myexp, annotated = TRUE)  print(dataset) #> # A tibble: 14,471 × 19 #>    analysis_order analysis_id  acquisition_time_stamp qc_type batch_id sample_id #>             <int> <chr>        <dttm>                 <chr>   <chr>    <chr>     #>  1              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  2              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  3              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  4              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  5              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  6              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  7              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  8              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #>  9              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #> 10              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        Longit_B… #> # ℹ 14,461 more rows #> # ℹ 13 more variables: replicate_no <int>, specimen <chr>, feature_id <chr>, #> #   feature_class <chr>, feature_label <chr>, is_istd <lgl>, #> #   is_quantifier <lgl>, analyte_id <chr>, feature_rt <dbl>, #> #   feature_area <dbl>, feature_height <dbl>, feature_fwhm <dbl>, #> #   feature_intensity <dbl> analyses <- myexp$annot_analyses features <- myexp$annot_features   print(features) #> # A tibble: 29 × 16 #>    feature_id              feature_class analyte_id is_istd istd_feature_id      #>    <chr>                   <chr>         <chr>      <lgl>   <chr>                #>  1 CE 18:1                 CE            NA         FALSE   CE 18:1 d7 (ISTD)    #>  2 CE 18:1 d7 (ISTD)       CE            NA         TRUE    CE 18:1 d7 (ISTD)    #>  3 Cer d18:1/16:0          Cer 18:1;O2   NA         FALSE   Cer d18:1/25:0 (IST… #>  4 Cer d18:1/24:0          Cer 18:1;O2   NA         FALSE   Cer d18:1/25:0 (IST… #>  5 Cer d18:1/25:0 (ISTD)   Cer 18:1;O2   NA         TRUE    Cer d18:1/25:0 (IST… #>  6 LPC 18:1 (a)            LPC           NA         FALSE   LPC 18:1 (ab) d7 (I… #>  7 LPC 18:1 (ab) d7 (ISTD) LPC           NA         TRUE    LPC 18:1 (ab) d7 (I… #>  8 LPC 18:1 (b)            LPC           NA         FALSE   LPC 18:1 (ab) d7 (I… #>  9 PC 28:0|SM 32:1 M+3     PC            NA         FALSE   PC 33:1 d7 (ISTD)    #> 10 PC 32:1                 PC            NA         FALSE   PC 33:1 d7 (ISTD)    #> # ℹ 19 more rows #> # ℹ 11 more variables: quant_istd_feature_id <chr>, is_quantifier <lgl>, #> #   valid_feature <lgl>, response_factor <dbl>, interference_feature_id <chr>, #> #   interference_contribution <dbl>, curve_fit_model <chr>, #> #   fit_weighting <chr>, remarks <chr>, feature_label <chr>, #> #   curve_fit_weighting <chr>"},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"saving-and-reading-midarexperiment-objects","dir":"Articles","previous_headings":"Overview","what":"Saving and Reading MidarExperiment objects","title":"The `MidarExperiment` data object","text":"","code":"myexp <- MidarExperiment() myexp <- data_load_example(myexp, 1) saveRDS(myexp, file = \"myexp-midar.rds\", compress = TRUE) my_saved_exp <- readRDS(file = \"myexp-midar.rds\")"},{"path":"https://slinghub.github.io/midar/articles/03_midarexperiment.html","id":"status-of-an-midarexperiment","dir":"Articles","previous_headings":"Overview","what":"Status of an MidarExperiment","title":"The `MidarExperiment` data object","text":"detailed summary dataset processing status can printed time","code":"print(my_saved_exp)"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"data-sources","dir":"Articles","previous_headings":"","what":"Data Sources","title":"Importing analytical data","text":"Following formats currently supported:","code":""},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"metadata-within-analytical-results","dir":"Articles","previous_headings":"","what":"Metadata within analytical results","title":"Importing analytical data","text":"analytical results contain metadata, sample feature annotations, can imported metadata MidarExperiment object well. imported metadata checked integrity consistency (see TODO) added annotation tables within MidarExperiment. include available metadata, set argument import_metadata = TRUE.","code":""},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"mrmkit","dir":"Articles","previous_headings":"","what":"MRMkit","title":"Importing analytical data","text":"Output files MRMkit, open-source peak integration software MRM data () can imported directly. Specific metadata present data file can imported well (`import_metadata = TRUE`)","code":"library(midar) filepath <- system.file(\"extdata/MRMkit_demo.tsv\", package = \"midar\") myexp <- MidarExperiment()  myexp <- import_data_mrmkit(myexp, filepath, import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"agilent-masshunter-quantitative","dir":"Articles","previous_headings":"","what":"Agilent MassHunter Quantitative","title":"Importing analytical data","text":"Peak integration results exported Agilent Masshunter Quant CSV format can imported. Samples must present rows, features columns. Import qualifier results supported. Sample, method result metadata present files can also imported (`import_metadata = TRUE`)","code":"filepath <- system.file(\"extdata/MHQuant_demo.csv\", package = \"midar\") myexp <- MidarExperiment()  myexp <- import_data_masshunter(myexp, filepath, import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"skyline-molecule-transition-results","dir":"Articles","previous_headings":"","what":"Skyline Molecule Transition Results","title":"Importing analytical data","text":"Small molecule peak integration results Skyline can imported using long-format CSV reports. uniquely define feature_ids, CSV file must include Molecule Name along either corresponding precursor product m/z values, names. analysis_id mapped Replicate Name column, must also present CSV file. import process, unique feature_ids generated appending either precursor/product names m/z values  Molecule Name, unless Molecule Name alone uniquely identifies features. behavior controlled  transition_id_columns argument described . Sample, method, result metadata present files can also imported setting import_metadata = TRUE. details, refer documentation import_data_skyline() function. export results Skyline: Navigate “File” > “Export” select ‘Molecule Transition Results’ format. Ensure export includes Replicate Name, Molecule Name, either Precursor Mz Product Mz, Precursor Name Product Name. Also, export least one feature variable like Area Retention Time (RT).","code":"filepath <- system.file(\"extdata/Skyline_MoleculeTransitionResults.csv\", package = \"midar\") myexp <- MidarExperiment()  myexp <- import_data_skyline(myexp,                               filepath,                               import_metadata = TRUE,                               transition_id_columns = \"mz\" )"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"generic-wide-format-csv-files","dir":"Articles","previous_headings":"","what":"Generic Wide-Format CSV files","title":"Importing analytical data","text":"Analysis results, whether raw intensities (e.g., peak areas) preprocessed data (e.g., concentrations), can provided plain wide-format CSV tables. tables, analyses (samples) arranged rows, features columns. specific data type table (e.g., area concentration) defined using variable_name argument.","code":"filepath <- system.file(\"extdata/plain_wide_dataset.csv\", package = \"midar\") myexp <- MidarExperiment()  myexp <- midar::import_data_csv_wide(   myexp,    path = filepath,   variable_name = \"area\",    import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"generic-long-format-csv-files","dir":"Articles","previous_headings":"","what":"Generic Long-Format CSV Files","title":"Importing analytical data","text":"Analysis results containing various feature variables (e.g., peak areas, retention times) can provided generic long-format CSV tables. format, row represents unique observation feature-value pair given sample, additional columns capture feature variables well sample- method-related metadata. long-format structure common export format supported many vendor open-source software tools targeted untargeted raw data processing. default, CSV file must include least following columns: analysis_id, feature_id, one feature variable column area. Additional metadata feature variable columns also supported — please refer documentation import_data_csv_long() details. CSV file uses different column names, can import specifying column name mapping. mapping associates MiDAR expected column names corresponding column names CSV file (refer MiDAR Manual details). column mapping defined named vector, names correspond MiDAR column names values correspond column names CSV.","code":"file_path <- system.file(\"extdata\", \"plain_long_dataset.csv\", package = \"midar\")   mexp <- MidarExperiment()  # Define a column mapping, right side is the column name in the CSV file col_map <- c(   \"analysis_id\" = \"raw_data_filename\",   \"qc_type\" = \"qc_type\",   \"feature_id\" = \"feature_id\",   \"feature_class\" = \"feature_class\",   \"istd_feature_id\" = \"istd_feature_id\",   \"qc_type\" = \"qc_type\",   \"feature_rt\" = \"rt\",   \"feature_area\" = \"area\")  # Import data  mexp <- import_data_csv_long(    data = mexp,    path = file_path,    column_mapping = col_map,    import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/04_dataimport.html","id":"multiple-files-import-and-merging","dir":"Articles","previous_headings":"","what":"Multiple files Import and Merging","title":"Importing analytical data","text":"Multiple data files can imported merged. Users can either provide list file paths specify folder path import data files within directory. support multiple files useful raw data processing divided batches, leading separate result files. imported merged data checked consistency, ensuring analysis ID feature ID pair unique. means feature reported multiple times within analysis, can happend example feature sample integrated different raw data processing batches.","code":""},{"path":"https://slinghub.github.io/midar/articles/05_metadataimport.html","id":"metadata","dir":"Articles","previous_headings":"","what":"Metadata","title":"Metadata import","text":"Metadata context refers analysis metadata, .e., data annotate analytical data. Metadata can retrieved imported analysis data file far available, can imported separate files R data frames. Integrity metadata data instrumental correct smooth post processing data. Midar therefore inspects imported data/metadata completness data consistency IDs used across differet metadata tables. importing metadata summary identified error, warnings notes cocerning metadata printed console, allow user identify adress possible issues.","code":""},{"path":"https://slinghub.github.io/midar/articles/05_metadataimport.html","id":"metadata-formats-and-temples","dir":"Articles","previous_headings":"","what":"Metadata formats and temples","title":"Metadata import","text":"structure required/optional columns metadata type descrived Manual help correspoding import functions. obtain templates metadata, Excel file containing template metadata table templates can saved.","code":"midar::save_metadata_templates()"},{"path":"https://slinghub.github.io/midar/articles/05_metadataimport.html","id":"importing-metadata-from-filessheets","dir":"Articles","previous_headings":"","what":"Importing metadata from files/sheets","title":"Metadata import","text":"First import analysis data outlined “Importing data”. case explicitly import metadata present analysis data, .e., import peak areas. Now can add corresponding metadata file--file Metadata can also imported sheets Excel workbook, allows store metadata one file. case add metadata internal standard response curves MidarExperiment object Furthermore, metadata can imported R data.frame objects, thus allowing users obtain metadata additional sources, e.g. databases LIMS.","code":"library(midar) mexp <- midar::MidarExperiment()  data_path <- \"datasets/sPerfect_MRMkit.tsv\" mexp <- import_data_mrmkit(data = mexp, path = data_path, import_metadata = TRUE) mexp <- import_metadata_analyses(mexp,                                   path = \"datasets/analysis_metadata.csv\",                                   excl_unmatched_analyses = TRUE,                                   ignore_warnings = TRUE)  mexp <- import_metadata_features(mexp,                                   path = \"datasets/feature_metadata.csv\",                                  ignore_warnings= TRUE ) mexp <- import_metadata_istds(mexp,                                path = \"datasets/metadata_tables.xlsx\",                                sheet = \"ISTDs\",                               ignore_warnings= TRUE) df_qcinfo <- readr::read_table(file = \"datasets/qc_metadata.txt\") mexp <- import_metadata_qcconcentrations(mexp, table = df_qcinfo)"},{"path":"https://slinghub.github.io/midar/articles/05_metadataimport.html","id":"importing-msorganiser-metedata-file-template","dir":"Articles","previous_headings":"","what":"Importing MSOrganiser metedata file template","title":"Metadata import","text":"Another option import metadata via MSOrganiser template file, macro-based (XLSM) Excel file. template offers tables metadata types supported MiDAR, options perform checks validatiy integrity metadata. template can obtained https://github.com/SLINGhub/midar via midar function metadata tables required intended processing workflow need completed. following import function completed tables imported.","code":"midar::save_metadata_msorganiser_template() mexp <- import_metadata_msorganiser(mexp,                                      path = \"datasets/sPerfect_Metadata.xlsm\",                                     ignore_warnings= TRUE)"},{"path":[]},{"path":"https://slinghub.github.io/midar/articles/07_driftbatchcorr.html","id":"drift-correction-smoothing","dir":"Articles","previous_headings":"","what":"Drift correction (smoothing)","title":"Drift and Batch Correction","text":"Following drift correction method available MiDAR, two typically used QC samples one (gaussian kernel-based) study samples. Corrections can applied batch--batch basis (batch_wise = TRUE, default) across batches (batch_wise = FALSE). correction can either replace existing drift batch corrections (⁠replace_previous = ⁠TRUE⁠, default) applied top existing corrections (`⁠replace_previous = FALSE’). Drift correction can applied features (conditional_correction = FALSE) conditionally, based whether sample CV difference correction defined threshold (cv_diff_threshold). conditional correction applied separately batch batch_wise = TRUE. recommended visually inspect correction using plot_runscatter() function. Set argument recalc_trend_after = TRUE trends correction also available plotting. details, refer description plot_runscatter(). , however, doubles processing time. Note: function outputs message indicating median CV change mean absolute CV correction samples. However, metrics experimental used definitive criteria correction (see function documentation). Gaussian kernel smoothing fixed kernel size features. Option smooth scale (variability) well. Typically used study samples reference. suitable large sample numbers well-randomized/stratified. cubic spline smoothing approach, particularly used regularization parameter lambda, similar identical previously described QC-based drift correction methods, QC-RSC (Quality Control Regularized Spline Correction), described Dunn et al. (2011) Kirwan et al. (2013). See tutorial Drift Batch Correction information use functions plot results.","code":""},{"path":"https://slinghub.github.io/midar/articles/07_driftbatchcorr.html","id":"batch-effect-correction-centering","dir":"Articles","previous_headings":"","what":"Batch-effect correction (centering)","title":"Drift and Batch Correction","text":"MiDAR currently supports median centering-based batch correction correct_batch_centering()\\, whereby scale batches can optioanally also normalized. selected QC types (ref_qc_types) used calculate medians, used align samples. See tutorial Drift Batch Correction information.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/articles/T01_prepdata.html","id":"analytical-data","dir":"Articles","previous_headings":"","what":"Analytical Data","title":"Preparing and importing data","text":"Analytical data, preprocessed measurement data (e.g., peak areas), can imported various software platforms. MiDAR currently supports data import MRMkit, Agilent MassHunter Quantitative Analysis (CSV files), MRMkit, generic CSV files. importing data files generated platforms, important manually edit files importing. Manual edits can lead file corruption accidental errors data. MiDAR emphasizes reproducible automated workflows, manual editing data discouraged. importing data files generated supported platforms, important manually edit files importing MiDAR. can easily lead corrupt files imported, accidential errors data. MiDAR emphasis reproducible/automated workflows, thus manual editing data approach. Two examples import data MRMkit plain CSV table peak areas: See Importing analytical data details importing analysis data.","code":"library(midar) # Add analysis data from file generated by MRMkit mexp <- MidarExperiment() mexp <- import_data_mrmkit(mexp,                             path = \"datasets/sPerfect_MRMkit.tsv\",                             import_metadata = TRUE)  # Add analysis data from a CSV file (replaces all previous data) mexp2 <- MidarExperiment() mexp2 <- import_data_csv(mexp,                          path = \"data/plain_wide_dataset.csv\",                          variable_name = \"area\",                         import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T01_prepdata.html","id":"metadata","dir":"Articles","previous_headings":"","what":"Metadata","title":"Preparing and importing data","text":"Metadata, refering analysis metadata, .e., data describe/annotates analytical data analysis/sample feature level, essential data MiDAR workflow. Metadata can retrieved imported analysis data file far available. commonly, additional required metadata needs important sources. metadata tables required depends intended processing workflow, see Data Metadata MiDAR overview metadata categories. Integrity metadata data key accurate reproducible data processing. MiDAR therefore inspects imported data/metadata completeness data consistency IDs used across different metadata tables. summary identified error, warnings notes concerning metadata provided import.","code":""},{"path":"https://slinghub.github.io/midar/articles/T01_prepdata.html","id":"preparing-metadata","dir":"Articles","previous_headings":"Metadata","what":"Preparing metadata","title":"Preparing and importing data","text":"Metadata can imported Excel Sheets, CSV files, R data frames. Furthermore, specific metadata template file can used prepare metadata structured way. Preparation metadata often manual step, information collected various sources. facilitate process, MiDAR provides metadata templates Excel format. templates contain column headers instructions use. beginning, recommended start metadata template fill required information. Templates metadata types supported MiDAR can obtained via:","code":"midar::save_metadata_templates()"},{"path":"https://slinghub.github.io/midar/articles/T01_prepdata.html","id":"importing-metadata","dir":"Articles","previous_headings":"Metadata","what":"Importing metadata","title":"Preparing and importing data","text":"Specific metadata can imported table table, CSV files: Metadata can also obtained Excel workbook sheets, allows store metadata one file. case add metadata internal standard response curves MidarExperiment object Lastly, metadata can obtained directly R data.frame objects, allowing users prepare metadata R obtain , e.g., databases LIMS. import metadata quality control samples:","code":"mexp <- import_metadata_analyses(mexp,                                   path = \"datasets/analysis_metadata.csv\",                                   excl_unmatched_analyses = TRUE,                                   ignore_warnings = TRUE)  mexp <- import_metadata_features(mexp,                                   path = \"datasets/feature_metadata.csv\",                                  ignore_warnings= TRUE ) mexp <- import_metadata_istds(mexp,                                path = \"datasets/metadata_tables.xlsx\",                                sheet = \"ISTDs\",                               ignore_warnings= TRUE) df_qcinfo <- readr::read_table(file = \"datasets/qc_metadata.txt\") mexp <- import_metadata_qcconcentrations(mexp, table = df_qcinfo)"},{"path":"https://slinghub.github.io/midar/articles/T01_prepdata.html","id":"preparing-and-importing-metadata-using-the-msorganiser-file-template","dir":"Articles","previous_headings":"","what":"Preparing and Importing metadata using the MSOrganiser file template","title":"Preparing and importing data","text":"Another option import metadata via ‘MiDAR MSOrganzier’ template, macro-enabled Excel file. See Metadata import.","code":""},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"importing-analysis-results","dir":"Articles","previous_headings":"","what":"1. Importing analysis results","title":"Lipidomics Data Processing","text":"begin importing MRMkit result file, contains areas integrated peaks (features) processed raw data files. addition, MRMkit result file also contains peak retention times widths, well metadata extracted mzML files, acquisition time stamp m/z values. import metadata setting import_metadata = TRUE. Type print(myexp) console get summary status. can explore myexp object RStudio clicking Environment panel top right.","code":"myexp <- midar::MidarExperiment(title = \"sPerfect\")  data_path <- \"datasets/sPerfect_MRMkit.tsv\" myexp <- import_data_mrmkit(data = myexp, path = data_path, import_metadata = TRUE) #> ✔ Imported 499 analyses with 503 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 503 features."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"a-glimpse-on-the-imported-data","dir":"Articles","previous_headings":"","what":"2. A glimpse on the imported data","title":"Lipidomics Data Processing","text":"Let us examine imported data executing code entering command View(myexp@dataset_orig) console. can observed, data long format, thereby enabling user view multiple parameters analysis-feature pair. Explore imported table using RStudio table viewer filter functionality.","code":"print(myexp@dataset) # Better use `get_rawdata(mexp, \"original\")` #> # A tibble: 250,997 × 20 #>    analysis_order analysis_id  acquisition_time_stamp qc_type batch_id sample_id #>             <int> <chr>        <dttm>                 <chr>   <chr>    <chr>     #>  1              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  2              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  3              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  4              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  5              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  6              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  7              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  8              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #>  9              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #> 10              1 Longit_BLAN… 2017-10-20 14:15:36    SBLK    1        NA        #> # ℹ 250,987 more rows #> # ℹ 14 more variables: replicate_no <int>, specimen <chr>, feature_id <chr>, #> #   feature_class <chr>, feature_label <chr>, is_istd <lgl>, #> #   is_quantifier <lgl>, analyte_id <chr>, feature_rt <dbl>, #> #   feature_area <dbl>, feature_height <dbl>, feature_fwhm <dbl>, #> #   feature_width <dbl>, feature_intensity <dbl>"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"analytical-design-and-timeline","dir":"Articles","previous_headings":"","what":"3. Analytical design and timeline","title":"Lipidomics Data Processing","text":"overview analysis design timelines can provide useful information subsequent processing steps. plot illustrates batch structure, quality control (QC) samples included respective positions, additional information regarding date, duration, run time analysis. Show analysis timestamps show_timestamp = TRUE. long interruptions within batches?","code":"plot_runsequence(   myexp,    qc_types = NA,    show_batches = TRUE,    batch_zebra_stripe = TRUE,    batch_fill_color = \"#fffbdb\",    segment_linewidth = 0.5,   show_timestamp = FALSE)"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"signal-trends-of-internal-standards","dir":"Articles","previous_headings":"","what":"4. Signal trends of Internal Standards","title":"Lipidomics Data Processing","text":"can look internal standards (ISTDs) samples across six batches see analyses went. ISTD amount spiked sample (except SBLK) expect intensities samples sample types. observe? can set output_pdf = TRUE save plots PDF (see subfolder output).","code":"plot_runscatter(   data = myexp,   variable = \"intensity\",   qc_types = c(\"BQC\", \"TQC\", \"SPL\", \"PBLK\", \"SBLK\"),   #analysis_range = NA, #get_batch_boundaries(myexp, c(1,6)),    include_feature_filter = \"ISTD\",    exclude_feature_filter = \"Hex|282\",   cap_outliers = TRUE,   log_scale = FALSE,    show_batches = TRUE,base_font_size = 5,   output_pdf = FALSE,   path = \"./output/runscatter_istd.pdf\",   cols_page = 4, rows_page = 3 ) #> Generating plots (3 pages)... #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"adding-detailed-metadata","dir":"Articles","previous_headings":"","what":"5. Adding detailed metadata","title":"Lipidomics Data Processing","text":"proceed processing, require additional metadata describing samples features. MiDAR Excel template provides solution collection, organisation pre-validation analysis metadata. Import metadata template using function . errors metadata (e.g. duplicate missing ID), import fail error message summary errors. metadata error-free, summary warnings notes metadata shown table, present. Check metadata working warnings, proceed using ignore_warnings = TRUE. Open XLSM file data folder explore metadata structure (click ‘Disable Macros’).","code":"file_path <- \"datasets/sPerfect_Metadata.xlsm\" myexp <- import_metadata_msorganiser(myexp, path = file_path, ignore_warnings = TRUE) #> ! Metadata has following warnings and notifications: #> -------------------------------------------------------------------------------------------- #>   Type Table    Column                Issue                           Count #> 1 W*   Analyses analysis_id           Analyses not in analysis data      15 #> 2 W*   Features feature_id            Feature(s) not in analysis data     4 #> 3 W*   Features feature_id            Feature(s) without metadata         1 #> 4 W*   ISTDs    quant_istd_feature_id Internal standard(s) not used       1 #> -------------------------------------------------------------------------------------------- #> E = Error, W = Warning, W* = Supressed Warning, N = Note #> -------------------------------------------------------------------------------------------- #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 502 features. #> ✔ Internal Standard metadata associated with 17 ISTDs. #> ✔ Response curve metadata associated with 12 annotated analyses. myexp <- set_analysis_order(myexp, order_by = \"timestamp\") #> ✔ Analysis order set to \"timestamp\" myexp <- set_intensity_var(myexp, variable_name = \"area\") #> ✔ Default feature intensity variable set to \"feature_area\""},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"overall-trends-and-possible-outlier","dir":"Articles","previous_headings":"","what":"6. Overall trends and possible outlier","title":"Lipidomics Data Processing","text":"examine overall technical trends issues affecting majority analytes (features), RLA (Relative Log Abundance) plot useful tool (De Livera et al., Analytical Chemistry, 2015). plot, features normalised (across within-batch medians) plotted boxplot per sample. plot can help identify potential pipetting errors, sample spillage, injection volume changes instrument sensitivity changes. First, run code . observations can made? , examine batch 6, uncommenting line #plot_range_indices =. see batch? Identify potential outlier sample setting x_axis_variable = \"analysis_id\". Next, set y-axis limits manually y_lim = c(-2,2) display analyses/batches inspect data trends fluctuations.","code":"midar::plot_rla_boxplot(   data = myexp,   rla_type_batch = c(\"within\"),   variable = \"intensity\",   qc_types = c(\"BQC\", \"SPL\", \"RQC\", \"TQC\", \"PBLK\"),    filter_data = FALSE,    #analysis_range = get_batch_boundaries(myexp, batch_indices = c(5,6)),    #y_lim = c(-3,3),   show_timestamp = FALSE,   ignore_outliers = FALSE, x_gridlines = FALSE,   batch_zebra_stripe = FALSE,   linewidth = 0.1 )"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"pca-plot-of-all-qc-types","dir":"Articles","previous_headings":"","what":"7. PCA plot of all QC types","title":"Lipidomics Data Processing","text":"principal component analysis (PCA) plot provides alternative method obtaining overview study quality control (QC) samples, well identifying potential issues, batch effects, technical outliers, differences sample types. Add blanks sample dilutions plot, including \"PBLK\", \"RQC\" qc_types = . think resulting PCA plot suggests now?","code":"plot_pca(   data = myexp,    variable = \"feature_intensity\",    filter_data = FALSE,   pca_dim = c(1,2),   labels_threshold_mad = 3,    qc_types = c(\"SPL\", \"BQC\", \"TQC\"),   log_transform = TRUE,     point_size = 2, point_alpha = 0.7, font_base_size = 8, ellipse_alpha = 0.3,    include_istd = FALSE) #> ! 2 features contained missing or non-numeric values and were exluded. #> ℹ The PCA was calculated based on `feature_intensity` values of 423 features."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"exclude-technical-outliers","dir":"Articles","previous_headings":"","what":"8. Exclude technical outliers","title":"Lipidomics Data Processing","text":"Based RLA PCA plots, flagged technical outlier decided remove downstream processing via function exclude(). now see new PCA plot? Explore also different PCA dimensions (modifying pca_dim).","code":"# Exclude the sample from the processing myexp <- exclude_analyses(myexp, analyses = c(\"Longit_batch6_51\"), clear_existing  = TRUE) #> ℹ 1 analyses were excluded for downstream processing. Please reprocess data.  # Replot the PCA plot_pca(   data = myexp,   variable = \"intensity\",   filter_data = FALSE,   pca_dim = c(1,2),   labels_threshold_mad = 3,   qc_types = c(\"SPL\", \"BQC\", \"TQC\"),   log_transform = TRUE,   point_size = 2, point_alpha = 0.7, font_base_size = 8, ellipse_alpha = 0.3,   include_istd = FALSE,   shared_labeltext_hide = NA) #> ! 2 features contained missing or non-numeric values and were exluded. #> ℹ The PCA was calculated based on `feature_intensity` values of 423 features."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"response-curves","dir":"Articles","previous_headings":"","what":"9. Response curves","title":"Lipidomics Data Processing","text":"linear response quantification prerequisite compared differences analyte concentrations samples. Given considerable dynamic range plasma lipid species abundances fact class-specific ISTD spiked single concentration, verifying linear response can valuable aspect analytical quality assessment. optimising injected sample amount primarily matter quality assurance (QA), differences instrument performance can affect dynamic range. Therefore, measured injection volume series start end analysis QC. Look response curves . see results? Change plotted lipid species modifying include_feature_filter (can use regular expressions). Save PDF lipids setting output_pdf = TRUE commenting (add # front ) include_feature_filter","code":"# Exclude very low abundant features myexp <- midar::filter_features_qc(myexp,                                     include_qualifier = FALSE,                                    include_istd = TRUE,                                    min.intensity.median.spl = 200) #> Calculating feature QC metrics - please wait... #> ✔ New feature QC filters were defined: 437 of 448 quantifier features meet QC criteria (including the 25 quantifier ISTD features).  #Plot the curves plot_responsecurves(   data = myexp,   variable = \"intensity\",   filter_data = TRUE,   include_feature_filter = \"^PC 3[0-5]\", # here we use regular expressions   output_pdf = FALSE, path = \"response-curves.pdf\",   cols_page = 5, rows_page = 4, ) #> Registered S3 methods overwritten by 'ggpp': #>   method                  from    #>   heightDetails.titleGrob ggplot2 #>   widthDetails.titleGrob  ggplot2 #> Generating plots (1 page): #>   |                                      |                              |   0% #>   |                                      |==============================| 100% #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"isotope-interference-correction","dir":"Articles","previous_headings":"","what":"10. Isotope interference correction","title":"Lipidomics Data Processing","text":"demonstrated course presentation, several instances peaks interest co-integrated interfering isotope peaks lipid species. intereferences can subtracted raw intensities (areas) using function, utilises information metadata. relative abundances interfering fragments obtained using LICAR (https://github.com/SLINGhub/LICAR). Check sheet “Features (Analytes)” metadata file (folder data). species affected? information need? correct M+3 isotope interference?","code":"myexp <- midar::correct_interferences(myexp) #> ! Interference correction led to negative or zero values in 2 feature(s) in samples/QCs. Please verify the correction, or set `neg_to_na = TRUE` #> ✔ Interference-correction has been applied to 10 of the 502 features."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"normalization-and-quantification-based-on-istds","dir":"Articles","previous_headings":"","what":"11. Normalization and quantification based on ISTDs","title":"Lipidomics Data Processing","text":"first step normalize lipid species corresponding internal standard (ISTD). Subsequently, concentrations calculated based volume spiked-ISTD solution, concentration ISTDs solution, sample volume. Visit metadata template view corresponding details. can also try re-run e.g. RLA PCA plots variable = \"norm_intensity\" variable = \"conc\" plot normalized data.","code":"myexp <- midar::normalize_by_istd(myexp) #> ✔ 460 features normalized with 17 ISTDs in 498 analyses. myexp <- midar::quantify_by_istd(myexp) #> ✔ 460 feature concentrations calculated based on 42 ISTDs and sample amounts of 498 analyses. #> ℹ Concentrations are given in μmol/L."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"examine-the-effects-of-class-wide-istd-normalization","dir":"Articles","previous_headings":"","what":"12. Examine the effects of class-wide ISTD normalization","title":"Lipidomics Data Processing","text":"use class-specific ISTDs common practice lipidomics. However, non-authentic internal standards may elute different times, can result subject different matrix effects thus different responses compared analytes. may also differ fragmentation properties, can also affect response. Consequently, use non-authentic ISTDs normalization can lead introduction artefacts, can manifest increases sample variability, rather expected reduction. therefore important assess ISTDs QA particular, also QC, consider using alternative ISTDs observing artefacts. One approach detecting potential ISTD-related artefacts compare variability QC samples normalization. expect comarisons CV? notice potential issues ISTDs ? possible explanations effect? situation?","code":"myexp <- midar::filter_features_qc(myexp,                                     include_qualifier = FALSE,                                    include_istd = TRUE,                                    min.intensity.median.spl = 1000) #> Calculating feature QC metrics - please wait... #> ✔ New feature QC filters were defined: 413 of 448 quantifier features meet QC criteria (including the 25 quantifier ISTD features). midar::plot_normalization_qc(   data = myexp,    filter_data = FALSE,    facet_by_class = TRUE,   qc_type = \"SPL\",    before_norm_var = \"intensity\",    after_norm_var = \"norm_intensity\")"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"drift-correction","dir":"Articles","previous_headings":"","what":"13. Drift correction","title":"Lipidomics Data Processing","text":"’re going use Gaussian kernel smoothing based study sample correct drifts concentration data within batch. summary return function isn’t meant actual diagnostics fit, rather understand fit caused major artefacts. also option scale along fit setting scale_smooth = TRUE. order demonstrate correction, plot example (PC 40:8) drift batch correction. using plot several occasions, create simple function wraps plot many parameters preset. Let’s use defined function plot trends one selected example within-batch smoothing. may caused drift raw concentrations? QC samples follow trend sample? Look also lipid species. Try changing batch_wise = FALSE code chunk correct_drift_gaussiankernel() run run smoothing across batches. valid alternative? NOTE: don’t forget change back batch_wise = TRUE test.","code":"myexp <- midar::correct_drift_gaussiankernel(   data = myexp,   ignore_istd = TRUE,   variable = \"conc\",   ref_qc_types = c(\"SPL\"),   batch_wise = TRUE,   replace_previous = TRUE,   recalc_trend_after = TRUE,   kernel_size = 10,   #conditional_correction =    outlier_filter = FALSE,   outlier_ksd = 5,   location_smooth = TRUE,   scale_smooth = FALSE,    show_progress = FALSE  # set to FALSE when rendering ) #> ℹ Applying `conc` drift correction... #> ℹ 4 feature(s) contain one or more zero or negative `conc` values. Verify your data or use `log_transform_internal = FALSE`. #>   |                                                    |                                            |   0%  |                                                    |=                                           |   2%  |                                                    |==                                          |   4%  |                                                    |===                                         |   6%  |                                                    |====                                        |   8%  |                                                    |====                                        |  10%  |                                                    |=====                                       |  12%  |                                                    |======                                      |  14%  |                                                    |=======                                     |  16%  |                                                    |========                                    |  18%  |                                                    |=========                                   |  20%  |                                                    |==========                                  |  22%  |                                                    |===========                                 |  24%  |                                                    |============                                |  26%  |                                                    |============                                |  28%  |                                                    |=============                               |  30%  |                                                    |==============                              |  32%  |                                                    |===============                             |  34%  |                                                    |================                            |  37%  |                                                    |=================                           |  39%  |                                                    |==================                          |  41%  |                                                    |===================                         |  43%  |                                                    |====================                        |  45%  |                                                    |=====================                       |  47%  |                                                    |=====================                       |  49%  |                                                    |======================                      |  51%  |                                                    |=======================                     |  53%  |                                                    |========================                    |  55%  |                                                    |=========================                   |  57%  |                                                    |==========================                  |  59%  |                                                    |===========================                 |  61%  |                                                    |============================                |  63%  |                                                    |=============================               |  65%  |                                                    |=============================               |  67%  |                                                    |==============================              |  69%  |                                                    |===============================             |  71%  |                                                    |================================            |  73%  |                                                    |=================================           |  75%  |                                                    |==================================          |  77%  |                                                    |===================================         |  79%  |                                                    |====================================        |  81%  |                                                    |=====================================       |  83%  |                                                    |=====================================       |  85%  |                                                    |======================================      |  87%  |                                                    |=======================================     |  89%  |                                                    |========================================    |  91%  |                                                    |=========================================   |  93%  |                                                    |==========================================  |  95%  |                                                    |=========================================== |  97%  |                                                    |============================================|  99%  |                                                    |============================================| 100% - trend smoothing done! #>   |                                                    |                                            |   0%  |                                                    |=                                           |   2%  |                                                    |==                                          |   4%  |                                                    |===                                         |   6%  |                                                    |====                                        |   8%  |                                                    |====                                        |  10%  |                                                    |=====                                       |  12%  |                                                    |======                                      |  14%  |                                                    |=======                                     |  16%  |                                                    |========                                    |  18%  |                                                    |=========                                   |  20%  |                                                    |==========                                  |  22%  |                                                    |===========                                 |  24%  |                                                    |============                                |  26%  |                                                    |============                                |  28%  |                                                    |=============                               |  30%  |                                                    |==============                              |  32%  |                                                    |===============                             |  34%  |                                                    |================                            |  37%  |                                                    |=================                           |  39%  |                                                    |==================                          |  41%  |                                                    |===================                         |  43%  |                                                    |====================                        |  45%  |                                                    |=====================                       |  47%  |                                                    |=====================                       |  49%  |                                                    |======================                      |  51%  |                                                    |=======================                     |  53%  |                                                    |========================                    |  55%  |                                                    |=========================                   |  57%  |                                                    |==========================                  |  59%  |                                                    |===========================                 |  61%  |                                                    |============================                |  63%  |                                                    |=============================               |  65%  |                                                    |=============================               |  67%  |                                                    |==============================              |  69%  |                                                    |===============================             |  71%  |                                                    |================================            |  73%  |                                                    |=================================           |  75%  |                                                    |==================================          |  77%  |                                                    |===================================         |  79%  |                                                    |====================================        |  81%  |                                                    |=====================================       |  83%  |                                                    |=====================================       |  85%  |                                                    |======================================      |  87%  |                                                    |=======================================     |  89%  |                                                    |========================================    |  91%  |                                                    |=========================================   |  93%  |                                                    |==========================================  |  95%  |                                                    |=========================================== |  97%  |                                                    |============================================|  99%  |                                                    |============================================| 100% - trend recalc done! #> ! 1 features showed no variation in the study sample's original values across analyses.  #> ! 1 features have invalid values after smoothing. NA will be be returned for all values of these faetures. Set `use_original_if_fail = FALSE to return orginal values.. #> ✔ Drift correction was applied to 459 of 460 features (batch-wise). #> ℹ The median CV change of all features in study samples was -1.00% (range: -12.53% to 2.59%). The median absolute CV of all features across batches decreased from 39.00% to 37.71%. # Define a wrapper function  my_trend_plot <- function(variable, feature){   plot_runscatter(     data = myexp,     variable = variable,     qc_types = c(\"BQC\", \"TQC\", \"SPL\"),     include_feature_filter = feature,     exclude_feature_filter = \"ISTD\",     cap_outliers = TRUE,     log_scale = FALSE,     show_trend = TRUE,     output_pdf = FALSE,     path = \"./output/runscatter_PC408_beforecorr.pdf\",     cols_page = 1, rows_page = 1,    ) } my_trend_plot(\"conc_before\", \"PC 40:8\") #> Generating plots (1 page)... #>  - done! my_trend_plot(\"conc\", \"PC 40:8\") #> Generating plots (1 page)... #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"batch-effect-correction","dir":"Articles","previous_headings":"","what":"14. Batch-effect correction","title":"Lipidomics Data Processing","text":"observed, trend lines different batches aligned. use correct_batcheffects() correct median center (location) scale differences batches. define correction based study samples medians. optional scale correction can performed setting correct_scale = FALSE. correction directly plot example lipid species . Change sample type qc_type = \"BQC\" use BQC center batches. observe?","code":"myexp <- midar::correct_batch_centering(   myexp,    variable = \"conc\",   ref_qc_types = \"SPL\",   replace_previous = TRUE,   correct_location = TRUE,    correct_scale = TRUE,    log_transform_internal = TRUE) #> ℹ Adding batch correction on top of `conc` drift-correction. #> ✔ Batch median-centering of 6 batches was applied to drift-corrected concentrations of all 460 features. #> ℹ The median CV change of all features in study samples was -0.29% (range: -31.80% to 69.10%).  The median absolute CV of all features increased from 39.12% to 39.44%.  my_trend_plot(\"conc\", \"PC 40:8\") #> Generating plots (1 page)... #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"saving-runscatter-plots-of-all-features-as-pdf","dir":"Articles","previous_headings":"","what":"15. Saving runscatter plots of all features as PDF","title":"Lipidomics Data Processing","text":"additional inspection documentation, can save plots selected subset species. often preferable exclude blanks, can exhibit random concentrations signals features internal standards close proximity limit detection. corresponding PDF can accessed within output subfolder. Use filt_ arguments include exclude specific analytes. filter can use regular expressions (regex). (Hint: try using ChatGPT generate complex regex-based filters). Explore effect setting cap_outliers TRUEor FALSE. Run ?runscatter console press F2 function name see available options plot_runscatter().","code":"plot_runscatter(   data = myexp,   variable = \"conc\",   qc_types = c(\"BQC\", \"TQC\", \"SPL\"),   include_feature_filter =  NA,   exclude_feature_filter = \"ISTD\",   cap_outliers = TRUE,   log_scale = FALSE,   show_trend = TRUE,   output_pdf = TRUE,   path = \"./output/runscatter_after-drift-batch-correction.pdf\",   cols_page = 2,    rows_page = 2,   show_progress = TRUE )"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"qc-based-feature-filtering","dir":"Articles","previous_headings":"","what":"16. QC-based feature filtering","title":"Lipidomics Data Processing","text":"Finally, apply set filters exclude features don’t meet specific QC criteria. available criteria can seen pressing TAB first open bracket filter_features_qc() function, viewing help page. running ?filter_features_qc console. filter function can applied multiple times, either overwriting amending (clear_existing = FALSE) previously set filters. Explore effects different filtering criteria filtering thresholds. plot section 17 can run order examine effects visually.","code":"myexp <- filter_features_qc(   data = myexp,    clear_existing = TRUE,   use_batch_medians = TRUE,   include_qualifier = FALSE,   include_istd = FALSE,   response.curves.selection = c(1,2),   response.curves.summary = \"mean\",   min.rsquare.response = 0.8,   min.slope.response = 0.75,   max.yintercept.response = 0.5,   min.signalblank.median.spl.pblk = 10,   min.intensity.median.spl = 100,   max.cv.conc.bqc = 25,   features.to.keep = c(\"CE 20:4\", \"CE 22:5\", \"CE 22:6\", \"CE 16:0\", \"CE 18:0\") ) #> Calculating feature QC metrics - please wait... #> ! The following features were forced to be retained despite not meeting filtering criteria: CE 16:0, CE 20:4, CE 22:5, and CE 22:6 #> ✔ New feature QC filters were defined: 324 of 423 quantifier features meet QC criteria (not including the 25 quantifier ISTD features)."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"summary-of-the-qc-filtering","dir":"Articles","previous_headings":"","what":"17. Summary of the QC filtering","title":"Lipidomics Data Processing","text":"plot provides overview data quality feature filtering. segments green indicate number species passed previously defined quality control (QC) filtering criteria. rest number species failed different filtering criteria. noted criteria hierarchically organised; feature classified failing criterion (e.g., CV) passed hierarchically lower filters (e.g., S/B LOD). differences lipid classes terms analytical performance? identified QC issues possible explanations ? implications want run next analysis?  following plot provides summary feature filtering process, indicating total number features successfully filtered. previously stated, classification based hierarchical application filters. Venn diagram right illustrates number features excluded particular filtering criterion. Take look Venn diagram. feature shows bad non-linear response (e.g. r2 < 0.8), reasons ?","code":"midar::plot_qc_summary_byclass(myexp) midar::plot_qc_summary_overall(myexp)"},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"saving-a-report-with-data-metadata-and-processing-details","dir":"Articles","previous_headings":"","what":"18. Saving a report with data, metadata and processing details","title":"Lipidomics Data Processing","text":"detailed summary data post-processing can generated form formatted Excel workbook comprising multiple sheets, containing raw processed datasets, associated metadata, feature quality control metrics, information applied processing steps. Explore report saved output folder. can also save specific data subsets clean flat, wide CSV file. shared data statistical analysis presented next part workshop! Specify data export using function arguments check generated CSV files.","code":"midar::save_report_xlsx(myexp, path = \"./output/myexp-midar_report.xlsx\") #> Saving report to disk - please wait... #> ✔ The data processing report of experiment 'sPerfect' has been saved to './output/myexp-midar_report.xlsx'. midar::save_dataset_csv(   data = myexp,    path = \"./output/sperfect_filt_uM.csv\",   variable = \"conc\",    qc_types = \"SPL\",    include_qualifier = FALSE,   filter_data = TRUE) #> ✔ Concentration values for 377 analyses and 324 features have been exported to './output/sperfect_filt_uM.csv'."},{"path":"https://slinghub.github.io/midar/articles/T01_targetlipidomics_workflow.html","id":"sharing-the-midarexperiment-dataset","dir":"Articles","previous_headings":"","what":"19. Sharing the MidarExperiment dataset","title":"Lipidomics Data Processing","text":"myexp object can saved RDS file shared. RDS files serialized R variables/objects can opened R anyone, even absence midar package. imported MidarExperiment object can also utilized re-processing, plotting, inspection using midar package. Save dataset disk re-open different name. Check status comparing dataset generated workflow (mexp)","code":"saveRDS(myexp, file = \"./output/myexp-midar.rds\", compress = TRUE) my_saved_exp <- readRDS(file = \"./output/myexp-midar.rds\") print(myexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: sPerfect #>  #> Processing status: Drift-Batch-corrected concentrations #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 498 #> • Features: 502 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✔ #> • Response curves: ✔ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✔ #> • ISTD normalized: ✔ #> • ISTD quantitated: ✔ #> • Drift corrected variables: `feature_conc` #> • Batch corrected variables: `feature_conc` #> • Feature filtering applied: ✔ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): Longit_batch6_51 #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"setting-up-a-rstudio-project","dir":"Articles","previous_headings":"","what":"Setting up a RStudio project","title":"A basic MiDAR workflow","text":"start new MiDAR data analysis, creating RStudio project recommended. (See Using RStudio Projects). help keep data analysis organized makes easier share others. project contain following subfolders: data output. Add data metadata files data folder. Notebooks R/Notebook (.rmd) Quarto Notebook (.qmd) good choices create documented data processing workflows. formats allow combining code formatted text document data processing steps. Start new notebook R script load midar package","code":"library(midar)"},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"creating-a-midarexperiment-object","dir":"Articles","previous_headings":"","what":"Creating a MidarExperiment object","title":"A basic MiDAR workflow","text":"MidarExperiment object main data container used MiDAR workflow. See (MidarExperiment data object)[articles/03_midarexperiment.html] information. start creating new MidarExperiment object (myexp), used subsequent steps.","code":"myexp <- MidarExperiment()"},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"importing-analysis-results","dir":"Articles","previous_headings":"","what":"Importing analysis results","title":"A basic MiDAR workflow","text":"introduced Preparing importing data first import analytical data, case MRMkit file. file also contains metadata, qc_type batch_id (see Data Identifiers MiDAR) import well.","code":"myexp <- import_data_mrmkit(data = myexp,                              path = \"datasets/sPerfect_MRMkit.tsv\",                              import_metadata = TRUE) #> ✔ Imported 499 analyses with 503 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 503 features."},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"adding-metadata","dir":"Articles","previous_headings":"","what":"Adding metadata","title":"A basic MiDAR workflow","text":"subsequent processing steps require additional infomation available imported analysis data. includes information internal standards used normalize, concentrations sample amounts analysed. metadata can imported separate files R data frames described Preparing importing data. keep code concience example, import metadata msorganiser template. validation checks result warnings, default result failed metadata import. However, assuming understand , decided ignore warnings setting ignore_warnings = TRUE. still shown table printed console, labelled asterix (*) status column.","code":"myexp <- import_metadata_msorganiser(   myexp,    path = \"datasets/sPerfect_Metadata.xlsm\",    ignore_warnings = TRUE ) #> ! Metadata has following warnings and notifications: #> -------------------------------------------------------------------------------------------- #>   Type Table    Column                Issue                           Count #> 1 W*   Analyses analysis_id           Analyses not in analysis data      15 #> 2 W*   Features feature_id            Feature(s) not in analysis data     4 #> 3 W*   Features feature_id            Feature(s) without metadata         1 #> 4 W*   ISTDs    quant_istd_feature_id Internal standard(s) not used       1 #> -------------------------------------------------------------------------------------------- #> E = Error, W = Warning, W* = Supressed Warning, N = Note #> -------------------------------------------------------------------------------------------- #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 502 features. #> ✔ Internal Standard metadata associated with 17 ISTDs. #> ✔ Response curve metadata associated with 12 annotated analyses."},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"applying-data-processing","dir":"Articles","previous_headings":"","what":"Applying Data Processing","title":"A basic MiDAR workflow","text":"Now ready proceed data processing. example employ basic data processing steps, whereby corresponding code self explanatory. end code block also set criteria based features filtered demand later workflow.","code":"myexp <- normalize_by_istd(myexp) #> ! Interfering features defined in metadata, but no correction was applied. Use `correct_interferences()` to correct. #> ✔ 460 features normalized with 17 ISTDs in 499 analyses. myexp <- quantify_by_istd(myexp) #> ✔ 460 feature concentrations calculated based on 42 ISTDs and sample amounts of 499 analyses. #> ℹ Concentrations are given in μmol/L.  myexp <- correct_drift_gaussiankernel(   data = myexp,   variable = \"conc\",   ref_qc_types = c(\"SPL\")) #> ℹ Applying `conc` drift correction... #> ℹ 2 feature(s) contain one or more zero or negative `conc` values. Verify your data or use `log_transform_internal = FALSE`. #>   |                                                    |                                            |   0%  |                                                    |=                                           |   2%  |                                                    |==                                          |   4%  |                                                    |===                                         |   6%  |                                                    |====                                        |   8%  |                                                    |====                                        |  10%  |                                                    |=====                                       |  12%  |                                                    |======                                      |  14%  |                                                    |=======                                     |  16%  |                                                    |========                                    |  18%  |                                                    |=========                                   |  20%  |                                                    |==========                                  |  22%  |                                                    |===========                                 |  24%  |                                                    |============                                |  26%  |                                                    |============                                |  28%  |                                                    |=============                               |  30%  |                                                    |==============                              |  32%  |                                                    |===============                             |  34%  |                                                    |================                            |  37%  |                                                    |=================                           |  39%  |                                                    |==================                          |  41%  |                                                    |===================                         |  43%  |                                                    |====================                        |  45%  |                                                    |=====================                       |  47%  |                                                    |=====================                       |  49%  |                                                    |======================                      |  51%  |                                                    |=======================                     |  53%  |                                                    |========================                    |  55%  |                                                    |=========================                   |  57%  |                                                    |==========================                  |  59%  |                                                    |===========================                 |  61%  |                                                    |============================                |  63%  |                                                    |=============================               |  65%  |                                                    |=============================               |  67%  |                                                    |==============================              |  69%  |                                                    |===============================             |  71%  |                                                    |================================            |  73%  |                                                    |=================================           |  75%  |                                                    |==================================          |  77%  |                                                    |===================================         |  79%  |                                                    |====================================        |  81%  |                                                    |=====================================       |  83%  |                                                    |=====================================       |  85%  |                                                    |======================================      |  87%  |                                                    |=======================================     |  89%  |                                                    |========================================    |  91%  |                                                    |=========================================   |  93%  |                                                    |==========================================  |  95%  |                                                    |=========================================== |  97%  |                                                    |============================================|  99%  |                                                    |============================================| 100% - trend smoothing done! #> ! 1 features showed no variation in the study sample's original values across analyses.  #> ! 1 features have invalid values after smoothing. NA will be be returned for all values of these faetures. Set `use_original_if_fail = FALSE to return orginal values.. #> ✔ Drift correction was applied to 459 of 460 features (batch-wise). #> ℹ The median CV change of all features in study samples was -0.56% (range: -10.22% to 2.49%). The median absolute CV of all features across batches decreased from 38.96% to 38.56%.  myexp <- midar::correct_batch_centering(   myexp,    variable = \"conc\",   ref_qc_types = \"SPL\") #> ℹ Adding batch correction on top of `conc` drift-correction. #> ✔ Batch median-centering of 6 batches was applied to drift-corrected concentrations of all 460 features. #> ℹ The median CV change of all features in study samples was -0.50% (range: -27.90% to 10.30%).  The median absolute CV of all features decreased from 39.89% to 39.46%.  myexp <- filter_features_qc(   data = myexp,   include_qualifier = FALSE,   include_istd = FALSE,    min.signalblank.median.spl.sblk = 10,   max.cv.conc.bqc = 25) #> Calculating feature QC metrics - please wait... #> ✔ New feature QC filters were defined: 182 of 423 quantifier features meet QC criteria (not including the 25 quantifier ISTD features)."},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"plotting-data","dir":"Articles","previous_headings":"","what":"Plotting data","title":"A basic MiDAR workflow","text":"MiDAR provides various plot function can useful understanding analytical performance, trends isses data. Plots also available inspect effect data processing (e.g. drift/bath-effect correction) QC-based feature filtering. create runscatter plot visualize concentration specific features across analytical series different QC sample types. plot can also saved PDF file.","code":"plot_runscatter(     data = myexp,     variable = \"conc\",     include_feature_filter = \"PC 4\",     include_istd = FALSE,     cap_outliers = TRUE,     log_scale = FALSE,     output_pdf = FALSE,     path = \"./output/runscatter_PC408_beforecorr.pdf\",     cols_page = 3, rows_page = 2,   ) #> Generating plots (1 page)... #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T02_settingup_workflow.html","id":"exporting-and-sharing-data","dir":"Articles","previous_headings":"","what":"Exporting and sharing data","title":"A basic MiDAR workflow","text":"Finally, can export specific datasets plain csv tables, create detailed data report, share entire MidarExperiment object someone else without code, can run data processing, plots QC checks.","code":"# Saves a detailed report in Excel format with multiple sheets midar::save_report_xlsx(myexp, path = \"./output/myexp-midar_report.xlsx\") #> Saving report to disk - please wait... #> ✔ The data processing report has been saved to './output/myexp-midar_report.xlsx'.  # Saves flat csv table with concentration values that passed the previously set # QC criteria, for each feature in each sample.  midar::save_dataset_csv(   data = myexp,    path = \"./output/sperfect_filt_uM.csv\",   variable = \"conc\",    qc_types = \"SPL\",    include_qualifier = FALSE,   filter_data = TRUE) #> ✔ Concentration values for 378 analyses and 182 features have been exported to './output/sperfect_filt_uM.csv'.  # Saves the entire MidarExperiment object as an RDS file, which can be # opened in R without MiDAR or used with MiDAR again. saveRDS(myexp, file = \"./output/myexp-midar.rds\", compress = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T_BatchCorrect.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import data","title":"Batch-effect correction","text":"tutorial, import pre-calculcated concentration values CSV file. file must contain column batch information (batch_id), see import_data_csv() information.","code":"library(midar)  myexp <- midar::MidarExperiment()  myexp <- import_data_csv(   myexp,   path = \"simdata-u1000-sd100_7batches.csv\",    variable_name = \"conc\",    import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T_BatchCorrect.html","id":"apply-batch-centering","dir":"Articles","previous_headings":"","what":"Apply batch-centering","title":"Batch-effect correction","text":"Now center concentration values batches based reference qc type, samples (ref_qc_types = \"SPL\") case. correct_scale parameter Next, inspect data batch correction. observe batches now aligned. Note: samples quality control types follow reference samples, may appropriately corrected.","code":"myexp <- correct_batch_centering(   data = myexp,    variable = \"conc\",   ref_qc_types = \"SPL\",    correct_scale = FALSE ) #> ℹ Adding batch correction to `conc` data. #> ✔ Batch median-centering of 7 batches was applied to raw concentrations of all 1 features. #> ℹ The median CV change of all features in study samples was -30.49% (range: -30.50% to -30.50%).  The median absolute CV of all features decreased from 44.05% to 13.56%. plot_runscatter(myexp, variable = \"conc_before\", rows_page = 1, cols_page = 1) plot_runscatter(myexp, variable = \"conc\", rows_page = 1, cols_page = 1)"},{"path":"https://slinghub.github.io/midar/articles/T_BatchCorrect.html","id":"batch-centering-with-variance-scaling","dir":"Articles","previous_headings":"","what":"Batch-centering with variance scaling","title":"Batch-effect correction","text":", observe batches aligned, spread (variance) data points varies considerably batches. can correct scaling variance via correct_scale = TRUE. shown plot , variance data points now appears fairly consistent across batches.","code":"myexp <- midar::correct_batch_centering(   myexp,    ref_qc_types = \"SPL\",    variable = \"conc\",   correct_scale = TRUE ) #> ℹ Replacing previous `conc` batch correction. #> ✔ Batch median-centering of 7 batches was applied to raw concentrations of all 1 features. #> ℹ The median CV change of all features in study samples was -32.20% (range: -32.20% to -32.20%).  The median absolute CV of all features decreased from 44.05% to 11.85%. plot_runscatter(myexp, variable = \"conc\", rows_page = 1, cols_page = 1)"},{"path":"https://slinghub.github.io/midar/articles/T_BatchCorrect.html","id":"export-batch-corrected-data","dir":"Articles","previous_headings":"","what":"Export batch-corrected data","title":"Batch-effect correction","text":"Next, can either continue work corrected data using MiDAR functions export data.","code":"save_dataset_csv(   myexp,    path = \"batch-corrected-conc-data.csv\",    variable = \"conc\",    filter_data = FALSE   ) #> ✔ Concentration values for 700 analyses and 1 features have been exported to 'batch-corrected-conc-data.csv'."},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"import-data-and-metata","dir":"Articles","previous_headings":"","what":"Import data and metata,","title":"Calibration by a Reference Sample","text":"","code":"library(midar)  # Get example data paths dat_file = system.file(\"extdata\", \"S1P_MHQuant.csv\", package = \"midar\") meta_file = system.file(\"extdata\", \"S1P_metadata_tables.xlsx\", package = \"midar\")  # Load data and metadata mexp <- MidarExperiment() mexp <- import_data_masshunter(mexp, dat_file, import_metadata = FALSE) mexp <- import_metadata_analyses(mexp, path = meta_file, sheet = \"Analyses\") mexp <- import_metadata_features(mexp, path = meta_file, sheet = \"Features\") mexp <- import_metadata_istds(mexp, path = meta_file, sheet = \"ISTDs\")"},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"load-known-analyte-concentrations-of-the-reference-sample","dir":"Articles","previous_headings":"","what":"Load known analyte concentrations of the reference sample","title":"Calibration by a Reference Sample","text":"table containing known analyte concentrations NIST SRM1950 reference sample now added MidarExperiment object. Please note S1P concentrations provided table intended illustrative purposes . actual absolute S1P concentrations NIST SRM1950 may differ significantly.","code":"mexp <- import_metadata_qcconcentrations(mexp, path = meta_file, sheet = \"QCconcentrations\") #> ✔ Analysis metadata associated with 65 analyses. #> ✔ Feature metadata associated with 16 features. #> ✔ Internal Standard metadata associated with 2 ISTDs. #> ✔ QC concentration metadata associated with 1 annotated samples and 6 annotated analytes"},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"process-the-data","dir":"Articles","previous_headings":"","what":"Process the data","title":"Calibration by a Reference Sample","text":"analysis performed using HILIC chromatography; thus, need correct isotope interferences S1P 18:2;O2 M+2 S1P 18:1;O2 M+2. Subsequently, initial quantification done using spiked-ISTD concentration.","code":"# Isotope correction mexp <- midar::correct_interferences(mexp) #> ✔ Interference-correction has been applied to 4 of the 16 features.  # Quantify the data mexp <- normalize_by_istd(mexp) #> ✔ 14 features normalized with 2 ISTDs in 65 analyses. mexp <- quantify_by_istd(mexp) #> ✔ 14 feature concentrations calculated based on 2 ISTDs and sample amounts of 65 analyses. #> ℹ Concentrations are given in μmol/L."},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"absolute-calibration","dir":"Articles","previous_headings":"","what":"Absolute calibration","title":"Calibration by a Reference Sample","text":"perform absolute re-calibration using function calibrate_by_reference(). reference sample set via reference_sample_id. cases multiple analyses reference sample present dataset, either mean median calculated (defined via summarize_fun). re-calibrated concentrations stored variable conc , overwriting previously calculated concentrations. original concentrations, however, still available via variable conc_beforecal. re-calibrated concentrations can exported usual, also appear MiDAR XLSX report concentrations.","code":"mexp <- calibrate_by_reference(     data = mexp,     variable = \"conc\",     reference_sample_id = \"SRM1950\",     absolute_calibration = TRUE,     batch_wise = FALSE,     summarize_fun = \"mean\",     undefined_conc_action = \"na\"   ) #> ! One or more feature concentration are not defined in the reference sample SRM1950. `NA` will be returned for these features. To change this, modify `undefined_conc_action` argument. #> ✔ 6 feature concentrations were re-calibrated using the reference sample SRM1950. #> ℹ Concentrations are given in umol/L. # Export absolute calibration concentrations save_dataset_csv(mexp, \"calibrated.csv\", variable = \"conc\") #> ✔ Concentration values for 65 analyses and 14 features have been exported to 'calibrated.csv'.    # Export non-calibrated concentrations save_dataset_csv(mexp, \"noncalibrated.csv\", variable = \"conc_beforecal\") #> ✔ Conc_beforecal values for 65 analyses and 16 features have been exported to 'noncalibrated.csv'.  # Create XLSX report with calibrated concentrations as filtered dataset save_report_xlsx(mexp, \"report.xlsx\", filtered_variable = \"conc\") #> Saving report to disk - please wait... #> ✔ The data processing report has been saved to 'report.xlsx'."},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"normalization-relative-calibration","dir":"Articles","previous_headings":"","what":"Normalization (relative calibration)","title":"Calibration by a Reference Sample","text":"can perform simple normalization reference sample using calibrate_by_reference() function, setting absolute_calibration = FALSE. approach, cases multiple analyses reference sample present dataset, either mean median calculated (defined via summarize_fun). results normalization stored, unlike absolute calibration, ratios, new variable, [VARIABLE]_normalized, [VARIABLE] input variable, e.g., conc_normalized intensity_normalized. normalized concentrations can exported [VARIABLE]_normalized using save_dataset_csv(). MiDAR XLSX report generated save_report_xlsx(), unfiltered dataset normalized concentrations included default. include normalized concentrations filtered dataset, set filtered_variable = “[VARIABLE]_normalized argument.","code":"mexp <- calibrate_by_reference(     data = mexp,     variable = \"conc\",     reference_sample_id = \"SRM1950\",     absolute_calibration = FALSE,     summarize_fun = \"mean\"   ) #> ✔ All features were normalized with reference sample SRM1950 features. #> ℹ Unit is: sample [conc] / SRM1950 [conc] # Export NIST1950-normalized concentrations save_dataset_csv(mexp, \"norm.csv\", variable = \"conc_normalized\") #> ✔ Conc_normalized values for 65 analyses and 16 features have been exported to 'norm.csv'.  # Create XLSX report with normalized concentrations as filtered dataset save_report_xlsx(mexp, \"report_norm.xlsx\", filtered_variable = \"conc_normalized\") #> Saving report to disk - please wait... #> ✔ The data processing report has been saved to 'report_norm.xlsx'."},{"path":"https://slinghub.github.io/midar/articles/T_CalibRef.html","id":"batch-wise-calibration","dir":"Articles","previous_headings":"","what":"Batch-wise calibration","title":"Calibration by a Reference Sample","text":"Calibration can also applied batch-wise, case batch calibrated separately data reference sample batch. done setting batch_wise = TRUE can used absolute relative calibration. approach can used correct batches assays/plates using reference material shared across batches.","code":"mexp <- calibrate_by_reference(     data = mexp,     variable = \"conc\",     reference_sample_id = \"SRM1950\",     absolute_calibration = TRUE,     batch_wise = TRUE,     summarize_fun = \"mean\",     undefined_conc_action = \"na\"   ) #> ! One or more feature concentration are not defined in the reference sample SRM1950. `NA` will be returned for these features. To change this, modify `undefined_conc_action` argument. #> Adding missing grouping variables: `batch_id` #> ✔ 6 feature concentrations were batch-wise re-calibrated using the reference #> sample SRM1950. #> ℹ Concentrations are given in umol/L.  save_dataset_csv(mexp, \"bathwise_calibrated.csv\", variable = \"conc_beforecal\") #> ✔ Conc_beforecal values for 65 analyses and 16 features have been exported to 'bathwise_calibrated.csv'."},{"path":"https://slinghub.github.io/midar/articles/T_DriftCorrect.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import data","title":"Drift Correction (Smoothing)","text":"tutorial, import pre-calculcated raw oncentration values CSV file. file must contain column batch information (batch_id) batch-wise correction applied, see import_data_csv() information.","code":"library(midar)  myexp <- midar::MidarExperiment()  myexp <- import_data_csv(   myexp,   path = \"smooth-testdata.csv\",    variable_name = \"conc\",    import_metadata = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T_DriftCorrect.html","id":"qc-based-smoothing","dir":"Articles","previous_headings":"","what":"QC-based smoothing","title":"Drift Correction (Smoothing)","text":"Now apply QC-based drift correction using cubic spline. See correct_drift_cubicspline() information. Next, inspect data correction. observe green trendline follows QC samples (red). correction, trend fully smoothed , resulting straight line.","code":"mexp_drift <- correct_drift_cubicspline(   myexp,   batch_wise = FALSE,   variable = \"conc\",   ref_qc_types = \"BQC\",   recalc_trend_after = TRUE) #> ℹ Applying `conc` drift correction... #> ✔ Drift correction was applied to 3 of 3 features (across all batches). #> ℹ The median CV change of all features in study samples was -4.69% (range: -8.21% to 1.17%). The median absolute CV of all features decreased from 30.56% to 28.52%. plot_runscatter(mexp_drift, variable = \"conc_before\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE) plot_runscatter(mexp_drift, variable = \"conc\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T_DriftCorrect.html","id":"sample-trend-based-smoothing","dir":"Articles","previous_headings":"","what":"Sample trend-based smoothing","title":"Drift Correction (Smoothing)","text":", observe QC samples fully represent trends study samples. discrepancy can occur QC samples, often based pooled samples, differ handling properties study samples. therefore now try sample-based drift correction gaussian kernel smoothing. See correct_drift_gaussiankernel) information. , inspect data correction. observe green trendline follows samples (grey). correction, trend fully smoothed , resulting straight line.  Now, trends study samples appear fairly well corrected. However, example, differences compared previous QC-based smoothing pronounced.","code":"mexp_drift <- correct_drift_gaussiankernel(   myexp,   variable = \"conc\",   kernel_size = 10,   batch_wise = FALSE,   ref_qc_types = \"SPL\",   recalc_trend_after = TRUE) #> ℹ Applying `conc` drift correction... #> ✔ Drift correction was applied to 3 of 3 features (across all batches). #> ℹ The median CV change of all features in study samples was -6.18% (range: -11.46% to -1.49%). The median absolute CV of all features decreased from 30.56% to 25.86%. plot_runscatter(mexp_drift, variable = \"conc_before\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE) plot_runscatter(mexp_drift, variable = \"conc\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE)"},{"path":"https://slinghub.github.io/midar/articles/T_DriftCorrect.html","id":"within-batch-drift-correction","dir":"Articles","previous_headings":"","what":"Within-batch drift correction","title":"Drift Correction (Smoothing)","text":"examples app;ied drift correction across batches. However, batch-effects present break drifts, recommended apply drift correction within batch. explore within-batch drift correction using sample-based gaussian kernel smoothing next example, setting batch_wise = TRUE. Now, batch trendline corresponding trend batch feature. Contrary previous correction across batches, now observe clear differences trends still present correction. effect correct applied independly batch, different sample sizes present batch effects. Therefore, often necessary apply batch correction bathc-wise drift correction   therefore apply subsequent batch correction using median-centering, resulting alignment batches.","code":"mexp_drift <- correct_drift_gaussiankernel(   myexp,   variable = \"conc\",   kernel_size = 10,   batch_wise = TRUE,   ref_qc_types = \"SPL\",   recalc_trend_after = TRUE) #> ℹ Applying `conc` drift correction... #> ✔ Drift correction was applied to 3 of 3 features (batch-wise). #> ℹ The median CV change of all features in study samples was -1.20% (range: -1.88% to -0.61%). The median absolute CV of all features across batches decreased from 26.28% to 25.67%. plot_runscatter(mexp_drift, variable = \"conc_before\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE) plot_runscatter(mexp_drift, variable = \"conc\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE) mexp_drift <- midar::correct_batch_centering(   mexp_drift,    ref_qc_types = \"SPL\",    variable = \"conc\",   correct_scale = TRUE ) #> ℹ Adding batch correction on top of `conc` drift-correction. #> ✔ Batch median-centering of 6 batches was applied to drift-corrected concentrations of all 3 features. #> ℹ The median CV change of all features in study samples was -5.38% (range: -8.80% to -0.60%).  The median absolute CV of all features decreased from 30.00% to 25.68%.  plot_runscatter(mexp_drift, variable = \"conc\", qc_types = c(\"BQC\", \"SPL\"),                 rows_page = 1, cols_page = 3, show_trend = TRUE) #> Generating plots (1 page)... #>  - done!"},{"path":"https://slinghub.github.io/midar/articles/T_DriftCorrect.html","id":"export-corrected-data","dir":"Articles","previous_headings":"","what":"Export corrected data","title":"Drift Correction (Smoothing)","text":"Next, can either continue work corrected data using MiDAR functions export data.","code":"save_dataset_csv(   mexp_drift,    path = \"drift-batch-corrected-conc-data.csv\",    variable = \"conc\",    filter_data = FALSE   ) #> ✔ Concentration values for 498 analyses and 3 features have been exported to 'drift-batch-corrected-conc-data.csv'."},{"path":"https://slinghub.github.io/midar/articles/midar.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"Getting Started","text":"Visit MiDAR Documentation page (https://slinghub.github.io/midar) detailed introduction comprehensive documentation package.","code":""},{"path":"https://slinghub.github.io/midar/articles/midar.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started","text":"","code":"if (!require(\"pak\")) install.packages(\"pak\") pak::pkg_install(\"SLINGhub/midar\")"},{"path":"https://slinghub.github.io/midar/articles/midar.html","id":"example-workflow","dir":"Articles","previous_headings":"","what":"Example Workflow","title":"Getting Started","text":"","code":"# Path of example files included with this package dir_path <- system.file(\"extdata\",  package = \"midar\")  # Create a MidarExperiment object mexp <- MidarExperiment()  # Load data and metadata mexp <- import_data_mrmkit(mexp,                            path = file.path(dir_path, \"MRMkit_demo.tsv\"),                            import_metadata = TRUE) #> ✔ Imported 499 analyses with 28 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features.  mexp <- import_metadata_analyses(mexp,                                   path = file.path(dir_path, \"MRMkit_AnalysesAnnot.csv\"),                                   ignore_warnings = T) #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features. mexp <- import_metadata_istds(mexp,                                path = file.path(dir_path, \"MRMkit_ISTDconc.csv\")) #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features. #> ✔ Internal Standard metadata associated with 9 ISTDs.  # Normalize and quantitate features by internal standards mexp <- normalize_by_istd(mexp) #> ✔ 19 features normalized with 9 ISTDs in 499 analyses. mexp <- quantify_by_istd(mexp) #> ✔ 19 feature concentrations calculated based on 9 ISTDs and sample amounts of 499 analyses. #> ℹ Concentrations are given in μmol/L.  # Drift and batch-effect correction mexp <- correct_drift_cubicspline(mexp, variable = \"conc\", ref_qc_types = \"BQC\") #> ℹ Applying `conc` drift correction... #>   |                                                    |                                            |   0%  |                                                    |=                                           |   3%  |                                                    |==                                          |   5%  |                                                    |===                                         |   8%  |                                                    |=====                                       |  11%  |                                                    |======                                      |  13%  |                                                    |=======                                     |  16%  |                                                    |========                                    |  18%  |                                                    |=========                                   |  21%  |                                                    |==========                                  |  24%  |                                                    |============                                |  26%  |                                                    |=============                               |  29%  |                                                    |==============                              |  32%  |                                                    |===============                             |  34%  |                                                    |================                            |  37%  |                                                    |=================                           |  39%  |                                                    |===================                         |  42%  |                                                    |====================                        |  45%  |                                                    |=====================                       |  47%  |                                                    |======================                      |  50%  |                                                    |=======================                     |  53%  |                                                    |========================                    |  55%  |                                                    |=========================                   |  58%  |                                                    |===========================                 |  61%  |                                                    |============================                |  63%  |                                                    |=============================               |  66%  |                                                    |==============================              |  68%  |                                                    |===============================             |  71%  |                                                    |================================            |  74%  |                                                    |==================================          |  76%  |                                                    |===================================         |  79%  |                                                    |====================================        |  82%  |                                                    |=====================================       |  84%  |                                                    |======================================      |  87%  |                                                    |=======================================     |  89%  |                                                    |=========================================   |  92%  |                                                    |==========================================  |  95%  |                                                    |=========================================== |  97%  |                                                    |============================================| 100% - trend smoothing done! #> ✔ Drift correction was applied to 19 of 19 features (batch-wise). #> ℹ The median CV change of all features in study samples was 0.57% (range: -0.72% to 2.66%). The median absolute CV of all features across batches increased from 33.20% to 35.31%. mexp <- correct_batch_centering(mexp, variable = \"conc\", ref_qc_types = \"BQC\") #> ℹ Adding batch correction on top of `conc` drift-correction. #> ✔ Batch median-centering of 6 batches was applied to drift-corrected concentrations of all 19 features. #> ℹ The median CV change of all features in study samples was 0.01% (range: -7.60% to 2.50%).  The median absolute CV of all features increased from 36.14% to 36.76%.  # Plot analysis time-trends of final concentrations of each feature  plot_runscatter(mexp,                 variable = \"conc\",                 qc_types = c(\"BQC\", \"TQC\", \"SPL\", \"PBLK\", \"SBLK\"),                 cap_outliers = TRUE,                 output_pdf = FALSE,                 path = \"./output/runscatter_istd.pdf\") #> Generating plots (4 pages)... #>  - done!  # Set features QC-filter criteria     mexp <- filter_features_qc(mexp,                             max.cv.conc.bqc = 25,                             min.signalblank.median.spl.pblk = 3,                             include_qualifier = FALSE,                             include_istd = FALSE) #> Calculating feature QC metrics - please wait... #> ✔ New feature QC filters were defined: 19 of 19 quantifier features meet QC criteria (not including the 9 quantifier ISTD features).   # Save concentration data  save_dataset_csv( mexp,                     path = \"mydata.csv\",                     variable = \"conc\",                     filter_data = TRUE) #> ✔ Concentration values for 499 analyses and 19 features have been exported to 'mydata.csv'."},{"path":"https://slinghub.github.io/midar/articles/midar.html","id":"contributor-code-of-conduct","dir":"Articles","previous_headings":"","what":"Contributor Code of Conduct","title":"Getting Started","text":"Please note midar project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://slinghub.github.io/midar/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bo Burla. Author, maintainer.","code":""},{"path":"https://slinghub.github.io/midar/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Burla B (2025). midar: Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration Reporting. R package version 0.2.1, https://slinghub.github.io/midar/, https://github.com/SLINGhub/midar.","code":"@Manual{,   title = {midar: Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting},   author = {Bo Burla},   year = {2025},   note = {R package version 0.2.1, https://slinghub.github.io/midar/},   url = {https://github.com/SLINGhub/midar}, }"},{"path":"https://slinghub.github.io/midar/index.html","id":"midar-","dir":"","previous_headings":"","what":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","title":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","text":"MiDAR R package designed reproducible post-processing, quality control, reporting quantitative small-molecule mass spectrometry (MS) data. modular functionalities defined data structure, support diverse analytical designs, data formats, processing tasks, including metabolomics lipidomics. MiDAR intended analytical bioinformatics scientists facilitate collaboration . enables creation customizable, supervisable, documented data processing workflows intuitive high-level R functions data objects. MiDAR’s core tools, accessible also limited R experience, allow analysts annotate, inspect, process data. includes importing data metadata various file formats, managing organizing data integrity checks, performing processing tasks quantification, drift/batch correction, applying QC-based feature filtering. Users can assess data quality using QC metrics diagnostic plots, share raw processed data along entire processing workflow analyses documentation. MiDAR also serves validated software framework building robust scalable data processing pipelines.","code":""},{"path":"https://slinghub.github.io/midar/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","text":"Please visit Getting Started page tutorials documentation MiDAR.","code":""},{"path":"https://slinghub.github.io/midar/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","text":"install, update, MiDAR, run following code R console:","code":"if (!require(\"pak\")) install.packages(\"pak\") pak::pkg_install(\"SLINGhub/midar\")"},{"path":"https://slinghub.github.io/midar/index.html","id":"example-workflow","dir":"","previous_headings":"","what":"Example Workflow","title":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","text":"","code":"# Path of example files included with this package dir_path <- system.file(\"extdata\",  package = \"midar\")  # Create a MidarExperiment object mexp <- MidarExperiment()  # Load data and metadata mexp <- import_data_mrmkit(mexp,                            path = file.path(dir_path, \"MRMkit_demo.tsv\"),                            import_metadata = TRUE)  mexp <- import_metadata_analyses(mexp,                                   path = file.path(dir_path, \"MRMkit_AnalysesAnnot.csv\"),                                   ignore_warnings = T) mexp <- import_metadata_istds(mexp,                                path = file.path(dir_path, \"MRMkit_ISTDconc.csv\"))  # Normalize and quantitate features by internal standards mexp <- normalize_by_istd(mexp) mexp <- quantify_by_istd(mexp)  # Drift and batch-effect correction mexp <- correct_drift_cubicspline(mexp, variable = \"conc\", ref_qc_types = \"BQC\") mexp <- correct_batch_centering(mexp, variable = \"conc\", ref_qc_types = \"BQC\")  # Plot analysis time-trends of final concentrations of each feature  plot_runscatter(mexp,                 variable = \"conc\",                 qc_types = c(\"BQC\", \"TQC\", \"SPL\", \"PBLK\", \"SBLK\"),                 cap_outliers = TRUE,                 output_pdf = FALSE,                 path = \"./output/runscatter_istd.pdf\")  # Set features QC-filter criteria     mexp <- filter_features_qc(mexp,                             max.cv.conc.bqc = 25,                             min.signalblank.median.spl.pblk = 3,                             include_qualifier = FALSE,                             include_istd = FALSE)   # Save concentration data  save_dataset_csv( mexp,                     path = \"mydata.csv\",                     variable = \"conc\",                     filter_data = TRUE)"},{"path":"https://slinghub.github.io/midar/index.html","id":"contributor-code-of-conduct","dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting","text":"Please note midar project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment-class.html","id":null,"dir":"Reference","previous_headings":"","what":"S4 Class Representing the MIDAR Dataset — MidarExperiment-class","title":"S4 Class Representing the MIDAR Dataset — MidarExperiment-class","text":"MidarExperiment object core data structure utilized within MiDAR workflow, encapsulating relevant experimental data metadata. also includes processing results, details applied processing steps, current status data.","code":""},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"S4 Class Representing the MIDAR Dataset — MidarExperiment-class","text":"title Title experiment analysis_type Analysis type, one \"lipidomics\", \"metabolomics\", \"externalcalib\", \"others\" feature_intensity_var Feature variable used default calculations dataset_orig Original imported analysis data. Required fields: dataset Processed analysis data. Required fields: dataset_filtered Processed analysis data. Required fields: annot_analyses Annotation analyses/runs annot_features Annotation measured features. annot_istds Annotation Internal Standard concs. annot_responsecurves Annotation response curves (RQC). Required fields annot_qcconcentrations Annotation calibration curves. Required fields annot_studysamples Annotation study samples. Required fields: annot_batches Annotation batches. Required fields: metrics_qc QC information measured feature metrics_calibration Calibration metrics calculated external calibration curves measured feature parameters_processing Values parameters used different processing steps status_processing Status within data processing workflow is_istd_normalized Flag data ISTD normalized is_quantitated Flag data quantitated using ISTD sample amount is_filtered Flag data filtered based QC parameters is_isotope_corr Flag one features isotope corrected has_outliers_tech Flag data technical analysis/sample outliers analyses_excluded Analyses excluded processing, plots reporting, unless explicitly requested features_excluded Features excluded processing, plots reporting, unless explicitly requested var_drift_corrected List indicating variables drift corrected var_batch_corrected List indicating variables batch corrected","code":""},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for the MidarExperiment object. — MidarExperiment","title":"Constructor for the MidarExperiment object. — MidarExperiment","text":"Constructor MidarExperiment object.","code":""},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for the MidarExperiment object. — MidarExperiment","text":"","code":"MidarExperiment(title = \"\", analysis_type = NA_character_)"},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for the MidarExperiment object. — MidarExperiment","text":"title Title experiment analysis_type Analysis type, one \"lipidomics\", \"metabolomics\", \"externalcalib\", \"others\"","code":""},{"path":"https://slinghub.github.io/midar/reference/MidarExperiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for the MidarExperiment object. — MidarExperiment","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/add_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Add metadata an MidarExperiment object — add_metadata","title":"Add metadata an MidarExperiment object — add_metadata","text":"Metadata provided list tibbles validates consistency loaded analysis data provided MidarExperiment object transfered.","code":""},{"path":"https://slinghub.github.io/midar/reference/add_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add metadata an MidarExperiment object — add_metadata","text":"","code":"add_metadata(data = NULL, metadata, excl_unmatched_analyses = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/add_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add metadata an MidarExperiment object — add_metadata","text":"data MidarExperiment object metadata List tibbles data.frames containing analysis, feature, istd, response curve tables excl_unmatched_analyses Exclude analyses (samples) matching metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/add_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add metadata an MidarExperiment object — add_metadata","text":"metadata list","code":""},{"path":"https://slinghub.github.io/midar/reference/assert_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Add metadata an MidarExperiment object — assert_metadata","title":"Add metadata an MidarExperiment object — assert_metadata","text":"Metadata provided list tibbles validates consistency loaded analysis data provided MidarExperiment object transfered.","code":""},{"path":"https://slinghub.github.io/midar/reference/assert_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add metadata an MidarExperiment object — assert_metadata","text":"","code":"assert_metadata(   data = NULL,   metadata,   ignore_warnings,   excl_unmatched_analyses )"},{"path":"https://slinghub.github.io/midar/reference/assert_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add metadata an MidarExperiment object — assert_metadata","text":"data MidarExperiment object metadata List tibbles data.frames containing analysis, feature, istd, response curve tables ignore_warnings Ignore data validation warnings proceed adding metadata excl_unmatched_analyses Exclude analyses (samples) matching metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/assert_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add metadata an MidarExperiment object — assert_metadata","text":"metadata list","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"Calculates average molecular weight one chemical formulas, based natural isotopic distribution elements. calculation uses enviPat package retrieve isotopic masses abundances, computes weighted mean isotopic distribution.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"","code":"calc_average_molweight(formula)"},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"formula character vector one chemical formulas process.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"numeric vector average molecular weights, one formula.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"function calculates average molecular weight (monoisotopic mass), reflects average isotopic distribution found nature. Isotopes can specified explicitly formula. Atomic mass numbers isotopes must enclosed square brackets (e.g., [13]C carbon-13). Deuterium must written D instead [3]H. function uses enviPat package validate parse chemical formulas, calculate isotopic patterns, determine average molecular weight based weighted means isotopic abundances.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"Loos, M., Gerber, C., Corona, F., Hollender, J., & Singer, H. (2015). Accelerated Isotope Fine Structure Calculation Using Pruned Transition Trees. Analytical Chemistry, 87(11), 5738–5744. doi:10.1021/acs.analchem.5b00941","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_average_molweight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Average Molecular Weight from Chemical Formulas — calc_average_molweight","text":"","code":"calc_average_molweight(c(\"C6H12O6\", \"[13]C6H12O6\", \"C8H10N4O2\", \"D2O\")) #> [1] 180.15613 186.11184 194.19090  20.02761"},{"path":"https://slinghub.github.io/midar/reference/calc_calibration_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate external calibration curve results — calc_calibration_results","title":"Calculate external calibration curve results — calc_calibration_results","text":"Calibration curves calculated feature using ISTD-normalized intensities corresponding concentrations calibration samples, defined qc_concentrations metadata. regression fit model (linear quadratic) weighting method (either \"none\", \"1/x\", \"1/x^2\") can defined globally via arguments fit_model fit_weighting features, overwrite_fit_param TRUE. Alternatively, model weighting can defined individually feature feature metadata (columns curve_fit_model fit_weighting). details missing metadata, default values provided via fit_model fit_weighting used.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_calibration_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate external calibration curve results — calc_calibration_results","text":"","code":"calc_calibration_results(   data = NULL,   variable = \"feature_norm_intensity\",   include_qualifier = TRUE,   overwrite_fit_param = TRUE,   fit_model,   fit_weighting,   ignore_missing_annotation = FALSE,   include_fit_object = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/calc_calibration_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate external calibration curve results — calc_calibration_results","text":"data MidarExperiment object containing data used calibration. variable character string specifying variable calibration. Use \"feature_norm_intensity\" typical scenarios involving internal standardization. performing external standardization, without internal standardization, use \"feature_intensity\". include_qualifier logical value. TRUE, function include quantifier features calibration curve calculations. overwrite_fit_param TRUE, function ignore fit method weighting settings defined metadata use provided fit_model fit_weighting values analytes. fit_model character string specifying default regression fit method use calibration curve. Must one \"linear\" \"quadratic\". method applied specific fit method defined feature metadata, overwrite_fit_param = TRUE. fit_weighting character string specifying default weighting method regression points calibration curve. Must one \"none\", \"1/x\", \"1/x^2\". method applied specific weighting method defined feature metadata, overwrite_fit_param = TRUE. ignore_missing_annotation FALSE, error raised following information missing: calibration curve data, ISTD mix volume, sample amounts feature. include_fit_object TRUE, function return full regression fit objects feature metrics_calibration table.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_calibration_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate external calibration curve results — calc_calibration_results","text":"modified MidarExperiment object updated metrics_calibration table containing calibration curve results, including concentrations, LoD, LoQ values feature.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_calibration_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate external calibration curve results — calc_calibration_results","text":"Additionally, limit detection (LoD) limit quantification (LoQ) calculated feature based calibration curve. LoD calculated 3 times sample standard error regression residuals divided regression slope, LoQ 10 times ratio. case quadratic fit, LoD LoQ calculated using slope concentration lowest calibration point. results regression calculated LoD LoQ values stored metrics_calibration table returned MidarExperiment object.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/calc_qc_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","title":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","text":"Computes various quality control (QC) metrics feature MidarExperiment object. Metrics derived different sample types can computed either across full dataset medians batch-wise calculations.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_qc_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","text":"","code":"calc_qc_metrics(   data = NULL,   use_batch_medians = FALSE,   include_norm_intensity_stats = NA,   include_conc_stats = NA,   include_response_stats = NA,   include_calibration_results = NA )"},{"path":"https://slinghub.github.io/midar/reference/calc_qc_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","text":"data MidarExperiment object containing data metadata, whereby data needs normalized quantitated specific QC metrics, statistics based normalized intensities concentrations. use_batch_medians Logical, whether compute QC metrics using median batch-wise derived values instead full dataset. Default FALSE. include_norm_intensity_stats Logical. NA (default), statistics normalized intensity values included data available. TRUE, always calculated, raising error data missing. include_conc_stats Logical. NA (default), concentration-related statistics included concentration data available. TRUE, always calculated, raising error data missing. include_response_stats Logical. NA (default), response curve statistics included required data available. TRUE, always calculated, raising error data missing. include_calibration_results Logical, whether incorporate external calibration results QC metrics table available. Default TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_qc_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","text":"MidarExperiment object updated metrics_qc table containing computed QC metrics feature.","code":""},{"path":"https://slinghub.github.io/midar/reference/calc_qc_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Quality Control (QC) Metrics for Features — calc_qc_metrics","text":"Batch-wise calculations: function computes following QC metrics feature different QC sample types (e.g., SPL, TQC, BQC, PBLK, NIST, LTR) format metrics standardized metric_name_qc_type, qc_type refers specific QC sample type metric calculated. example: intensity_min_spl refers minimum intensity Statistics normalized intensities , external calibration, response curves can included setting relevant arguments (include_norm_intensity_stats, include_conc_stats, include_response_stats, include_calibration_results) TRUE. Note corresponding underlying processed data available, function raise error return NA values respective metrics. , however, apply optinal metrics mentioned . cases error raised underlying data missing. use_batch_medians = TRUE, batch-specific QC statistics computed first, median values returned feature. However, response curve calibration statistics calculated per curve, irrespective batches use_batch_medians settings. calculated metrics stored metrics_qc table MidarExperiment objects comprises following details Feature details: Specific feature information extracted feature metadata tanle, feature class, associated ISTD, quantifier status. Feature MS Method Information (method variables available analysis data). Extracts summarizes method-related variables feature. multiple values exist feature, concatenated string. latter indicate inconsistent analysis conditions. precursor_mz: m/z value precursor ion(s), product_mz: m/z value product ion(s), concatenated multiple values exist feature. collision_energy: collision energy used fragmentation, concatenated multiple values exist exist feature. Missing Value Metrics: missing_intensity_prop_spl: Proportion missing intensities SPL sample type. missing_norm_intensity_prop_spl: Proportion missing normalized intensities SPL samples. missing_conc_prop_spl: Proportion missing concentration values SPL samples. na_in_all: Indicator feature missing intensities across samples Retention Time (RT) Metrics: Requires retention tim data available. rt_min_*: Minimum retention time across different QC sample types (e.g., SPL, BQC, TQC). rt_max_*: Maximum retention time across different QC sample types. rt_median_*: Median retention time specific QC sample types like PBLK, SPL, BQC, TQC, etc. Intensity Metrics: intensity_min_*: Minimum intensity value features across different QC sample types SPL, TQC, BQC, etc. intensity_max_*: Maximum intensity values across sample types. intensity_median_*: Median intensity various QC sample types. intensity_cv_*: Coefficient variation (CV) intensity values specific QC types. sb_ratio_*: Signal--blank ratios ratio intensity values SPL vs PBLK, UBLK, SBLK. intensity_q10_*: 10th percentile intensity values SPL sample type. Normalized Intensity Metrics (include_norm_intensity_stats = TRUE): Requires raw intensities  normalized, see normalize_by_istd() details. norm_intensity_cv_*: Coefficient variation (CV) normalized intensities QC sample types like TQC, BQC, SPL, etc. Concentration Metrics (include_conc_stats = TRUE): Requires concentration calculated, see quantify_by_istd() quantify_by_calibration() details. conc_median_*: Median concentration values different QC sample types like TQC, BQC, SPL, NIST, LTR. conc_cv_*: Coefficient variation (CV) concentration values. conc_dratio_sd_*: ratio standard deviations concentration BQC TQC SPL samples. conc_dratio_mad_*: ratio median absolute deviations (MAD) BQC TQC SPL concentrations. Response Curve Metrics (include_response_stats = TRUE): Calculates response curve statistics feature curve (# refers curve identifier). Requires response curves defined data. See get_response_curve_stats() additional details. r2_rqc_#: R-squared value linear regression response curve, representing goodness fit. slopenorm_rqc_#: Normalized slope linear regression response curve, indicating relationship response concentration. y0norm_rqc_#: Normalized intercept linear regression response curve, representing baseline starting value. External Calibration Results Incorporates external calibration results, include_calibration_results = TRUE calibration curves defined data: fit_model: regression model used curve fitting. fit_weighting: weighting method applied curve fitting. lowest_cal: lowest nonzero calibration concentration. highest_cal: highest calibration concentration. r.squared: R-squared value indicating goodness fit. coef_a: linear fits, represents slope regression line. quadratic fits, represents coefficient quadratic term (x²). coef_b: linear fits, represents intercept regression line. quadratic fits, represents coefficient linear term (x). coef_c: present quadratic fits, representing intercept regression equation. Set NA linear fits. sigma: residual standard error regression model. reg_failed: Boolean flag indicating regression fitting failed.","code":""},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"function calibrates feature abundances based specified reference sample. Calibration can applied entire dataset using one reference samples, batch-wise using reference sample analyses present within batch. approaches, multiple measurements reference sample summarized using either mean (default) median (set summarize_fun argument).","code":""},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"","code":"calibrate_by_reference(   data,   variable,   reference_sample_id,   absolute_calibration,   batch_wise = FALSE,   summarize_fun = \"mean\",   undefined_conc_action = NULL )"},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"data MidarExperiment object containing metabolomics data normalized variable Character string indicating data type calibrate Must one : \"intensity\", \"norm_intensity\", \"conc\" reference_sample_id Character vector specifying sample ID(s) use reference(s) standards absolute_calibration Logical indicating whether perform absolute calibration using known concentrations reference sample (TRUE) relative calibration (FALSE). batch_wise Logical indicating whether perform calibration batch seperately (TRUE) samples together (FALSE). summarize_fun Either \"mean\" \"median\". absolute_calibration = TRUE, function used summarize reference sample concentrations across analyses specified reference_sample_id. Default \"mean\". undefined_conc_action Character string specifying handle features without defined concentrations reference samples absolute_calibration = TRUE. Must one : \"original\" (keep original values), \"na\" (set NA), \"error\". Default \"keep\".","code":""},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"MidarExperiment object calibrated data","code":""},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"Calibration can performed two ways, either absolute, resulting concentrations, relative, resulting ratios: Absolute calibration (absolute_calibration = TRUE) Calibrates (re-calibrates) feature abundances based known concentrations corresponding features defined reference sample. input variable can either conc, norm_intensity, intensity, whereas result always stored variableconc` (concentration), unit defined feature concentrations reference sample. Metadata requirements: sample_id analyte_id must defined reference sample features analysis feature metadata, respectively. Known analyte concentrations must defined QC concentration metadata reference sample error raised  concentrations defined features Missing analyte concentrations reference sample can handed via undefined_conc_handling following options: original: Keep original feature values, .e. non-calibrated values returned. Note: available variable = conc. Use caution avoid mixing units. na: Set affected features values NA error (default): function stops error case undefined reference sample feature concentration. case feature concentrations undefined, function stop error. re-calibrated feature concentrations stored conc, overwriting existing conc values. original conc values stored conc_beforecal. export calibrated concentrations use save_dataset_csv() variable = \"conc\", export non-calibrated values variable = \"conc_beforecal\". saving MiDAR XLSX report, calibrated concentrations also stored conc`. Normalization (relative calibration, absolute_calibration = FALSE) Normalizes features abundances corresponding feature abundances reference sample, resulting ratios. available feature abundance variable (.e., conc, norm_intensity, intensity) can used input. normalization calculate present features. resulting output stored [VARIABLE]_normalized, whereby [VARIABLE] input variable, e.g., conc_normalized. export normalized abundances , use save_dataset_csv() variable = \"[VARIABLE]_normalized\" MiDAR XLSX report, use save_report_xlsx() variable setting save_dataset_csv() saving MiDAR XLSX report via save_report_xlsx(), availble unfiltered normalized feature abundances included default. include filtered normalized feature abundances, set filtered_variable = \"[VARIABLE]_normalized\".","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/calibrate_by_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate Features Values Using Reference Sample — calibrate_by_reference","text":"","code":"dat_file = system.file(\"extdata\", \"S1P_MHQuant.csv\", package = \"midar\") meta_file = system.file(\"extdata\", \"S1P_metadata_tables.xlsx\", package = \"midar\") # Load data and metadata mexp <- MidarExperiment() mexp <- import_data_masshunter(mexp, dat_file, import_metadata = FALSE) #> ✔ Imported 65 analyses with 16 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. mexp <- import_metadata_analyses(mexp, path = meta_file, sheet = \"Analyses\") #> ✔ Analysis metadata associated with 65 analyses. mexp <- import_metadata_features(mexp, path = meta_file, sheet = \"Features\") #> ✔ Analysis metadata associated with 65 analyses. #> ✔ Feature metadata associated with 16 features. mexp <- import_metadata_istds(mexp, path = meta_file, sheet = \"ISTDs\") #> ✔ Analysis metadata associated with 65 analyses. #> ✔ Feature metadata associated with 16 features. #> ✔ Internal Standard metadata associated with 2 ISTDs.  # Load known feature concentrations in the reference sample mexp <- import_metadata_qcconcentrations(mexp, path = meta_file, sheet = \"QCconcentrations\") #> ✔ Analysis metadata associated with 65 analyses. #> ✔ Feature metadata associated with 16 features. #> ✔ Internal Standard metadata associated with 2 ISTDs. #> ✔ QC concentration metadata associated with 1 annotated samples and 6 annotated analytes mexp <- normalize_by_istd(mexp) #> ! Interfering features defined in metadata, but no correction was applied. Use `correct_interferences()` to correct. #> ✔ 14 features normalized with 2 ISTDs in 65 analyses. mexp <- quantify_by_istd(mexp) #> ✔ 14 feature concentrations calculated based on 2 ISTDs and sample amounts of 65 analyses. #> ℹ Concentrations are given in μmol/L.  # Absolute calibration # --------------------    mexp <- calibrate_by_reference(     data = mexp,     variable = \"conc\",     reference_sample_id = \"SRM1950\",     absolute_calibration = TRUE,     batch_wise = FALSE,     summarize_fun = \"mean\",     undefined_conc_action = \"original\"   ) #> ! One or more feature concentration are not defined in the reference sample SRM1950. Original values will be returned for these. To change this, modify `undefined_conc_action` argument. #> ✔ 6 feature concentrations were re-calibrated using the reference sample SRM1950. #> ℹ Concentrations are given in umol/L.    # Export absolute calibration concentrations   save_dataset_csv(mexp, \"calibrated.csv\", variable = \"conc\", filter_data = FALSE) #> ✔ Concentration values for 65 analyses and 14 features have been exported to 'calibrated.csv'.    # Export non-calibrated concentrations   save_dataset_csv(mexp, \"noncalibrated.csv\", variable = \"conc_beforecal\", filter_data = FALSE) #> ✔ Conc_beforecal values for 65 analyses and 16 features have been exported to 'noncalibrated.csv'.    # Create XLSX report with calibrated concentrations as filtered dataset   save_report_xlsx(mexp, \"report.xlsx\", filtered_variable = \"conc\") #>  Saving report to disk - please wait... #> ✔  The data processing report has been saved to 'report.xlsx'.  # Relative calibration # --------------------    mexp <- calibrate_by_reference(     data = mexp,     variable = \"conc\",     reference_sample_id = \"SRM1950\",     batch_wise = FALSE,     absolute_calibration = FALSE   ) #> ✔ All features were normalized with reference sample SRM1950 features. #> ℹ Unit is: sample [conc] / SRM1950 [conc]    # Export SRM1950-normalized concentrations   save_dataset_csv(mexp, \"normalized.csv\", variable = \"conc_normalized\", filter_data = FALSE) #> ✔ Conc_normalized values for 65 analyses and 16 features have been exported to 'normalized.csv'.    # Create XLSX report with SRM1950-normalized concentrations as filtered dataset   save_report_xlsx(mexp, \"report.xlsx\", filtered_variable = \"conc_normalized\") #>  Saving report to disk - please wait... #> ✔  The data processing report has been saved to 'report.xlsx'."},{"path":"https://slinghub.github.io/midar/reference/cash-MidarExperiment-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","title":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","text":"$ syntax can used shortcut getting specific variables results MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/cash-MidarExperiment-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","text":"","code":"# S4 method for class 'MidarExperiment' x$name"},{"path":"https://slinghub.github.io/midar/reference/cash-MidarExperiment-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","text":"x MidarExperiment object name MidarExperiment slot","code":""},{"path":"https://slinghub.github.io/midar/reference/cash-MidarExperiment-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","text":"Value variable tibble","code":""},{"path":"https://slinghub.github.io/midar/reference/cash-MidarExperiment-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access Slots of a MidarExperiment Object via $ Syntax — $,MidarExperiment-method","text":"","code":"mexp <- MidarExperiment(title = \"Test Experiment\", analysis_type = \"lipidomics\") mexp$analysis_type #> [1] \"lipidomics\" mexp$title #> [1] \"Test Experiment\" mexp$annot_analyses #> # A tibble: 0 × 13 #> # ℹ 13 variables: analysis_order <int>, analysis_id <chr>, sample_id <chr>, #> #   qc_type <fct>, batch_id <chr>, replicate_no <int>, specimen <chr>, #> #   sample_amount <dbl>, sample_amount_unit <chr>, istd_volume <dbl>, #> #   valid_analysis <lgl>, annot_order_num <int>, remarks <chr>"},{"path":"https://slinghub.github.io/midar/reference/correct_batch_centering.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch Centering Correction — correct_batch_centering","title":"Batch Centering Correction — correct_batch_centering","text":"function performs batch centering correction feature. Optionally, scale batches can equalized across batches. selected QC types (ref_qc_types) used calculate medians, used align samples. correction can applied one three variables: \"intensity\", \"norm_intensity\", \"conc\". correction can either applied top previous corrections replace prior batch corrections.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_batch_centering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch Centering Correction — correct_batch_centering","text":"","code":"correct_batch_centering(   data = NULL,   variable,   ref_qc_types,   correct_scale = FALSE,   replace_previous = TRUE,   log_transform_internal = TRUE,   replace_exisiting_trendcurves = FALSE,   ... )"},{"path":"https://slinghub.github.io/midar/reference/correct_batch_centering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch Centering Correction — correct_batch_centering","text":"data MidarExperiment object containing data corrected. object must include information QC types measurements. variable variable corrected. Must one \"intensity\", \"norm_intensity\", \"conc\". ref_qc_types character vector specifying QC types used references batch centering. correct_scale logical value indicating whether equalize scale batches addition center . Defaults FALSE. replace_previous logical value indicating whether replace previous batch corrections apply new correction top. Defaults TRUE (replace). log_transform_internal logical value indicating whether log-transform data internally correction. Defaults TRUE. replace_exisiting_trendcurves logical value indicating whether replace trend curves previous corrections. use plotting using plot_runscatter(). Default FALSE. ... Additional arguments can passed batch correction function.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_batch_centering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch Centering Correction — correct_batch_centering","text":"MidarExperiment object containing corrected data.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"function corrects run-order drifts within across batches using cubic spline smoothing. correction typically based QC (Quality Control) samples measured specific intervals throughout run sequence. smoothed curve derived QC samples used adjust samples dataset. correction can applied \"intensity\", \"norm_intensity\", \"conc\" data. cubic spline smoothing approach, particularly used regularization parameter lambda, similar identical previously described QC-based drift correction methods, QC-RSC (Quality Control Regularized Spline Correction), described Dunn et al. (Nat Protoc, 2011) Kirwan et al. (Anal Bioanal Chem, 2014). default, smoothing parameter determined using cross-validation, can lead overfitting. reduce overfitting regularization parameter lambda may defined, good starting point lambda = 0.01. Additionally, global smoothing parameter can specified via spar. recommended visually inspect correction using plot_runscatter() function. Set argument recalc_trend_after = TRUE trends correction also available plotting. details, refer description plot_runscatter(). corrections can applied batch--batch basis (batch_wise = TRUE, default) across batches (batch_wise = FALSE). Existing corrections either replaced (replace_previous = TRUE) added top (replace_previous = FALSE). Furthermore, drift correction can applied unconditionally (conditional_correction = FALSE) conditionally, based whether sample CV change correction defined threshold (cv_diff_threshold). conditional correction assessed independently batch batch_wise = TRUE, median CV changes across batch compared threshold. Note: function outputs message indicating median CV change mean absolute CV correction samples. However, metrics experimental used definitive criteria correction (see Details ). cubic spline method implemented using base R function","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"","code":"correct_drift_cubicspline(   data = NULL,   variable,   ref_qc_types,   batch_wise = TRUE,   ignore_istd = TRUE,   replace_previous = TRUE,   cv = TRUE,   spar = NULL,   lambda = NULL,   penalty = 1,   conditional_correction = FALSE,   recalc_trend_after = FALSE,   log_transform_internal = TRUE,   feature_list = NULL,   cv_diff_threshold = 0,   use_original_if_fail = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"data MidarExperiment object variable variable corrected drift effects. Must one \"intensity\", \"norm_intensity\", \"conc\" ref_qc_types QC types used drift correction batch_wise Logical. Apply correction batch separately (TRUE, default) across batches (FALSE). ignore_istd Logical. Exclude internal standards (ISTDs) correction TRUE. replace_previous Logical. Replace existing correction (TRUE, default) layer top (FALSE). cv Ordinary leave-one-(TRUE) ‘generalized’ cross-validation (GCV) FALSE; used smoothing parameter computation spar specified spar Smoothing parameter cubic spline smoothing. specified NULL, smoothing parameter computed using specified cv method. Typically (necessarily) (0,1]. lambda Regularization parameter cubic spline smoothing. Default 0, means regularization. penalty coefficient penalty degrees freedom GCV criterion. conditional_correction Determines whether drift correction applied features unconditionally (TRUE) conditionally, based sample CV change. recalc_trend_after Recalculate trend post-drift correction plot_qc_runscatter(). double calculation time. log_transform_internal Log transform data correction TRUE (default). Note: log transformation solely applied internally smoothing, results log-transformed. feature_list Subset features correction whose names match specified text using regular expression. Default NULL. cv_diff_threshold Maximum allowable change CV ratio smoothing correction applied. use_original_if_fail Determines action smoothing fails results invalid values feature. FALSE (default), result feature NA batches, TRUE, original data kept.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"output message, median CV change computed median CV changes features global correction features correction passed defined CV difference treshold case conditional correction  (conditional_correction = FALSE). batch-wise correction, change calculated per batch, final median CV change median batch medians across features.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_cubicspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Drift Correction by Cubic Spline Smoothing — correct_drift_cubicspline","text":"Dunn, W., Broadhurst, D., Begley, P. et al. Procedures large-scale metabolic profiling serum plasma using gas chromatography liquid chromatography coupled mass spectrometry. Nat Protoc 6, 1060–1083 (2011). https://doi.org/10.1038/nprot.2011.335 Kirwan, J.., Broadhurst, D.., Davidson, R.L. et al. Characterising correcting batch variation automated direct infusion mass spectrometry (DIMS) metabolomics workflow. Anal Bioanal Chem 405, 5147–5157 (2013). https://doi-org.libproxy1.nus.edu.sg/10.1007/s00216-013-6856-7","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","title":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","text":"function corrects run-order drifts within across batches using Generalized Additive Models (GAMs). correction uses penalized splines, automatic selection smoothing parameters based cross-validation penalized likelihood. typically based QC (Quality Control) samples measured specific intervals throughout run sequence. correction can applied \"intensity\", \"norm_intensity\", \"conc\" data. recommended visually inspect correction using plot_runscatter() function. Set argument recalc_trend_after = TRUE trends correction also available plotting. details, refer description plot_runscatter(). corrections can applied batch--batch basis (batch_wise = TRUE, default) across batches (batch_wise = FALSE). Existing corrections either replaced (replace_previous = TRUE) added top (replace_previous = FALSE). Furthermore, drift correction can applied unconditionally (conditional_correction = FALSE) conditionally, based whether sample CV change correction defined threshold (cv_diff_threshold). conditional correction assessed independently batch batch_wise = TRUE, median CV changes across batch compared threshold. Note: function outputs message indicating median CV change mean absolute CV correction samples. However, metrics experimental used definitive criteria correction (see Details ). cubic spline method implemented using base R function stats::spline().","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","text":"","code":"correct_drift_gam(   data = NULL,   variable,   ref_qc_types,   batch_wise = TRUE,   ignore_istd = TRUE,   replace_previous = TRUE,   bs = \"ps\",   k = -1,   sp = NULL,   log_transform_internal = TRUE,   conditional_correction = FALSE,   recalc_trend_after = FALSE,   feature_list = NULL,   cv_diff_threshold = 0,   use_original_if_fail = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","text":"data MidarExperiment object variable variable corrected drift effects. Must one \"intensity\", \"norm_intensity\", \"conc\" ref_qc_types QC types used drift correction batch_wise Logical. Apply correction batch separately (TRUE, default) across batches (FALSE). ignore_istd Logical. Exclude internal standards (ISTDs) correction TRUE. replace_previous Logical. Replace existing correction (TRUE, default) layer top (FALSE). bs Basis type spline: \"ps\" (penalized spline, default) \"tp\" (thin plate spline). k Number basis functions (default: -1, automatically chosen GAM). sp Smoothing parameter (NULL default, estimated automatically). log_transform_internal Log transform data correction TRUE (default). Note: log transformation solely applied internally smoothing, results log-transformed. conditional_correction Determines whether drift correction applied features unconditionally (TRUE) conditionally, based sample CV change. recalc_trend_after Recalculate trend post-drift correction plot_qc_runscatter(). double calculation time. feature_list Subset features correction whose names match specified text using regular expression. Default NULL. cv_diff_threshold Maximum allowable change CV ratio smoothing correction applied. use_original_if_fail Determines action smoothing fails results invalid values feature. FALSE (default), result feature NA batches, TRUE, original data kept.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drift Correction by Generalized Additive Model (GAM) Smoothing — correct_drift_gam","text":"output message, median CV change computed median CV changes features global correction features correction passed defined CV difference treshold case conditional correction  (conditional_correction = FALSE). batch-wise correction, change calculated per batch, final median CV change median batch medians across features. smoothing based Generalized Additive Models (GAM) using penalized splines, implemented via mgcv::gam().","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"Performs drift correction run-order effects within across batches using Gaussian kernel smoothing, detailed Teo et al. (2020). Gaussian kernel estimates local data trend, bandwidth defined kernel_size parameter. smoothing approach mostly used study samples applied datasets sufficiently randomized stratified samples avoid local biases artifacts. smoothing can applied  concentration, norm_intensity, intensity data. Corrections can applied batch--batch basis (batch_wise = TRUE, default) across batches (batch_wise = FALSE). correction can either replace existing drift batch corrections (replace_previous = TRUE, default) applied top existing corrections (replace_previous = FALSE`). Drift correction can applied features (conditional_correction = FALSE) conditionally, based whether sample CV difference correction defined threshold (cv_diff_threshold). conditional correction applied separately batch batch_wise = TRUE, . recommended visually inspect correction using plot_runscatter() function. Set argument recalc_trend_after = TRUE trends correction also available plotting. details, refer description plot_runscatter(). double processing time. Note: function outputs message indicating median CV change mean absolute CV correction samples. However, metrics experimental used definitive criteria correction (see Details ).","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"","code":"correct_drift_gaussiankernel(   data = NULL,   variable,   ref_qc_types,   batch_wise = TRUE,   ignore_istd = TRUE,   replace_previous = TRUE,   kernel_size = 10,   outlier_filter = FALSE,   outlier_ksd = 5,   location_smooth = TRUE,   scale_smooth = FALSE,   log_transform_internal = TRUE,   conditional_correction = FALSE,   cv_diff_threshold = 0,   recalc_trend_after = FALSE,   feature_list = NULL,   use_original_if_fail = FALSE,   show_progress = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"data MidarExperiment object. variable target variable drift correction; options include \"intensity\", \"norm_intensity\", \"conc\". ref_qc_types QC types used drift correction, typically including study samples (SPL). batch_wise Logical. Apply correction batch separately (TRUE, default) across batches (FALSE). ignore_istd Logical. Exclude internal standards (ISTDs) correction TRUE. replace_previous Logical. Replace existing correction (TRUE, default) layer top (FALSE). kernel_size Numeric. Defines Gaussian kernel's bandwidth. outlier_filter Logical. Enable kernel outlier filtering TRUE. outlier_ksd Numeric. Set kernel's k times standard deviation outlier detection. location_smooth Logical. Apply smoothing location parameter TRUE. scale_smooth Logical. Apply smoothing scale parameter TRUE. log_transform_internal Logical. Conduct log transformation internally enhanced outlier robustness TRUE (default); alter output data. conditional_correction Determines whether drift correction applied features unconditionally (TRUE) difference sample CV vs smoothing threshold specified cv_diff_threshold. cv_diff_threshold parameter defines maximum allowable change (difference) coefficient variation (CV) ratio samples smoothing correction applied. value 0 (default) requires CV improve, value 0 allows CV also become worse maximum defined difference. recalc_trend_after Logical. Recalculate trends post-smoothing visualization (e.g., plot_runscatter()). feature_list Character vector. Regular expression pattern select specific features correction. Default NULL features. use_original_if_fail Determines action smoothing fails results invalid values feature. FALSE (default), result feature NA batches, TRUE, original data kept. show_progress Logical. Display progress bars TRUE; disable notebook rendering setting FALSE.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"Returns MidarExperiment object.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"output message, median CV change computed median CV changes features global correction features correction passed defined CV difference treshold case conditional correction  (conditional_correction = FALSE). batch-wise correction, change calculated per batch, final median CV change median batch medians across features.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_gaussiankernel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Drift Correction by Gaussian Kernel Smoothing — correct_drift_gaussiankernel","text":"Teo G., Chew WS, Burla B, Herr D, Tai ES, Wenk MR, Torta F, & Choi H (2020). MRMkit: Automated Data Processing Large-Scale Targeted Metabolomics Analysis. Analytical Chemistry, 92(20), 13677–13682. https://doi.org/10.1021/acs.analchem.0c03060","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_loess.html","id":null,"dir":"Reference","previous_headings":"","what":"Drift Correction by LOESS Smoothing — correct_drift_loess","title":"Drift Correction by LOESS Smoothing — correct_drift_loess","text":"function corrects run-order drifts within across batches using LOESS (Locally Estimated Scatterplot Smoothing). correction typically based QC (Quality Control) samples measured specific intervals throughout run sequence. smoothed curve derived QC samples used adjust samples dataset. correction can applied \"intensity\", \"norm_intensity\", \"conc\" data. degree smoothing controlled span parameter span (default 0.75). Additionally, degree parameter can specified control degree polynomial used local regression (default 2) recommended visually inspect correction using plot_runscatter() function. Set argument recalc_trend_after = TRUE trends correction also available plotting. details, refer description plot_runscatter(). LOESS correction applies samples lie within span QC samples used smoothing. Extrapolation outside range recommended, can lead unreliable corrections artefacts extrapolated regions. However, extrapolation can activated setting extrapolate = TRUE. may useful cases specific drifts occur segments analysis sequence spanned QC samples, analysis interrupted instrument rapid changes performance. corrections can applied batch--batch basis (batch_wise = TRUE, default) across batches (batch_wise = FALSE). Existing corrections either replaced (replace_previous = TRUE) added top (replace_previous = FALSE). Furthermore, drift correction can applied unconditionally (conditional_correction = FALSE) conditionally, based whether sample CV change correction defined threshold (cv_diff_threshold). conditional correction assessed independently batch batch_wise = TRUE, median CV changes across batch compared threshold. Note: function outputs message indicating median CV change mean absolute CV correction samples. However, metrics experimental used definitive criteria correction (see Details ). LOESS method implemented using base R function stats::loess().","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_loess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drift Correction by LOESS Smoothing — correct_drift_loess","text":"","code":"correct_drift_loess(   data = NULL,   variable,   ref_qc_types,   batch_wise = TRUE,   ignore_istd = TRUE,   replace_previous = TRUE,   conditional_correction = FALSE,   recalc_trend_after = FALSE,   log_transform_internal = TRUE,   feature_list = NULL,   cv_diff_threshold = 0,   use_original_if_fail = FALSE,   extrapolate = FALSE,   span = 0.75,   degree = 2 )"},{"path":"https://slinghub.github.io/midar/reference/correct_drift_loess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drift Correction by LOESS Smoothing — correct_drift_loess","text":"data MidarExperiment object variable variable corrected drift effects. Must one \"intensity\", \"norm_intensity\", \"conc\" ref_qc_types QC types used drift correction batch_wise Logical. Apply correction batch separately (TRUE, default) across batches (FALSE). ignore_istd apply corrections ISTDs replace_previous Logical. Replace existing correction (TRUE, default) layer top (FALSE). conditional_correction Determines whether drift correction applied features unconditionally (TRUE) difference sample CV vs smoothing threshold specified cv_diff_threshold. recalc_trend_after Recalculate trend post-drift correction plot_qc_runscatter(). double calculation time. log_transform_internal Log transform data correction TRUE (default). Note: log transformation solely applied internally smoothing, results log-transformed. Log transformation may result robust smoothing less sensitive outlier. feature_list Subset features correction whose names matches specified text using regular expression. Default NULL means features selected. cv_diff_threshold parameter defines maximum allowable change (difference) coefficient variation (CV) ratio samples smoothing correction applied. value 0 (default) requires CV improve, value 0 allows CV also become worse maximum defined difference. use_original_if_fail Determines action smoothing fails results invalid values feature. FALSE (default), result feature NA batches, TRUE, original data kept. extrapolate Extrapolate loess smoothing. WARNING: generally recommended extrapolate outside range spanned QCs used smoothing. See details . span Loess span width (default 0.75) degree Degree polynomial used loess smoothing, normally 1 (default) 2","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_loess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drift Correction by LOESS Smoothing — correct_drift_loess","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_drift_loess.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drift Correction by LOESS Smoothing — correct_drift_loess","text":"output message, median CV change computed median CV changes features global correction features correction passed defined CV difference treshold case conditional correction  (conditional_correction = FALSE). batch-wise correction, change calculated per batch, final median CV change median batch medians across features.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interference_manual.html","id":null,"dir":"Reference","previous_headings":"","what":"Manual isotopic interference correction — correct_interference_manual","title":"Manual isotopic interference correction — correct_interference_manual","text":"interference subtracted using following formula: $$Value_{Corrected} = Value_{Feature} - Factor_{Contribution} * Value_{Interfering Feature}$$","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interference_manual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manual isotopic interference correction — correct_interference_manual","text":"","code":"correct_interference_manual(   data = NULL,   variable,   feature,   interfering_feature,   interference_contribution,   neg_to_na = FALSE,   updated_feature_id = NA )"},{"path":"https://slinghub.github.io/midar/reference/correct_interference_manual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manual isotopic interference correction — correct_interference_manual","text":"data MidarExperiment object variable Default: feature_intensity. Name Variable corrected. feature Name feature corrected interfering_feature Name feature interfering, .e. contributing signal feature interference_contribution Relative portion interfering feature contribute feature signal. Must 0 1. neg_to_na TRUE, negative zero values correction replaced NA. Default: FALSE. updated_feature_id Optional. New name corrected feature. empty feature name change.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interference_manual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manual isotopic interference correction — correct_interference_manual","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply interference correction — correct_interferences","title":"Apply interference correction — correct_interferences","text":"function corrects lipidomics feature intensities subtracting interference (e.g., isotope overlap -source fragments). correction applied using following formula: $$value\\_corrected = value\\_raw - value\\_raw\\_interfering\\_feature \\times proportion\\_interference$$ interfering features relative contributions must defined feature metadata. default, sequential series interferences (e.g., isotopic M+2 interferences PC 34:2 > PC 34:“1 > PC 34:0) corrected sequential manner. means correction applied iteratively, starting downstream feature series. disable behavior, basing correction raw signal interfering feature set sequential_correction = FALSE","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply interference correction — correct_interferences","text":"","code":"correct_interferences(   data = NULL,   variable = \"feature_intensity\",   sequential_correction = TRUE,   neg_to_na = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply interference correction — correct_interferences","text":"data MidarExperiment object containing lipidomics data. variable Name variable corrected. Default: feature_intensity. sequential_correction logical indicating whether apply corrections sequentially, starting downstream feature.  FALSE, corrections based raw signal interfering features. FALSE, correction based raw signal interfering feature. neg_to_na TRUE, negative zero values correction replaced NA. Default: FALSE.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply interference correction — correct_interferences","text":"MidarExperiment object feature intensities corrected interferences.","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply interference correction — correct_interferences","text":"isotopic interference correction MRM/PRM data, relative isotope abundances needed calculation ('proportion_interference') can calculated using LICAR application (Gao et al., 2021), see ..","code":""},{"path":"https://slinghub.github.io/midar/reference/correct_interferences.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Apply interference correction — correct_interferences","text":"Gao L., Ji S, Burla B, Wenk MR, Torta F, Wenk MR, & Cazenave-Gassiot (2021). LICAR: Application Isotopic Correction Targeted Lipidomic Data Acquired Class-Based Chromatographic Separations Using Multiple Reaction Monitoring. Analytical Chemistry, 93(6), 3163-3171. https://doi.org/10.1021/acs.analchem.0c04565","code":""},{"path":"https://slinghub.github.io/midar/reference/cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Percent coefficient of variation (%CV) — cv","title":"Percent coefficient of variation (%CV) — cv","text":"function computes percent coefficient variation  values x. na.rm TRUE missing values removed computation proceeds.","code":""},{"path":"https://slinghub.github.io/midar/reference/cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Percent coefficient of variation (%CV) — cv","text":"","code":"cv(x, na.rm = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Percent coefficient of variation (%CV) — cv","text":"x numeric vector untransformed data na.rm logical, TRUE NA values stripped x computation takes place","code":""},{"path":"https://slinghub.github.io/midar/reference/cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Percent coefficient of variation (%CV) — cv","text":"numeric value. x contains zero numeric, NA_real_ returned","code":""},{"path":"https://slinghub.github.io/midar/reference/cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Percent coefficient of variation (%CV) — cv","text":"","code":"cv(c(5, 6, 3, 4, 5, NA), na.rm = TRUE) #> [1] 24.78642"},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"Computes percent coefficient variation (CV) based log-transformation input data. can robust certain cases, especially data normally distributed.","code":""},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"","code":"cv_log(x, na.rm = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"x numeric vector untransformed data na.rm logical, TRUE NA values stripped x computation takes place","code":""},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"numeric value. x contains zero, NaN returned. x numeric, NA_real_ returned","code":""},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"Canchola et al. (2017) Correct use percent coefficient variation (% CV) formula log-transformed data. MOJ Proteomics Bioinform. 2017;6(4):316‒317. DOI: 10.15406/mojpb.2017.06.00200","code":""},{"path":"https://slinghub.github.io/midar/reference/cv_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Percent coefficient of variation (%CV) based on log-transformation — cv_log","text":"","code":"cv_log(c(5, 6, 3, 4, 5, NA), na.rm = TRUE) #> [1] 27.082"},{"path":"https://slinghub.github.io/midar/reference/data_load_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Load an example MidarExperiment dataset — data_load_example","title":"Load an example MidarExperiment dataset — data_load_example","text":"Load example MidarExperiment dataset. Dataset 1 small dataset (Burla et al, 2024, see ) Dataset 2 larger dataset (Tan et al, 2022).See Details .","code":""},{"path":"https://slinghub.github.io/midar/reference/data_load_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load an example MidarExperiment dataset — data_load_example","text":"","code":"data_load_example(data = NULL, dataset = 1)"},{"path":"https://slinghub.github.io/midar/reference/data_load_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load an example MidarExperiment dataset — data_load_example","text":"data MidarExperiment object, optional. Data overwritten provided. dataset Dataset type. Either 1 2. Default 1.","code":""},{"path":"https://slinghub.github.io/midar/reference/data_load_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load an example MidarExperiment dataset — data_load_example","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/data_load_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load an example MidarExperiment dataset — data_load_example","text":"","code":"myexp <- MidarExperiment() myexp <- data_load_example(myexp) myexp #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 499 #> • Features: 29 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✔ #> • Response curves: ✔ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/detect_outlier.html","id":null,"dir":"Reference","previous_headings":"","what":"Get list of analyses classified as technical outliers — detect_outlier","title":"Get list of analyses classified as technical outliers — detect_outlier","text":"Retrieves analysis IDs data outliers based  principal components PCA SD MAD fences","code":""},{"path":"https://slinghub.github.io/midar/reference/detect_outlier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get list of analyses classified as technical outliers — detect_outlier","text":"","code":"detect_outlier(   data = NULL,   variable,   filter_data,   qc_types = c(\"BQC\", \"TQC\", \"SPL\"),   pca_component,   fence_multiplicator,   summarize_fun = c(\"pca\", \"rma\"),   outlier_detection = c(\"sd\", \"mad\"),   log_transform = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/detect_outlier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get list of analyses classified as technical outliers — detect_outlier","text":"data MidarExperiment object variable Feature variable used outlier detection filter_data Use (default) qc-filtered data qc_types QC types included outlier detection pca_component PCA component used fence_multiplicator Multiplicator SD MAD, respectively. summarize_fun Function used summarize features, either \"pca\" based PCA, \"rma\" based mean relative abundance (RMA) features outlier_detection Outlier detection method, either based \"sd\" \"mad\" log_transform Log-transform data outlier detection","code":""},{"path":"https://slinghub.github.io/midar/reference/detect_outlier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get list of analyses classified as technical outliers — detect_outlier","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_analyses.html","id":null,"dir":"Reference","previous_headings":"","what":"Exclude analyses from the dataset — exclude_analyses","title":"Exclude analyses from the dataset — exclude_analyses","text":"function excludes specified analyses MidarExperiment object, either marking invalid downstream processing. function also alloows reset exclusions.","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_analyses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exclude analyses from the dataset — exclude_analyses","text":"","code":"exclude_analyses(data = NULL, analyses, clear_existing)"},{"path":"https://slinghub.github.io/midar/reference/exclude_analyses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exclude analyses from the dataset — exclude_analyses","text":"data MidarExperiment object analyses character vector analysis IDs (case-sensitive) excluded dataset. NA empty vector, exclusion behavior handled set via clear_existing flag. clear_existing logical value. TRUE, existing valid_analysis flags overwritten. FALSE, exclusions appended, preserving existing invalidated analyses.","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_analyses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exclude analyses from the dataset — exclude_analyses","text":"modified MidarExperiment object specified analyses defined excluded.","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Exclude features from the dataset — exclude_features","title":"Exclude features from the dataset — exclude_features","text":"function excludes specified features MidarExperiment object, either marking invalid downstream processing. function also alloows reset exclusions.","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exclude features from the dataset — exclude_features","text":"","code":"exclude_features(data = NULL, features, clear_existing)"},{"path":"https://slinghub.github.io/midar/reference/exclude_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exclude features from the dataset — exclude_features","text":"data MidarExperiment object features character vector feature IDs (case-sensitive) excluded dataset. NA empty vector, exclusion behavior handled set via clear_existing flag. clear_existing logical value. TRUE, existing valid_analysis flags overwritten. FALSE, exclusions appended, preserving existing invalidated features","code":""},{"path":"https://slinghub.github.io/midar/reference/exclude_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exclude features from the dataset — exclude_features","text":"modified MidarExperiment object specified analyses defined excluded.","code":""},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Filtering Based on QC Criteria — filter_features_qc","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"Filters dataset based quality control (QC) criteria, including intensity, coefficient variation (CV), signal--blank ratios, D-ratio, response curve properties, proportion missing values. Criteria apply different QC types (BQC, TQC) measurement variables (concentration, intensity, normalized intensity). clear existing filters, run filter_features_qc() clear_existing = TRUE without filtering criteria.","code":""},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"","code":"filter_features_qc(   data = NULL,   clear_existing = TRUE,   use_batch_medians = FALSE,   include_qualifier,   include_istd,   features.to.keep = NA,   max.prop.missing.intensity.spl = NA,   max.prop.missing.normintensity.spl = NA,   max.prop.missing.conc.spl = NA,   min.intensity.lowest.bqc = NA,   min.intensity.lowest.tqc = NA,   min.intensity.lowest.spl = NA,   min.intensity.median.bqc = NA,   min.intensity.median.tqc = NA,   min.intensity.median.spl = NA,   min.intensity.highest.spl = NA,   min.signalblank.median.spl.pblk = NA,   min.signalblank.median.spl.ublk = NA,   min.signalblank.median.spl.sblk = NA,   max.cv.intensity.bqc = NA,   max.cv.intensity.tqc = NA,   max.cv.normintensity.bqc = NA,   max.cv.normintensity.tqc = NA,   max.cv.conc.bqc = NA,   max.cv.conc.tqc = NA,   response.curves.selection = NA,   response.curves.summary = NA,   min.rsquare.response = NA,   min.slope.response = NA,   max.slope.response = NA,   max.yintercept.response = NA,   max.dratio.sd.conc.bqc = NA,   max.dratio.sd.conc.tqc = NA,   max.dratio.mad.conc.bqc = NA,   max.dratio.mad.conc.tqc = NA,   max.dratio.sd.normint.bqc = NA,   max.dratio.sd.normint.tqc = NA,   max.dratio.mad.normint.bqc = NA,   max.dratio.mad.normint.tqc = NA )"},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"data MidarExperiment object. clear_existing Logical. TRUE, replaces existing filters; FALSE, adds new filters top existing ones. Default TRUE. use_batch_medians Logical. TRUE, uses batch-wise median QC values filtering. Default FALSE. include_qualifier Logical. TRUE, includes qualifier features filtering process. include_istd Logical. TRUE, includes internal standards (ISTDs) filtering process. features..keep vector feature identifiers retain, even meet filtering criteria. max.prop.missing.intensity.spl Maximum proportion missing intensity values among study samples (SPL). Default NA. max.prop.missing.normintensity.spl Maximum proportion missing normalized intensity values among study samples (SPL). Default NA. max.prop.missing.conc.spl Maximum proportion missing concentration values among study samples (SPL). Default NA. min.intensity.lowest.bqc Minimum intensity lowest BQC sample. Default NA. min.intensity.lowest.tqc Minimum intensity lowest TQC sample. Default NA. min.intensity.lowest.spl Minimum intensity lowest study sample (SPL). Default NA. min.intensity.median.bqc Minimum median intensity BQC samples. Default NA. min.intensity.median.tqc Minimum median intensity TQC samples. Default NA. min.intensity.median.spl Minimum median intensity study samples (SPL). Default NA. min.intensity.highest.spl Minimum intensity highest intensity study sample (SPL). Default NA. min.signalblank.median.spl.pblk Minimum signal--blank ratio SPL samples PBLK. Default NA. min.signalblank.median.spl.ublk Minimum signal--blank ratio SPL samples UBLK. Default NA. min.signalblank.median.spl.sblk Minimum signal--blank ratio SPL samples SBLK. Default NA. max.cv.intensity.bqc Maximum CV intensity BQC samples. Default NA. max.cv.intensity.tqc Maximum CV intensity TQC samples. Default NA. max.cv.normintensity.bqc Maximum CV normalized intensity BQC samples. Default NA. max.cv.normintensity.tqc Maximum CV normalized intensity TQC samples. Default NA. max.cv.conc.bqc Maximum CV concentration BQC samples. Default NA. max.cv.conc.tqc Maximum CV concentration TQC samples. Default NA. response.curves.selection Select specific response curves ID. Default NA. response.curves.summary Define method summarize multiple response curves. Default NA. min.rsquare.response Minimum R-squared value response curves. Default NA. min.slope.response Minimum slope response curve. Default NA. max.slope.response Maximum slope response curve. Default NA. max.yintercept.response Maximum y-intercept response curve. Default NA. max.dratio.sd.conc.bqc Maximum allowed D-ratio (SD BQC / SD SPL) using standard deviation BQC samples. Default NA. max.dratio.sd.conc.tqc Maximum allowed D-ratio (SD TQC / SD SPL) using standard deviation TQC samples. Default NA. max.dratio.mad.conc.bqc Maximum allowed D-ratio (MAD BQC / MAD SPL) using mean absolute deviation BQC samples. Default NA. max.dratio.mad.conc.tqc Maximum allowed D-ratio (MAD TQC / MAD SPL) using mean absolute deviation TQC samples. Default NA. max.dratio.sd.normint.bqc Maximum allowed D-ratio (SD normalized intensity BQC / SD SPL) using standard deviation. Default NA. max.dratio.sd.normint.tqc Maximum allowed D-ratio (SD normalized intensity TQC / SD SPL) using standard deviation. Default NA. max.dratio.mad.normint.bqc Maximum allowed D-ratio (MAD normalized intensity BQC / MAD SPL) using mean absolute deviation. Default NA. max.dratio.mad.normint.tqc Maximum allowed D-ratio (MAD normalized intensity TQC / MAD SPL) using mean absolute deviation. Default NA.","code":""},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"input MidarExperiment object feature filtering criteria applied.","code":""},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"function implements filtering criteria based quality control (QC) samples additional analytical parameters, following recommendations outlined Broadhurst et al. (2018). implemented criteria evaluate data quality analysis QC samples, blanks, study samples.","code":""},{"path":"https://slinghub.github.io/midar/reference/filter_features_qc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Feature Filtering Based on QC Criteria — filter_features_qc","text":"Broadhurst, D., Goodacre, R., Reinke, S. N., Kuligowski, J., Wilson, . D., Lewis, M. R., & Dunn, W. B. (2018). Guidelines considerations use system suitability quality control samples mass spectrometry assays applied clinical studies. Metabolomics, 14(6), 72. doi:10.1007/s11306-018-1367-3","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_correct_drift.html","id":null,"dir":"Reference","previous_headings":"","what":"Drift Correction by Custom Function — fun_correct_drift","title":"Drift Correction by Custom Function — fun_correct_drift","text":"Function correct run-order drifts within across batches via provided custom function #' @details drift correction function needs provided user. See smooth_fun details.","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_correct_drift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drift Correction by Custom Function — fun_correct_drift","text":"","code":"fun_correct_drift(   data = NULL,   smooth_fun,   variable,   ref_qc_types,   batch_wise,   replace_previous = TRUE,   log_transform_internal = TRUE,   conditional_correction = FALSE,   cv_diff_threshold = 0,   use_original_if_fail = TRUE,   ignore_istd = TRUE,   feature_list = NULL,   recalc_trend_after = FALSE,   show_progress = TRUE,   ... )"},{"path":"https://slinghub.github.io/midar/reference/fun_correct_drift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drift Correction by Custom Function — fun_correct_drift","text":"data MidarExperiment object smooth_fun Function performs drift correction. Function need following parameter data (MidarExperiment), ref_qc_types (one strings), span_width (numerical). Function needs return numerical vector length number rows data. case functions fails vector NA_real_ needs returned variable variable corrected drift effects. Must one \"intensity\", \"norm_intensity\", \"conc\" ref_qc_types QC types used drift correction batch_wise Apply batch separately TRUE (default) replace_previous Logical. Replace previous correction (TRUE), adds top previous correction (FALSE). Default TRUE. log_transform_internal Apply log transformation internally smoothing TRUE (default). enhances robustness outliers affect final data, remains untransformed. conditional_correction Determines whether drift correction applied features unconditionally (TRUE) difference sample CV vs smoothing threshold specified cv_diff_threshold. cv_diff_threshold parameter defines maximum allowable change (difference) coefficient variation (CV) ratio samples smoothing correction applied. value 0 (default) requires CV improve, value 0 allows CV also become worse maximum defined difference. use_original_if_fail Determines action smoothing fails results invalid values feature. TRUE (default), original data used; FALSE, result analysis NA. ignore_istd apply corrections ISTDs feature_list Sets specific features correction . Can character vector regular expression. Default NULL means features selected. recalc_trend_after Recalculate trend post-drift correction plot_qc_runscatter(). double calculation time. show_progress Show progress bar. Default = `TRUE. ... Arguments specific smoothing function","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_correct_drift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drift Correction by Custom Function — fun_correct_drift","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_cspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Cubic spline smoothing helper function — fun_cspline","title":"Cubic spline smoothing helper function — fun_cspline","text":"Function cubic spline-based smoothing optional cross-validation, use fun_correct_drift","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_cspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cubic spline smoothing helper function — fun_cspline","text":"","code":"fun_cspline(tbl, ref_qc_types, log_transform_internal, ...)"},{"path":"https://slinghub.github.io/midar/reference/fun_cspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cubic spline smoothing helper function — fun_cspline","text":"tbl Table (tibble data.frame) containing fields qc_type, x (run order number), y (variable) ref_qc_types QC types used smoothing (fit) cubic spline log_transform_internal Apply log transformation internally smoothing TRUE (default). affect final data, remains untransformed. ... Additional arguments forwarded smooth.spline","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_cspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cubic spline smoothing helper function — fun_cspline","text":"List data.frame containing original x smoothed y values, boolean value indicating whether fit failed .","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gam_smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Additive Model (GAM) smoothing helper function — fun_gam_smooth","title":"Generalized Additive Model (GAM) smoothing helper function — fun_gam_smooth","text":"Function penalized spline-based smoothing using GAM, use fun_correct_drift","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gam_smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Additive Model (GAM) smoothing helper function — fun_gam_smooth","text":"","code":"fun_gam_smooth(tbl, ref_qc_types, log_transform_internal = TRUE, ...)"},{"path":"https://slinghub.github.io/midar/reference/fun_gam_smooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Additive Model (GAM) smoothing helper function — fun_gam_smooth","text":"tbl Table (tibble data.frame) containing fields qc_type, x (run order number), y (variable) ref_qc_types QC types used smoothing (fit) GAM log_transform_internal Apply log transformation internally smoothing TRUE (default). affect final data, remains untransformed. ... Additional arguments forwarded mgcv::gam","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gam_smooth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Additive Model (GAM) smoothing helper function — fun_gam_smooth","text":"List data.frame containing original x smoothed y values, boolean value indicating whether fit failed .","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gauss.kernel.smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","title":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","text":"Function Gaussian kernel-based smoothing, use fun_correct_drift.","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gauss.kernel.smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","text":"","code":"fun_gauss.kernel.smooth(tbl, ref_qc_types, log_transform_internal, ...)"},{"path":"https://slinghub.github.io/midar/reference/fun_gauss.kernel.smooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","text":"tbl Table (tibble data.frame) containing fields qc_type, x (run order number), y (variable) ref_qc_types QC types used smoothing (fit) loess log_transform_internal Apply log transformation internally smoothing TRUE (default). affect final data, remains untransformed. ... Additional arguments","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gauss.kernel.smooth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","text":"List data.frame containing original x smoothed y values, boolean value indicting whether fit failed .","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_gauss.kernel.smooth.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gaussian Kernel smoothing helper function — fun_gauss.kernel.smooth","text":"Hyung Won Choi","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_loess.html","id":null,"dir":"Reference","previous_headings":"","what":"Loess smoothing helper function — fun_loess","title":"Loess smoothing helper function — fun_loess","text":"Function loess-based smoothing, use fun_correct_drift","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_loess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loess smoothing helper function — fun_loess","text":"","code":"fun_loess(tbl, ref_qc_types, log_transform_internal, ...)"},{"path":"https://slinghub.github.io/midar/reference/fun_loess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loess smoothing helper function — fun_loess","text":"tbl Table (tibble data.frame) containing fields qc_type, x (run order number), y (variable) ref_qc_types QC types used smoothing (fit) loess log_transform_internal Apply log transformation internally smoothing TRUE (default). affect final data, remains untransformed. ... Additional arguments forwarded Loess","code":""},{"path":"https://slinghub.github.io/midar/reference/fun_loess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loess smoothing helper function — fun_loess","text":"List data.frame containing original x smoothed y values, boolean value indicting whether fit failed .","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_end.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the end time of the analysis sequence — get_analyis_end","title":"Get the end time of the analysis sequence — get_analyis_end","text":"Returns end time analysis, corresponding last acquisition_time_stamp dataset. Note: estimate_analysis_end set FALSE, function return timestamp last analysis dataset, corresping start last analysis. Set estimate_analysis_end TRUE estimate end time analysis sequence, based median runtime.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_end.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the end time of the analysis sequence — get_analyis_end","text":"","code":"get_analyis_end(data, estimate_sequence_end)"},{"path":"https://slinghub.github.io/midar/reference/get_analyis_end.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the end time of the analysis sequence — get_analyis_end","text":"data MidarExperiment object estimate_sequence_end TRUE, function estimate end time analysis sequence based median runtime. FALSE return start time last analysis sequence.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_end.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the end time of the analysis sequence — get_analyis_end","text":"POSIXct timestamp, NA_POSIXct_ dataset empty.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_start.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the start time of the analysis sequence — get_analyis_start","title":"Get the start time of the analysis sequence — get_analyis_start","text":"Returns start time analysis, corresponding earliest acquisition_time_stamp dataset.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_start.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the start time of the analysis sequence — get_analyis_start","text":"","code":"get_analyis_start(data)"},{"path":"https://slinghub.github.io/midar/reference/get_analyis_start.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the start time of the analysis sequence — get_analyis_start","text":"data MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyis_start.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the start time of the analysis sequence — get_analyis_start","text":"POSIXct timestamp, NA_POSIXct_ dataset empty.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of analysis breaks in the analysis — get_analysis_breaks","title":"Get the number of analysis breaks in the analysis — get_analysis_breaks","text":"Counts number interruptions analysis, interruption defined time gap consecutive acquisition timestamps exceeds given threshold (break_duration_minutes).","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of analysis breaks in the analysis — get_analysis_breaks","text":"","code":"get_analysis_breaks(data, break_duration_minutes)"},{"path":"https://slinghub.github.io/midar/reference/get_analysis_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of analysis breaks in the analysis — get_analysis_breaks","text":"data MidarExperiment object break_duration_minutes numeric value specifying minimum duration (minutes) two consecutive analyses qualifies interruption.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of analysis breaks in the analysis — get_analysis_breaks","text":"integer number interruptions, NA_integer_ dataset empty.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of analyses in the dataset — get_analysis_count","title":"Get the number of analyses in the dataset — get_analysis_count","text":"Returns number analyses dataset, optional filter based qc_types.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of analyses in the dataset — get_analysis_count","text":"","code":"get_analysis_count(data, qc_types = NULL)"},{"path":"https://slinghub.github.io/midar/reference/get_analysis_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of analyses in the dataset — get_analysis_count","text":"data MidarExperiment object qc_types Defines qc_types counted. NULL NA, analyses counted.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of analyses in the dataset — get_analysis_count","text":"integer analysis count","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_duration.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the total duration of the analysis — get_analysis_duration","title":"Get the total duration of the analysis — get_analysis_duration","text":"function returns total duration analysis, time difference timestamps first last analyses sequence.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_duration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the total duration of the analysis — get_analysis_duration","text":"","code":"get_analysis_duration(data, estimate_sequence_end)"},{"path":"https://slinghub.github.io/midar/reference/get_analysis_duration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the total duration of the analysis — get_analysis_duration","text":"data MidarExperiment object estimate_sequence_end TRUE, function estimate end time analysis sequence based median runtime, added timestamp last analysis. FALSE, function calculate time difference first last analysis timestamps without adjustment.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analysis_duration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the total duration of the analysis — get_analysis_duration","text":"estimate_sequence_end TRUE, function estimate end time analysis sequence adding median runtime timestamp last analysis, instead simply using timestamp last analysis.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyticaldata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the annotated or the originally imported analytical data — get_analyticaldata","title":"Get the annotated or the originally imported analytical data — get_analyticaldata","text":"Get annotated originally imported analytical data","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyticaldata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the annotated or the originally imported analytical data — get_analyticaldata","text":"","code":"get_analyticaldata(data = NULL, annotated)"},{"path":"https://slinghub.github.io/midar/reference/get_analyticaldata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the annotated or the originally imported analytical data — get_analyticaldata","text":"data MidarExperiment object annotated Boolean indicating whether return annotated data (FALSE) original imported data (TRUE)","code":""},{"path":"https://slinghub.github.io/midar/reference/get_analyticaldata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the annotated or the originally imported analytical data — get_analyticaldata","text":"tibble analytical data long format","code":""},{"path":"https://slinghub.github.io/midar/reference/get_batch_boundaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the start and end analysis numbers of specified batches — get_batch_boundaries","title":"Get the start and end analysis numbers of specified batches — get_batch_boundaries","text":"Sets analysis order (sequence) based either () analysis timestamp, available, (ii) order analysis appeared imported raw data file, (iii) order analyses defined Analysis metadata.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_batch_boundaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the start and end analysis numbers of specified batches — get_batch_boundaries","text":"","code":"get_batch_boundaries(data = NULL, batch_indices = NULL)"},{"path":"https://slinghub.github.io/midar/reference/get_batch_boundaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the start and end analysis numbers of specified batches — get_batch_boundaries","text":"data MidarExperiment object batch_indices numeric vector one two elements, representing first /last batch index (.e., sequential batch number). NULL invalid, function abort.#' @return vector two elements: lower upper analysis number specified batch(es).","code":""},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Calibration Metrics — get_calibration_metrics","title":"Get Calibration Metrics — get_calibration_metrics","text":"Extracts calibration fit metrics MidarExperiment object.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Calibration Metrics — get_calibration_metrics","text":"","code":"get_calibration_metrics(   data = NULL,   with_lod = TRUE,   with_loq = TRUE,   with_bias = TRUE,   with_coefficients = TRUE,   with_sigma = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Calibration Metrics — get_calibration_metrics","text":"data MidarExperiment object QC metrics. with_lod Whether include LoD output. Default TRUE. with_loq Whether include LoQ output. Default TRUE. with_bias Whether include bias output. Default TRUE. with_coefficients Whether include regression coefficients. Default TRUE. with_sigma Whether include sigma output. Default TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Calibration Metrics — get_calibration_metrics","text":"tibble exported calibration metrics.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Calibration Metrics — get_calibration_metrics","text":"Requires prior computation regression results using calc_calibration_results(). See documentation details.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_calibration_metrics.html","id":"returned-details-and-metrics","dir":"Reference","previous_headings":"","what":"Returned Details and Metrics","title":"Get Calibration Metrics — get_calibration_metrics","text":"feature_id: Feature identifier. is_quantifier: Logical, indicates feature quantifier. fit_model: Regression model used fitting. weighting: Weighting method used fitting. lowest_cal: Lowest nonzero calibration concentration. highest_cal: Highest  calibration concentration. r.squared: R-squared value, indicating goodness fit. coef_a: Slope regression line (linear) coefficient quadratic term (x^2) (quadratic). coef_b: Intercept regression line (linear) coefficient linear term (x) (quadratic). coef_c: Intercept regression equation (quadratic). Set NA linear models. sigma: Residual standard error model. reg_failed: TRUE regression fitting failed. LoD = 3× sample standard error residuals / slope regression. LoQ = 10× sample standard error residuals / slope regression. Note: LoD/LoQ calculations, slope used formula calculated lowest nonzero calibration point quadratic fits.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_feature_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of features in the dataset — get_feature_count","title":"Get the number of features in the dataset — get_feature_count","text":"Returns number features dataset, optional filters whether counted features must internal standard /quantifier.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_feature_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of features in the dataset — get_feature_count","text":"","code":"get_feature_count(data, is_istd = NA, is_quantifier = NA)"},{"path":"https://slinghub.github.io/midar/reference/get_feature_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of features in the dataset — get_feature_count","text":"data MidarExperiment object is_istd set, defines whether include exclude internal standard features. Default NA means filter internal standards applied. is_quantifier set, defines whether include exclude qualifier features. Default NA means filter qualifier features applied.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_feature_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of features in the dataset — get_feature_count","text":"integer feature count","code":""},{"path":"https://slinghub.github.io/midar/reference/get_featurelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature IDs — get_featurelist","title":"Get feature IDs — get_featurelist","text":"Returns vector annotated feature IDs (feature_id) present dataset","code":""},{"path":"https://slinghub.github.io/midar/reference/get_featurelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature IDs — get_featurelist","text":"","code":"get_featurelist(data, is_istd = NA, is_quantifier = NA)"},{"path":"https://slinghub.github.io/midar/reference/get_featurelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature IDs — get_featurelist","text":"data MidarExperiment object is_istd set, defines whether include exclude internal standard features. Default NA means filter internal standards applied. is_quantifier set, defines whether include exclude qualifier features. Default NA means filter qualifier features applied.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_featurelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get feature IDs — get_featurelist","text":"character vector feature_id values","code":""},{"path":"https://slinghub.github.io/midar/reference/get_lipid_class_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get lipid class, species and transition names — get_lipid_class_names","title":"Get lipid class, species and transition names — get_lipid_class_names","text":"function retrieves lipid class, species transition names feature_id column adds columns dataset.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_lipid_class_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get lipid class, species and transition names — get_lipid_class_names","text":"","code":"get_lipid_class_names(   data = NULL,   use_as_feature_class = \"lipid_class\",   add_transition_names = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/get_lipid_class_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get lipid class, species and transition names — get_lipid_class_names","text":"data MidarExperiment object use_as_feature_class Set feature_class lipid_class add_transition_names add transition name transition group, based information square brackets feature_id","code":""},{"path":"https://slinghub.github.io/midar/reference/get_lipid_class_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get lipid class, species and transition names — get_lipid_class_names","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/get_mad_tails.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MAD-based tails — get_mad_tails","title":"Get MAD-based tails — get_mad_tails","text":"Computes lower upper boundaries based Median Absolute Deviation (MAD) numeric vector. Returns c(NA_real_, NA_real_) input vector less 2 elements.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_mad_tails.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MAD-based tails — get_mad_tails","text":"","code":"get_mad_tails(x, k, na.rm = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/get_mad_tails.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MAD-based tails — get_mad_tails","text":"x numeric vector k multiplier MAD na.rm TRUE NA values stripped x computation takes place.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_mad_tails.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MAD-based tails — get_mad_tails","text":"numeric vector length 2 lower upper boundaries.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_mad_tails.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get MAD-based tails — get_mad_tails","text":"","code":"x <- c(-100,1, 2, 3, 4, 100) k <- 1.5 get_mad_tails(x, k) #> [1] 1 4"},{"path":"https://slinghub.github.io/midar/reference/get_qc_bias_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Calibration Regression Results — get_qc_bias_variability","title":"Retrieve Calibration Regression Results — get_qc_bias_variability","text":"function retrieves calibration curve regression results MidarExperiment object. returns summary quality control (QC) metrics specified QC samples. including bias, percentage bias, intra-assay coefficient variation (CV). standard deviation bias percentage bias also included unless NA analytes, .e. replicates measured.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_qc_bias_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Calibration Regression Results — get_qc_bias_variability","text":"","code":"get_qc_bias_variability(   data,   qc_types = NA,   wide_format = \"none\",   include_qualifier = FALSE,   with_conc = TRUE,   with_bias = TRUE,   with_bias_perc = TRUE,   with_cv_intra = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/get_qc_bias_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Calibration Regression Results — get_qc_bias_variability","text":"data MidarExperiment object containing dataset necessary annotations calibration analysis. qc_types character vector specifying QC types include results, addition CAL. specified, applicable QC types included default. wide_format Format output table. Must one \"none\", \"features\", \"samples\". \"none\", output long format. \"features\", output wide format features columns. \"samples\", output wide format samples columns. include_qualifier Logical. TRUE, includes qualifier features results. Defaults FALSE. with_conc Logical. TRUE, includes target measured mean concentrations results. Defaults TRUE. with_bias Logical. TRUE, includes bias concentration units results. Defaults TRUE. with_bias_perc Logical. TRUE, includes percentage bias results. Defaults TRUE. with_cv_intra Logical. TRUE, includes intra-assay coefficient variation (CV) results. Defaults TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_qc_bias_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Calibration Regression Results — get_qc_bias_variability","text":"data frame containing calibration results, including metrics bias, percentage bias, intra-assay CV based specified parameters.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_qc_bias_variability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve Calibration Regression Results — get_qc_bias_variability","text":"function uses data MidarExperiment object filters according specified QC types parameters. calculates summary statistics feature, bias CV, organizes data user-specified format.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_response_curve_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Regression Statistics of Response Curves — get_response_curve_stats","title":"Linear Regression Statistics of Response Curves — get_response_curve_stats","text":"function calculates linear regression statistics (R-squared, slope, intercept) response curve provided MidarExperiment object. Optionally, can include additional statistics lancer package (installed) with_staturation_stats set TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_response_curve_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Regression Statistics of Response Curves — get_response_curve_stats","text":"","code":"get_response_curve_stats(   data = NULL,   with_staturation_stats = FALSE,   limit_to_rqc = FALSE,   silent_invalid_data = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/get_response_curve_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Regression Statistics of Response Curves — get_response_curve_stats","text":"data MidarExperiment object containing dataset response curve annotations. with_staturation_stats Logical, TRUE, include additional statistics lancer package. Note: lancer package must installed argument set TRUE. limit_to_rqc Logical, TRUE (default), include rows qc_type == \"RQC\". silent_invalid_data Logical, TRUE suppresses raising error required data metadata missing, mismatch .","code":""},{"path":"https://slinghub.github.io/midar/reference/get_response_curve_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Regression Statistics of Response Curves — get_response_curve_stats","text":"tibble linear regression statistics (r2, slopenorm, y0norm) curve, NULL data matches criteria.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_runtime_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the median run time — get_runtime_median","title":"Get the median run time — get_runtime_median","text":"Calculates median run time (seconds) based timestamps differences consecutive analyses sequence.","code":""},{"path":"https://slinghub.github.io/midar/reference/get_runtime_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the median run time — get_runtime_median","text":"","code":"get_runtime_median(data)"},{"path":"https://slinghub.github.io/midar/reference/get_runtime_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the median run time — get_runtime_median","text":"data MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/get_runtime_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the median run time — get_runtime_median","text":"lubridate time period object, NA dataset empty.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"(Depreciated) Import Wide CSV Files — import_data_csv","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"(Depreciated) Import Wide CSV Files","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"","code":"import_data_csv(   data = NULL,   path,   variable_name,   analysis_id_col = NA,   import_metadata = TRUE,   first_feature_column = NA,   na_strings = \"NA\" )"},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"data MidarExperiment object path One file names path, folder path, case *.csv files folder read. variable_name Variable type representing values table. Must one \"intensity\", \"norm_intensity\", \"conc\", \"area\", \"height\", \"response\") analysis_id_col Column used analysis_id. NA (default) used 'analysis_id' present, first column contains unique values. import_metadata Import additional metadata columns (e.g. batch ID, sample type) add MidarExperiment object. following metadata column names supported: \"qc_type\", \"batch_id\", \"is_quantifier\", \"is_istd\", \"analysis_order\" first_feature_column Column number first column representing feature values na_strings character vector strings interpreted NA values. Blank fields also considered missing values.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"function deprecated. Please use import_data_csv_wide() instead.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Depreciated) Import Wide CSV Files — import_data_csv","text":"","code":"file_path <- system.file(\"extdata\", \"plain_wide_dataset.csv\", package = \"midar\")  mexp <- MidarExperiment()  mexp <- import_data_csv(   data = mexp,   path = file_path,  variable_name = \"conc\",  import_metadata = TRUE) #> ! The function import_data_csv is deprecated. Please use import_data_csv_wide instead. #> ℹ Metadata column(s) 'qc_type, batch_id' imported. To ignore, set `import_metadata = FALSE` #> ✔ Imported 87 analyses with 5 features #> ✔ Analysis metadata associated with 87 analyses. #> ✔ Feature metadata associated with 5 features. #> ℹ Analysis order was based on `analysis_order` column of imported data. Use `set_analysis_order` to change the order.  print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw CONC values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 87 #> • Features: 5 #> • Raw signal used for processing: `feature_conc` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✔ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"function imports analysis results CSV files long table format, row represents unique observation feature-value pair analysis (sample), along associated feature variables metadata. See \"Details\" information using function.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"","code":"import_data_csv_long(   data = NULL,   path,   import_metadata = TRUE,   column_mapping = NULL,   na_strings = \"NA\",   warn_unrecognized_columns = TRUE,   silent = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"data MidarExperiment object imported data added. path single file path, multiple file paths, directory path. directory provided, *.csv files within imported. import_metadata Logical indicating whether import additional metadata columns (e.g., batch ID, sample type) MidarExperiment object. Supported metadata column names include \"qc_type\", \"batch_id\", \"is_quantifier\", \"is_istd\", \"analysis_order\". column_mapping named character vector mapping internal column names CSV column names. include keys \"analysis_id\", \"feature_id\", feature variable names. NULL (default), function attempts automatic detection. na_strings Character vector strings interpret missing values (NA). Blank fields always treated missing. warn_unrecognized_columns Logical indicating whether issue warning unknown columns encountered dataset. silent Logical indicating whether suppress notifications messages.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"MidarExperiment object containing imported data.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"column mapping provided via column_mapping argument, function automatically detect import columns following names: Detection columns case-insensitive. Additionally, feature variable columns use internal naming convention prefixes \"feature_\" \"method_\" (e.g. feature_area instead area), function detect import automatically. import data different column names, provide named vector mapping CSV column names internal column names used MidarExperiment. mapping format: c(\"analysis_id\" = \"[CSV column name analysis]\", \"feature_id\" = \"[CSV column name feature]\", ...), right-hand side refers exact column name CSV file header. Columns matching internal names require mapping imported automatically. mapping case-insensitive. Note dataset must contain analysis identifier, either analysis_id column via mapped column. function processes CSV files specified directory given file(s), combining single dataset. supports datasets split across multiple files preprocessing. feature raw data file pair appear avoid duplication. na_strings parameter allows specifying character strings interpreted NA, ensuring proper handling missing values.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Analysis Results from Long Format CSV Files — import_data_csv_long","text":"","code":"file_path <- system.file(\"extdata\", \"plain_long_dataset.csv\", package = \"midar\") mexp <- MidarExperiment()  # Define the column mapping; right side is the CSV column name col_map <- c(   \"analysis_id\" = \"raw_data_filename\",   \"qc_type\" = \"qc_type\",   \"feature_id\" = \"feature_id\",   \"feature_class\" = \"feature_class\",   \"istd_feature_id\" = \"istd_feature_id\",   \"feature_rt\" = \"rt\",   \"feature_area\" = \"area\" )  mexp <- import_data_csv_long(   data = mexp,   path = file_path,   column_mapping = col_map,   import_metadata = TRUE ) #> ! Following unrecognized columns present in the data and were ignored: \"internal_standard\", \"time_stamp\", \"batch\", \"sample_type\", \"precursor_mz\", \"product_mz\", \"collision_energy\", \"polarity\", \"rt_apex\", \"area_normalized\", \"concentration\", \"height\", \"fwhm\", \"rt_int_start\", and \"rt_int_end\". #> ! Use argument `column_mapping` to define column mapping. #> ✔ Imported 3 analyses with 4 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 3 analyses. #> ✔ Feature metadata associated with 4 features. #> ℹ Analysis order was based on `analysis_order` column of imported data. Use `set_analysis_order` to change the order.  print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 3 #> • Features: 4 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"Imports analysis result data wide-format .csv files, row corresponds unique analysis-feature pair columns contain analysis- feature-specific variables.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"","code":"import_data_csv_wide(   data = NULL,   path,   variable_name,   analysis_id_col = NA,   import_metadata = TRUE,   first_feature_column = NA,   na_strings = \"NA\" )"},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"data MidarExperiment object. path file path vector file paths, directory path. directory provided, .csv files within read. variable_name character string specifying variable type contained data. Must one \"intensity\", \"norm_intensity\", \"conc\", \"area\", \"height\", \"response\". analysis_id_col column name index used analysis_id. Defaults NA, case \"analysis_id\" used present; otherwise, first column used contains unique values. import_metadata Logical indicating whether import additional metadata columns (e.g., batch ID, sample type) MidarExperiment object. Supported metadata columns : \"qc_type\", \"batch_id\", \"is_quantifier\", \"is_istd\", \"analysis_order\". first_feature_column Integer indicating column number feature value columns start. na_strings Character vector strings interpret NA values. Blank fields also treated NA.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"MidarExperiment object containing imported dataset.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"dataset must include two identifier columns: \"analysis_id\" \"feature_id\", pair values unique across table. Additionally, table must contain least one feature variable column, \"area\", \"height\", \"intensity\", \"norm_intensity\", \"response\", \"conc\", \"rt\", \"fwhm\". downstream functions may require specific columns among present. variable_name argument specifies data type represented table, must one : \"area\", \"height\", \"intensity\", \"norm_intensity\", \"response\", \"conc\", \"conc_raw\", \"rt\", \"fwhm\". column named analysis_id, inferred first column, provided contains unique values. import_metadata set TRUE, following metadata columns imported present: analysis_order qc_type batch_id is_quantifier prevent additional non-metadata columns misinterpreted features, use first_feature_column parameter specify column feature data starts. directory path provided path, .csv files directory processed merged single dataset. facilitates handling datasets split multiple files preprocessing. Ensure feature raw data file pair appears avoid duplication errors. na_strings parameter allows specifying character strings interpreted missing values (NA). Blank fields also treated missing.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_csv_wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Analysis Results from Plain Wide-Format CSV Files — import_data_csv_wide","text":"","code":"file_path <- system.file(\"extdata\", \"plain_wide_dataset.csv\", package = \"midar\") mexp <- MidarExperiment() mexp <- import_data_csv_wide(   data = mexp,   path = file_path,   variable_name = \"conc\",   import_metadata = TRUE ) #> ℹ Metadata column(s) 'qc_type, batch_id' imported. To ignore, set `import_metadata = FALSE` #> ✔ Imported 87 analyses with 5 features #> ✔ Analysis metadata associated with 87 analyses. #> ✔ Feature metadata associated with 5 features. #> ℹ Analysis order was based on `analysis_order` column of imported data. Use `set_analysis_order` to change the order. print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw CONC values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 87 #> • Features: 5 #> • Raw signal used for processing: `feature_conc` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✔ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_data_masshunter.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","title":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","text":"Imports .csv files exported Agilent MassHunter Quantitative Analysis software, containing peak integration results. input files must anlyses (samples) rows, features/compounds columns, either peak areas, peak heights, response values. Additional columns, retention time (RT), full-width half-maximum (FWHM), precursor m/z (PrecursorMZ), collision energy (CE), also imported made available MidarExperiment object downstream analyses. directory path provided, matching .csv files directory imported merged single dataset. useful importing datasets pre-processed blocks, resulting multiple files. unique combination feature raw data file must occur across source data files. Duplicate combinations result error.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_masshunter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","text":"","code":"import_data_masshunter(   data = NULL,   path,   import_metadata = TRUE,   expand_qualifier_names = TRUE,   conc_column = \"conc_final\",   silent = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_data_masshunter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","text":"data MidarExperiment object path One file paths, directory path (case matching files imported) import_metadata Logical, whether extract add metadata analysis result file expand_qualifier_names Logical, whether add quantifier name front qualifier name (latter m/z transition values) conc_column concentration field masshunter data use, case \"Calc. Conc.\" \"Final. Conc.\" present.  Default \"conc_final\". Must one \"conc_calc\" \"conc_final\" (default). silent Logical, whether suppress notifications","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_masshunter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","text":"MidarExperiment object imported data","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_masshunter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Agilent MassHunter Quantitative Analysis CSV files — import_data_masshunter","text":"","code":"mexp <- MidarExperiment() file_path = system.file(\"extdata\", \"MHQuant_demo.csv\", package = \"midar\")  mexp <- import_data_masshunter(   data = mexp,   path = file_path,   import_metadata = TRUE,   expand_qualifier_names = TRUE) #> ✔ Imported 38 analyses with 31 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 38 analyses. #> ✔ Feature metadata associated with 31 features.  print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 38 #> • Features: 31 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_data_mrmkit.html","id":null,"dir":"Reference","previous_headings":"","what":"Import MRMkit peak integration results — import_data_mrmkit","title":"Import MRMkit peak integration results — import_data_mrmkit","text":"Imports tabular data files (*.tsv) generated MRMkit containing peak integration results. input files must long format columns raw data file name, feature ID, peak intensity, arguments Additional information, retention time, FWHM, precursor/product m/z, CE also imported made available MidarExperiment object downstream analyses. Concentrations also imported present, whereby Calc. Conc. Final Conc. present files, argument conc_column can used specify concentration field 'concentration' use downstream analyses. directory path provided, matching files directory imported merged single dataset. useful importing datasets pre-processed blocks, resulting multiple files. unique combination feature raw data file must occur across source data files. Duplicate combinations result error.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_mrmkit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import MRMkit peak integration results — import_data_mrmkit","text":"","code":"import_data_mrmkit(data = NULL, path, import_metadata = TRUE, silent = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/import_data_mrmkit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import MRMkit peak integration results — import_data_mrmkit","text":"data MidarExperiment object path One file paths, directory path (case matching files imported) import_metadata Logical, whether import additional metadata columns (e.g., batch_id, qc_type) silent Logical, whether suppress notifications","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_mrmkit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import MRMkit peak integration results — import_data_mrmkit","text":"MidarExperiment object imported data","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_mrmkit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import MRMkit peak integration results — import_data_mrmkit","text":"","code":"mexp <- MidarExperiment()  file_path = system.file(\"extdata\", \"MRMkit_demo.tsv\", package = \"midar\")  mexp <- import_data_mrmkit(   data = mexp,   path = file_path,   import_metadata = TRUE) #> ✔ Imported 499 analyses with 28 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features. print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 499 #> • Features: 28 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Skyline Peak Integration Results — import_data_skyline","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"function imports tabular data files (*.csv) exported Skyline, containing peak integration results.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"","code":"import_data_skyline(   data = NULL,   path,   transition_id_columns = c(\"name\", \"mz\", \"none\"),   import_metadata = TRUE,   silent = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"data MidarExperiment object. path One file paths, directory path matching files imported. transition_id_columns character vector specifying columns define transition (precursor product) use unique feature_id generation. Options \"name\", \"mz\", \"none\". \"none\", feature_id derived Molecule Name Precursor Name Product Name. \"mz\", feature_id based Precursor Mz Product Mz. Using \"none\" result feature_id copy Molecule Name, error raised unique transition. import_metadata Logical; whether import additional metadata columns (e.g., precursor/product m/z values). silent Logical; whether suppress notifications.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"MidarExperiment object containing imported data.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"Skyline, transitions defined Molecule Name corresponding precursor product m/z values, rather identifier. importing data, feature_id generated using Molecule Name either precursor/product names m/z values, unless Molecule Name uniquely identifies features (refer transition_id_columns argument ). following supported columns Skyline can imported: *Requirements columns described transition_id_columns. export results Skyline, use 'Molecule Transition Results' format include Replicate Name, Molecule Name, either Precursor Mz/Product Mz Precursor Name/Product Name columns. least one feature variable, Area RT, must also exported.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_data_skyline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Skyline Peak Integration Results — import_data_skyline","text":"","code":"mexp <- MidarExperiment() file_path <- system.file(\"extdata\", \"Skyline_MoleculeTransitionResults.csv\", package = \"midar\") mexp <- import_data_skyline(   data = mexp,   path = file_path,   transition_id_columns = \"mz\",   import_metadata = TRUE ) #> ✔ Imported 6 analyses with 21 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 6 analyses. #> ✔ Feature metadata associated with 21 features. #> ℹ Analysis order was based on `analysis_order` column of imported data. Use `set_analysis_order` to change the order. print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 6 #> • Features: 21 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_analyses.html","id":null,"dir":"Reference","previous_headings":"","what":"Import analysis metadata — import_metadata_analyses","title":"Import analysis metadata — import_metadata_analyses","text":"Imports analysis metadata (annotation) preloaded data frame tibble via data argument, data file (CSV Excel) via path argument. analysis metadata must contain following columns: analysis_id qc_type. Additional analysis metadata columns described details .","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_analyses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import analysis metadata — import_metadata_analyses","text":"","code":"import_metadata_analyses(   data = NULL,   table = NULL,   path = NULL,   sheet = NULL,   ignore_warnings = FALSE,   excl_unmatched_analyses = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_analyses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import analysis metadata — import_metadata_analyses","text":"data MidarExperiment object table data frame tibble analysis (sample) metadata. path also provided, error raised. path character string specifying path CSV (.csv) Excel (.xlsx) file. table also provided, error raised. sheet Defines sheet name case Excel file provided. ignore_warnings Ignore warnings data validation proceed importing metadata excl_unmatched_analyses Exclude analyses (samples) matching metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_analyses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import analysis metadata — import_metadata_analyses","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_analyses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import analysis metadata — import_metadata_analyses","text":"","code":"mexp <- MidarExperiment() file_path = system.file(\"extdata\", \"MHQuant_demo.csv\", package = \"midar\") mexp <- import_data_masshunter(   data = mexp,   path = file_path,   import_metadata = FALSE) #> ✔ Imported 38 analyses with 31 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`.  meta_path = system.file(\"extdata\", \"MHQuant_demo_metadata_analyses.csv\", package = \"midar\")  mexp <- import_metadata_analyses(   data = mexp,   path = meta_path,   excl_unmatched_analyses = TRUE) #> ✔ Analysis metadata associated with 38 analyses.  print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 38 #> • Features: 31 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✖ #> • Internal standards: ✖ #> • Response curves: ✖ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Import feature metadata — import_metadata_features","title":"Import feature metadata — import_metadata_features","text":"Imports analysis metadata (annotation) preloaded data frame tibble via data argument,  data file (CSV Excel) via path argument. analysis metadata must contain following columns: analysis_id qc_type. Additional analysis metadata columns described details .","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import feature metadata — import_metadata_features","text":"","code":"import_metadata_features(   data = NULL,   table = NULL,   path = NULL,   sheet = NULL,   ignore_warnings = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import feature metadata — import_metadata_features","text":"data MidarExperiment object table data frame tibble analysis (sample) metadata. path also provided, error raised. path character string specifying path CSV (.csv) Excel (.xlsx) file. table also provided, error raised. sheet Defines sheet name case Excel file provided. ignore_warnings Ignore warnings data validation proceed importing metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import feature metadata — import_metadata_features","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_from_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Metadata from Imported Analysis Data — import_metadata_from_data","title":"Retrieve Metadata from Imported Analysis Data — import_metadata_from_data","text":"Retrieves available metadata imported analysis data associates provided MidarExperiment object.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_from_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Metadata from Imported Analysis Data — import_metadata_from_data","text":"","code":"import_metadata_from_data(data = NULL, qc_type_column_name = \"qc_type\")"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_from_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Metadata from Imported Analysis Data — import_metadata_from_data","text":"data MidarExperiment object qc_type_column_name Column name imported raw data representing qc_type","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_from_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Metadata from Imported Analysis Data — import_metadata_from_data","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_istds.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Internal Standards (ISTD) metadata — import_metadata_istds","title":"Import Internal Standards (ISTD) metadata — import_metadata_istds","text":"Imports ISTD metadata (annotation) preloaded data frame tibble via data argument, data file (CSV Excel) via path argument. analysis metadata must contain following columns: istd_feature_id one istd_conc_nmolar istd_conc_ngml.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_istds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Internal Standards (ISTD) metadata — import_metadata_istds","text":"","code":"import_metadata_istds(   data = NULL,   table = NULL,   path = NULL,   sheet = NULL,   ignore_warnings = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_istds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Internal Standards (ISTD) metadata — import_metadata_istds","text":"data MidarExperiment object table data frame tibble analysis (sample) metadata. path also provided, error raised. path character string specifying path CSV (.csv) Excel (.xlsx) file. table also provided, error raised. sheet Defines sheet name case Excel file provided. ignore_warnings Ignore warnings data validation proceed importing metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_istds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Internal Standards (ISTD) metadata — import_metadata_istds","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_msorganiser.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","title":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","text":"Imports metadata 'MIDAR Metadata Organizer' file (.xlsm/.xlsx) file associates analysis data.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_msorganiser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","text":"","code":"import_metadata_msorganiser(   data = NULL,   path,   ignore_warnings = FALSE,   excl_unmatched_analyses = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_msorganiser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","text":"data MidarExperiment object path File name path 'MIDAR Metadata Organizer' file (.xlsm/.xlsx) file ignore_warnings Ignore warnings data validation proceed importing metadata excl_unmatched_analyses Exclude analyses (samples) matching metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_msorganiser.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_msorganiser.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Metadata from a MIDAR Metadata Organizer file — import_metadata_msorganiser","text":"","code":"mexp <- MidarExperiment()  mexp <- import_data_mrmkit(   data = mexp,   path = system.file(\"extdata\", \"MRMkit_demo.tsv\", package = \"midar\"),   import_metadata = TRUE) #> ✔ Imported 499 analyses with 28 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features.  mexp <- import_metadata_msorganiser(  data = mexp,  path = system.file(\"extdata\", \"Example_Metadata_1.xlsm\", package = \"midar\"),  excl_unmatched_analyses = FALSE,  ignore_warnings = TRUE) #> ! Metadata has following warnings and notifications: #> -------------------------------------------------------------------------------------------- #>   Type Table    Column                Issue                           Count #> 1 W*   Analyses analysis_id           Analyses not in analysis data      15 #> 2 W*   Features feature_id            Feature(s) not in analysis data   321 #> 3 W*   Features feature_id            Feature(s) without metadata         1 #> 4 W*   ISTDs    quant_istd_feature_id Internal standard(s) not used       2 #> -------------------------------------------------------------------------------------------- #> E = Error, W = Warning, W* = Supressed Warning, N = Note #> -------------------------------------------------------------------------------------------- #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 27 features. #> ✔ Internal Standard metadata associated with 15 ISTDs. #> ✔ Response curve metadata associated with 12 annotated analyses.  print(mexp) #>  #> ── MidarExperiment ───────────────────────────────────────────────────────────── #> Title: #>  #> Processing status: Annotated raw AREA values #>  #> ── Annotated Raw Data ── #>  #> • Analyses: 499 #> • Features: 27 #> • Raw signal used for processing: `feature_area` #>  #> ── Metadata ── #>  #> • Analyses/samples: ✔ #> • Features/analytes: ✔ #> • Internal standards: ✔ #> • Response curves: ✔ #> • Calibrants/QC concentrations: ✖ #> • Study samples: ✖ #>  #> ── Processing Status ── #>  #> • Isotope corrected: ✖ #> • ISTD normalized: ✖ #> • ISTD quantitated: ✖ #> • Drift corrected variables: ✖ #> • Batch corrected variables: ✖ #> • Feature filtering applied: ✖ #>  #> ── Exclusion of Analyses and Features ── #>  #> • Analyses manually excluded (`analysis_id`): ✖ #> • Features manually excluded (`feature_id`): ✖"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_qcconcentrations.html","id":null,"dir":"Reference","previous_headings":"","what":"Import calibration curves metadata — import_metadata_qcconcentrations","title":"Import calibration curves metadata — import_metadata_qcconcentrations","text":"Imports calibration curve metadata (annotation) preloaded data frame tibble via data argument, data file (CSV Excel) via path argument. analysis metadata must contain following columns: analysis_id, curve_id, feature_id, concentration, concentration_unit.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_qcconcentrations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import calibration curves metadata — import_metadata_qcconcentrations","text":"","code":"import_metadata_qcconcentrations(   data = NULL,   table = NULL,   path = NULL,   sheet = NULL,   ignore_warnings = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_qcconcentrations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import calibration curves metadata — import_metadata_qcconcentrations","text":"data MidarExperiment object table data frame tibble calibration curve metadata. path also provided, error raised. path character string specifying path CSV (.csv) Excel (.xlsx) file. table also provided, error raised. sheet Defines sheet name case Excel file provided. ignore_warnings Ignore warnings data validation proceed importing metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_qcconcentrations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import calibration curves metadata — import_metadata_qcconcentrations","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_responsecurves.html","id":null,"dir":"Reference","previous_headings":"","what":"Import response curves metadata — import_metadata_responsecurves","title":"Import response curves metadata — import_metadata_responsecurves","text":"Imports response curve metadata (annotation) preloaded data frame tibble via data argument, data file (CSV Excel) via path argument. analysis metadata must contain following columns: analysis_id, curve_id, analyzed_amount analyzed_amount_unit.","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_responsecurves.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import response curves metadata — import_metadata_responsecurves","text":"","code":"import_metadata_responsecurves(   data = NULL,   table = NULL,   path = NULL,   sheet = NULL,   ignore_warnings = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/import_metadata_responsecurves.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import response curves metadata — import_metadata_responsecurves","text":"data MidarExperiment object table data frame tibble response curve metadata. path also provided, error raised. path character string specifying path CSV (.csv) Excel (.xlsx) file. table also provided, error raised. sheet Defines sheet name case Excel file provided. ignore_warnings Ignore warnings data validation proceed importing metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/import_metadata_responsecurves.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import response curves metadata — import_metadata_responsecurves","text":"updated MidarExperiment object","code":""},{"path":"https://slinghub.github.io/midar/reference/lipidomics_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Plasma Lipidomics Dataset with Metadata — lipidomics_dataset","title":"Plasma Lipidomics Dataset with Metadata — lipidomics_dataset","text":"demo dataset included use function examples user testing.. small, preprocessed subset plasma lipidomics dataset, containing raw peak areas analytical metadata. original dataset published Tan et al., ATVB, 2022.","code":""},{"path":"https://slinghub.github.io/midar/reference/lipidomics_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plasma Lipidomics Dataset with Metadata — lipidomics_dataset","text":"","code":"lipidomics_dataset"},{"path":"https://slinghub.github.io/midar/reference/lipidomics_dataset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Plasma Lipidomics Dataset with Metadata — lipidomics_dataset","text":"MidarExperiment object following data metadata: dataset_orig tibble containing original peak data. dataset tibble annotated lipidomics data. annot_analyses Analysis-level metadata annot_features Feature-level metadata annot_batches Batch annotations. annot_istds ISTD concentrations annot_responsecurves Response curves metadata","code":""},{"path":"https://slinghub.github.io/midar/reference/midar-package.html","id":null,"dir":"Reference","previous_headings":"","what":"midar: Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting — midar-package","title":"midar: Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting — midar-package","text":"'midar' package offers R functions processing, quality control, visualization lipidomics mass spectrometry data.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/midar-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"midar: Small Molecule Mass Spectrometry Data Post-Processing, Quality Control, Exploration and Reporting — midar-package","text":"Maintainer: Bo Burla bo.burla@nus.edu.sg (ORCID)","code":""},{"path":"https://slinghub.github.io/midar/reference/normalize_by_istd.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize Feature Intensities Using Internal Standards — normalize_by_istd","title":"Normalize Feature Intensities Using Internal Standards — normalize_by_istd","text":"Normalize feature intensities dividing intensities corresponding internal standards (ISTDs). feature must defined internal standard (ISTD) feature metadata.","code":""},{"path":"https://slinghub.github.io/midar/reference/normalize_by_istd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize Feature Intensities Using Internal Standards — normalize_by_istd","text":"","code":"normalize_by_istd(data = NULL, ignore_missing_annotation = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/normalize_by_istd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize Feature Intensities Using Internal Standards — normalize_by_istd","text":"data MidarExperiment object. ignore_missing_annotation FALSE, function raise error ISTD defined one features (excluding ISTDs ). TRUE, features missing ISTD annotations NA values normalized intensities.","code":""},{"path":"https://slinghub.github.io/midar/reference/normalize_by_istd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize Feature Intensities Using Internal Standards — normalize_by_istd","text":"MidarExperiment object normalized feature intensities","code":""},{"path":"https://slinghub.github.io/midar/reference/order_chained_columns_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","title":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","text":"function orders rows data frame based chained relationships defined two columns. can also handle fully disconnected rows (.e., rows values present rows). behavior disconnected rows controlled via disconnected_action parameter.","code":""},{"path":"https://slinghub.github.io/midar/reference/order_chained_columns_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","text":"","code":"order_chained_columns_tbl(   df,   from_col,   to_col,   include_chain_id,   disconnected_action = \"keep\" )"},{"path":"https://slinghub.github.io/midar/reference/order_chained_columns_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","text":"df data frame containing chain relationships. from_col string specifying column name representing starting point chain. to_col string specifying column name representing endpoint chain. include_chain_id logical indicating whether include chain_id column output. disconnected_action string indicating handle fully disconnected rows. Options : \"exclude\" Exclude disconnected rows output. \"keep\" Keep disconnected rows result.","code":""},{"path":"https://slinghub.github.io/midar/reference/order_chained_columns_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","text":"data frame containing ordered chains chain_id column distinguish different chains. disconnected rows included, chain_id.","code":""},{"path":"https://slinghub.github.io/midar/reference/order_chained_columns_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorder Data Frame based on a chain of linked values in two columns. — order_chained_columns_tbl","text":"","code":"df_unordered <- data.frame(   From = c(\"INSPECT\", \"VERIFY\", \"START\", \"NULL\", \"NEW\", \"CREATE\", \"MID\", \"DIFFERENT\", \"OUTLIER\"),   To = c(\"VERIFY\", \"PUBLISH\", \"MID\", \"NEW\", \"CREATE\", \"INSPECT\", \"END\", \"NOTSAME\", \"INSIDER\"), stringsAsFactors = FALSE )  # Order keeping disconnected rows order_chained_columns_tbl(df_unordered, \"From\", \"To\", FALSE, \"keep\") #>        From      To #> 8     START     MID #> 4       MID     END #> 6      NULL     NEW #> 5       NEW  CREATE #> 1    CREATE INSPECT #> 3   INSPECT  VERIFY #> 9    VERIFY PUBLISH #> 2 DIFFERENT NOTSAME #> 7   OUTLIER INSIDER  # Ordr excluding disconnected rows order_chained_columns_tbl(df_unordered, \"From\", \"To\", FALSE, \"exclude\") #>      From      To #> 6   START     MID #> 3     MID     END #> 5    NULL     NEW #> 4     NEW  CREATE #> 1  CREATE INSPECT #> 2 INSPECT  VERIFY #> 7  VERIFY PUBLISH"},{"path":"https://slinghub.github.io/midar/reference/parse_masshunter_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","title":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","text":"Reads parses one Agilent MassHunter Quant CSV result file","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_masshunter_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","text":"","code":"parse_masshunter_csv(   path,   expand_qualifier_names = TRUE,   silent = FALSE,   conc_column = \"conc_final\" )"},{"path":"https://slinghub.github.io/midar/reference/parse_masshunter_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","text":"path File path MassHunter Quant CSV file expand_qualifier_names TRUE, original qualifier names renamed adding quantifier name front placing qualifier name square brackets(e.g. Qualifier (422.3 -> 113.0) transition names quantifier added qualifier names silent Suppress messages conc_column concentration field masshunter data use, case \"Calc. Conc.\" \"Final. Conc.\" present.  Default \"conc_final\".","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_masshunter_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","text":"tibble parse results long format","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_masshunter_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reads and parses one Agilent MassHunter Quant CSV result file — parse_masshunter_csv","text":"","code":"file_path = system.file(\"extdata\", \"MHQuant_demo.csv\", package = \"midar\")  tbl <- parse_masshunter_csv(   path = file_path,   expand_qualifier_names = TRUE)  head(tbl) #> # A tibble: 6 × 18 #>   analysis_id      file_analysis_order raw_data_filename sample_name sample_type #>   <chr>                          <int> <chr>             <chr>       <chr>       #> 1 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> 2 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> 3 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> 4 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> 5 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> 6 001_EQC_TQC pre…                   1 001_EQC_TQC prer… 001_EQC_TQ… Sample      #> # ℹ 13 more variables: sample_level <chr>, acquisition_time_stamp <dttm>, #> #   vial_position <chr>, feature_id <chr>, integration_qualifier <lgl>, #> #   method_polarity <fct>, method_precursor_mz <dbl>, method_product_mz <dbl>, #> #   method_collision_energy <dbl>, feature_rt <dbl>, feature_area <dbl>, #> #   feature_fwhm <dbl>, feature_manual_integration <lgl>"},{"path":"https://slinghub.github.io/midar/reference/parse_mrmkit_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","title":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","text":"Parses MRMkit peak integration results tibble","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_mrmkit_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","text":"","code":"parse_mrmkit_result(path, silent = FALSE)"},{"path":"https://slinghub.github.io/midar/reference/parse_mrmkit_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","text":"path File name MRMkit result file (*.tsv *.csv) silent comments printed","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_mrmkit_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","text":"tibble long format","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_mrmkit_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parses MRMkit peak integration results into a tibble — parse_mrmkit_result","text":"","code":"file_path = system.file(\"extdata\", \"MRMkit_demo.tsv\", package = \"midar\")  tbl <- parse_mrmkit_result(path = file_path)  head(tbl) #> # A tibble: 6 × 19 #>   analysis_id          raw_data_filename acquisition_time_stamp qc_type batch_id #>   <chr>                <chr>             <dttm>                 <chr>   <chr>    #> 1 Longit_BLANK-01 (El… Longit_BLANK-01 … 2017-10-20 14:15:36    SBLK    1        #> 2 Longit_B-ISTD 01 Ex… Longit_B-ISTD 01… 2017-10-20 14:27:06    PBLK    1        #> 3 Longit_Un-ISTD 01 U… Longit_Un-ISTD 0… 2017-10-20 14:38:26    UBLK    1        #> 4 Longit_LTR 01        Longit_LTR 01.mz… 2017-10-20 14:49:48    LTR     1        #> 5 Longit_TQC-10%       Longit_TQC-10%.m… 2017-10-20 15:12:31    TQC     1        #> 6 Longit_TQC-20%       Longit_TQC-20%.m… 2017-10-20 15:23:51    TQC     1        #> # ℹ 14 more variables: feature_id <chr>, istd_feature_id <chr>, #> #   integration_qualifier <lgl>, method_precursor_mz <dbl>, #> #   method_product_mz <dbl>, method_collision_energy <dbl>, #> #   method_polarity <chr>, feature_rt <dbl>, feature_area <dbl>, #> #   feature_height <dbl>, feature_fwhm <dbl>, feature_int_start <dbl>, #> #   feature_int_end <dbl>, feature_width <dbl>"},{"path":"https://slinghub.github.io/midar/reference/parse_plain_long_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses a plain long CSV file — parse_plain_long_csv","title":"Parses a plain long CSV file — parse_plain_long_csv","text":"Parses CSV table analysis/samples feature pairs rows, columns representing feature variables.","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_long_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses a plain long CSV file — parse_plain_long_csv","text":"","code":"parse_plain_long_csv(   path,   na_strings = \"NA\",   silent = FALSE,   column_mapping = NULL,   warn_unrecognized_columns = TRUE,   ... )"},{"path":"https://slinghub.github.io/midar/reference/parse_plain_long_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses a plain long CSV file — parse_plain_long_csv","text":"path File name (*.tsv *.csv) na_strings character vector strings interpreted NA values. Blank fields also considered missing values. silent comments printed column_mapping named character vector mapping columns input file columns output table. NULL (default), function use default mapping. See import_data_csv_long() details. warn_unrecognized_columns Logical indicating whether issue warning unknown columns dataset. ... Additional arguments passed function. Currently transition_id_columns, used Skyline-like data files. column mapped feature_id appended following info:  transition_id_columns = \"name\", function use method_precursor_name method_product_name columns create unique feature IDs. transition_id_columns = \"mz\", function use method_precursor_mz method_product_mz columns create unique feature IDs.","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_long_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses a plain long CSV file — parse_plain_long_csv","text":"tibble long format","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_long_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parses a plain long CSV file — parse_plain_long_csv","text":"","code":"file_path = system.file(\"extdata\", \"plain_long_dataset.csv\", package = \"midar\")  tbl <- parse_plain_long_csv(path = file_path) #> ! Following unrecognized columns present in the data and were ignored: \"internal_standard\", \"batch\", \"sample_type\", \"rt_apex\", \"area_normalized\", \"concentration\", \"rt_int_start\", and \"rt_int_end\". #> ! Use argument `column_mapping` to define column mapping.  head(tbl) #> # A tibble: 6 × 12 #>   analysis_id      raw_data_filename     acquisition_time_stamp feature_id       #>   <chr>            <chr>                 <dttm>                 <chr>            #> 1 Longit_batch1_15 Longit_batch1_15.mzML 2017-10-20 20:07:09    CE 18:1          #> 2 Longit_batch1_16 Longit_batch1_16.mzML 2017-10-20 20:29:49    CE 18:1          #> 3 Longit_batch1_17 Longit_batch1_17.mzML 2017-10-20 20:41:10    CE 18:1          #> 4 Longit_batch1_15 Longit_batch1_15.mzML 2017-10-20 20:07:09    CE 18:1 d7 (IST… #> 5 Longit_batch1_16 Longit_batch1_16.mzML 2017-10-20 20:29:49    CE 18:1 d7 (IST… #> 6 Longit_batch1_17 Longit_batch1_17.mzML 2017-10-20 20:41:10    CE 18:1 d7 (IST… #> # ℹ 8 more variables: integration_qualifier <lgl>, method_precursor_mz <dbl>, #> #   method_product_mz <dbl>, method_collision_energy <dbl>, #> #   method_polarity <chr>, feature_area <dbl>, feature_height <dbl>, #> #   feature_fwhm <dbl>"},{"path":"https://slinghub.github.io/midar/reference/parse_plain_wide_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses a plain wide CSV file — parse_plain_wide_csv","title":"Parses a plain wide CSV file — parse_plain_wide_csv","text":"Parses CSV table analysis/samples rows, features values columns.","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_wide_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses a plain wide CSV file — parse_plain_wide_csv","text":"","code":"parse_plain_wide_csv(   path,   variable_name,   analysis_id_col = NA,   import_metadata = TRUE,   first_feature_column = NA,   na_strings = \"NA\" )"},{"path":"https://slinghub.github.io/midar/reference/parse_plain_wide_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses a plain wide CSV file — parse_plain_wide_csv","text":"path path name path plain long-format CSV file variable_name Name variable representing values table. Must one \"intensity\", \"norm_intensity\", \"conc\", \"area\", \"height\", \"response\") analysis_id_col Column used analysis_id import_metadata Import additional metadata columns (e.g. batch ID, sample type) add MidarExperiment object first_feature_column Column number first column representing feature values na_strings character vector strings interpreted NA values. Blank fields also considered missing values.","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_wide_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses a plain wide CSV file — parse_plain_wide_csv","text":"tibble long format","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_plain_wide_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parses a plain wide CSV file — parse_plain_wide_csv","text":"","code":"file_path <- system.file(\"extdata\", \"plain_wide_dataset.csv\", package = \"midar\")  tbl <- parse_plain_wide_csv(  path = file_path,  variable_name = \"conc\",  analysis_id_col = \"analysis_id\",  import_metadata = TRUE) #> ℹ Metadata column(s) 'qc_type, batch_id' imported. To ignore, set `import_metadata = FALSE`  head(tbl) #> # A tibble: 6 × 6 #>   analysis_id qc_type batch_id feature_id  feature_conc integration_qualifier #>   <chr>       <chr>   <chr>    <chr>              <dbl> <lgl>                 #> 1 1           SPL     1        S1P 18:1;O2        944.  FALSE                 #> 2 1           SPL     1        S1P 18:2;O2        321.  FALSE                 #> 3 1           SPL     1        S1P 18:0;O2        338.  FALSE                 #> 4 1           SPL     1        S1P 16:1;O2         91.2 FALSE                 #> 5 1           SPL     1        S1P 17:1;O2         24.5 FALSE                 #> 6 2           SPL     1        S1P 18:1;O2        977.  FALSE"},{"path":"https://slinghub.github.io/midar/reference/parse_skyline_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses skyline peak integration results into a tibble — parse_skyline_result","title":"Parses skyline peak integration results into a tibble — parse_skyline_result","text":"Parses skyline peak integration results tibble","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_skyline_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses skyline peak integration results into a tibble — parse_skyline_result","text":"","code":"parse_skyline_result(path, na_strings, silent = FALSE, ...)"},{"path":"https://slinghub.github.io/midar/reference/parse_skyline_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses skyline peak integration results into a tibble — parse_skyline_result","text":"path File name MRMkit result file (*.tsv *.csv) na_strings character vector strings interpreted NA values. silent comments printed ... Additional arguments passed function. Currently transition_id_columns, used Skyline-like data files. column mapped feature_id appended following info:  transition_id_columns = \"name\", function use method_precursor_name method_product_name columns create unique feature IDs. transition_id_columns = \"mz\", function use method_precursor_mz method_product_mz columns create unique feature IDs.","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_skyline_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses skyline peak integration results into a tibble — parse_skyline_result","text":"tibble long format","code":""},{"path":"https://slinghub.github.io/midar/reference/parse_skyline_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parses skyline peak integration results into a tibble — parse_skyline_result","text":"","code":"file_path = system.file(\"extdata\", \"MRMkit_demo.tsv\", package = \"midar\")  tbl <- parse_mrmkit_result(path = file_path)  head(tbl) #> # A tibble: 6 × 19 #>   analysis_id          raw_data_filename acquisition_time_stamp qc_type batch_id #>   <chr>                <chr>             <dttm>                 <chr>   <chr>    #> 1 Longit_BLANK-01 (El… Longit_BLANK-01 … 2017-10-20 14:15:36    SBLK    1        #> 2 Longit_B-ISTD 01 Ex… Longit_B-ISTD 01… 2017-10-20 14:27:06    PBLK    1        #> 3 Longit_Un-ISTD 01 U… Longit_Un-ISTD 0… 2017-10-20 14:38:26    UBLK    1        #> 4 Longit_LTR 01        Longit_LTR 01.mz… 2017-10-20 14:49:48    LTR     1        #> 5 Longit_TQC-10%       Longit_TQC-10%.m… 2017-10-20 15:12:31    TQC     1        #> 6 Longit_TQC-20%       Longit_TQC-20%.m… 2017-10-20 15:23:51    TQC     1        #> # ℹ 14 more variables: feature_id <chr>, istd_feature_id <chr>, #> #   integration_qualifier <lgl>, method_precursor_mz <dbl>, #> #   method_product_mz <dbl>, method_collision_energy <dbl>, #> #   method_polarity <chr>, feature_rt <dbl>, feature_area <dbl>, #> #   feature_height <dbl>, feature_fwhm <dbl>, feature_int_start <dbl>, #> #   feature_int_end <dbl>, feature_width <dbl>"},{"path":"https://slinghub.github.io/midar/reference/plot_calibrationcurves.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Calibration Curves — plot_calibrationcurves","title":"Plot Calibration Curves — plot_calibrationcurves","text":"function plots calibration curves feature defined displays QC samples defined concentrations within plot. Users can select regression model (linear quadratic) apply weighting (none, \"1/x\", \"1/x^2\"), either function arguments feature metadata.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_calibrationcurves.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Calibration Curves — plot_calibrationcurves","text":"","code":"plot_calibrationcurves(   data = NULL,   variable = \"norm_intensity\",   qc_types = NA,   overwrite_fit_param = FALSE,   fit_model = c(\"linear\", \"quadratic\"),   fit_weighting = c(NA, \"none\", \"1/x\", \"1/x^2\"),   show_confidence_interval = NA,   log_axes = FALSE,   filter_data = FALSE,   include_qualifier = TRUE,   include_istd = FALSE,   include_feature_filter = NA,   exclude_feature_filter = NA,   output_pdf = FALSE,   path = NA,   return_plots = FALSE,   point_size = 1.5,   line_width = 0.7,   point_color = NA,   point_fill = NA,   point_shape = NA,   line_color = \"#4575b4\",   ribbon_fill = \"#91bfdb40\",   font_base_size = 7,   rows_page = 4,   cols_page = 5,   specific_page = NA,   page_orientation = \"LANDSCAPE\",   show_progress = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/plot_calibrationcurves.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Calibration Curves — plot_calibrationcurves","text":"data MidarExperiment object containing dataset. variable Variable plot y-axis, usually intensity. Default \"intensity\". qc_types character vector specifying QC types plot. must contain least CAL, represents calibration curve samples. QC types plotted points assigned concentrations (see QC-concentration metadata). QC types need present data defined analysis metadata. default NA, means QC types \"CAL\", \"HQC\", \"MQC\", \"LQC\", \"EQA\", \"QC\", plotted present assigned concentrations. overwrite_fit_param TRUE, function ignore fit method weighting settings defined metadata use provided fit_model fit_weighting values analytes. fit_model character string specifying default regression fit method use calibration curve. Must one \"linear\" \"quadratic\". method applied specific fit method defined feature metadata, overwrite_fit_param = TRUE. fit_weighting character string specifying default weighting method regression points calibration curve. Must one \"none\", \"1/x\", \"1/x^2\". method applied specific weighting method defined feature metadata, overwrite_fit_param = TRUE. show_confidence_interval Logical, TRUE, displays confidence interval ribbon. Default NA, case confidence intervals plotted linear scale ommitted log-log scale. log_axes Logical. Determines whether x y axes displayed logarithmic scale (log-log scale). Set TRUE enable logarithmic scaling; otherwise, set FALSE linear scale. Note: TRUE, regression curves standard error regions negative values omitted display. filter_data Logical, TRUE, uses QC filtered data; otherwise uses raw data. Default FALSE. include_qualifier Logical, whether include qualifier features. Default TRUE. include_istd Logical, whether include internal standard (ISTD) features. Default TRUE. include_feature_filter Regex pattern include features. omitted, considers features. exclude_feature_filter Regex pattern exclude features. omitted, excludes none. output_pdf Logical, TRUE, saves plots PDF file. Default FALSE. path File path saving PDF. Default empty string. return_plots Logical, TRUE, returns plots list ggplot2 objects. Default FALSE. point_size Size points plot. Default 1.5. line_width Width regression lines. Default 0.7. point_color vector specifying colors points corresponding different QC types. can either unnamed vector named vector, names corresponding QC types. Unused colors ignored. Default NA corresponds default colors QC types defined package. point_fill vector specifying fill colors points corresponding different QC types. can either unnamed vector named vector, names corresponding QC types. Unused fill colors ignored. Default NA corresponds default fill colors QC types defined package. point_shape vector specifying shapes points corresponding different QC types. can either unnamed vector named vector, names corresponding QC types. Unused shapes ignored. Default NA corresponds default shapes QC types defined package. line_color Color regression line. Default \"#4575b4\". ribbon_fill Color confidence interval ribbon. Default \"#91bfdb40\". font_base_size Base font size text plots. Default 7. rows_page Number plot rows. Default 4. cols_page Number plot columns. Default 5. specific_page Show/save specific page number . NA plots/saves pages. page_orientation Orientation PDF, either \"LANDSCAPE\" \"PORTRAIT\". Default `\"LANDSCAPE show_progress Logical. TRUE, displays progress bar plot creation.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_calibrationcurves.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Calibration Curves — plot_calibrationcurves","text":"Features plotting can filtered using QC filters defined via filter_features_qc() include_feature_filter exclude_feature_filter arguments. resulting plots offer extensive customization options, including point size, line width, point color, point fill, point shape, line color, ribbon fill, font base size. Plots divided multiple pages number features exceeds product rows_page cols_page settings. function supports direct plotting within R saving plots PDF files. Additionally, plots can returned list ggplot2 objects manipulation integration analyses.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare %CV values before and after normalization — plot_normalization_qc","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"function compares coefficient variation (CV) QC study samples normalization. preselects relevant QC metrics based chosen arguments visualizes comparison scatter plot. plot can faceted feature_class.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"","code":"plot_normalization_qc(   data = NULL,   before_norm_var = c(\"intensity\", \"norm_intensity\"),   after_norm_var = c(\"norm_intensity\", \"conc\"),   qc_type,   facet_by_class = FALSE,   filter_data = FALSE,   include_qualifier = FALSE,   cv_threshold_value = 25,   xlim = c(0, NA),   ylim = c(0, NA),   ncol = 5,   point_size = 1,   point_alpha = 0.5,   font_base_size = 8 )"},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"data MidarExperiment object before_norm_var string specifying variable QC metrics table used x-axis (normalization). after_norm_var string specifying variable QC metrics table used y-axis (normalization). qc_type QC type used comparison (one : \"SPL\", \"BQC\", \"TQC\", \"NIST\", \"LTR\"). facet_by_class TRUE, facets plot feature_class, defined feature metadata. filter_data Whether use data (default) QC-filtered data (filtered via filter_features_qc()). include_qualifier Whether include qualifier features (default TRUE). cv_threshold_value Numerical threshold value shown dashed lines plot (default 25). xlim Numeric vector length 2 x-axis limits. Use NA auto-scaling (default c(0, NA)). ylim Numeric vector length 2 y-axis limits. Use NA auto-scaling (default c(0, NA)). ncol Number facet columns per page, representing different feature classes (default 5). used facet_by_class = TRUE. point_size Size points millimeters (default 1). point_alpha Transparency points (default 0.5). font_base_size Base font size points (default 8).","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"ggplot2 object representing scatter plot comparing CV values normalization.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"function preselects corresponding variables QC metrics uses plot_qcmetrics_comparison() visualize results. data must normalized using normalize_by_istd() followed calculation QC metrics table via calc_qc_metrics() filter_features_qc(), see examples . facet_by_class = TRUE, feature_class must defined metadata retrieved via specific functions, e.g., get_lipid_class_names().","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/plot_normalization_qc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare %CV values before and after normalization — plot_normalization_qc","text":"","code":"# Example usage: mexp <- lipidomics_dataset mexp <- normalize_by_istd(mexp) #> ! Interfering features defined in metadata, but no correction was applied. Use `correct_interferences()` to correct. #> ✔ 20 features normalized with 9 ISTDs in 499 analyses. mexp <- calc_qc_metrics(mexp) plot_normalization_qc(   data = mexp,   before_norm_var = \"intensity\",   after_norm_var = \"norm_intensity\",   qc_type = \"SPL\",   filter_data = FALSE,   facet_by_class = TRUE,   cv_threshold_value = 25 )"},{"path":"https://slinghub.github.io/midar/reference/plot_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"PCA Plot for Quality Control — plot_pca","title":"PCA Plot for Quality Control — plot_pca","text":"Generates Principal Component Analysis (PCA) plot visualizing samples including quality control (QC) samples. function provides options filtering data, applying transformations, customizing visual elements enhance visualization.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PCA Plot for Quality Control — plot_pca","text":"","code":"plot_pca(   data = NULL,   variable,   qc_types = NA,   ellipse_variable = \"qc_type\",   ellipse_levels = NA,   pca_dimensions = c(1, 2),   log_transform = TRUE,   filter_data = FALSE,   include_qualifier = FALSE,   include_istd = FALSE,   include_feature_filter = NA,   exclude_feature_filter = NA,   min_median_value = NA,   show_labels = TRUE,   labels_threshold_mad = 3,   shared_labeltext_hide = NA,   label_font_size = 3,   point_size = 2,   point_alpha = 0.8,   font_base_size = 8,   ellipse_confidence_level = 0.95,   ellipse_linewidth = 1,   ellipse_fill = TRUE,   ellipse_fillcolor = NA,   ellipse_alpha = 0.1 )"},{"path":"https://slinghub.github.io/midar/reference/plot_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PCA Plot for Quality Control — plot_pca","text":"data MidarExperiment object variable character string indicating variable use PCA analysis. Must one : \"area\", \"height\", \"intensity\", \"response\", \"conc\", \"conc_raw\", \"rt\", \"fwhm\". qc_types character vector specifying QC types plot. must contain least one element. default NA, means non-blank QC types (\"SPL\", \"TQC\", \"BQC\", \"HQC\", \"MQC\", \"LQC\", \"NIST\", \"LTR\") plotted present dataset. ellipse_variable String specifying sample variable show ellipses. Must one : \"none\", \"qc_type\", \"batch_id\". \"none\" omits ellipses. ellipse_levels character vector specifying levels ellipse_variable display ellipses. pca_dimensions numeric vector length 2 indicating PCA dimensions plot. Default c(1, 2). log_transform logical value indicating whether log-transform data PCA. Default TRUE. filter_data logical value indicating whether use data (default) QC-filtered data (filtered via filter_features_qc()). include_qualifier logical value indicating whether include qualifier features. Default TRUE. include_istd logical value indicating whether include internal standard (ISTD) features. Default TRUE. include_feature_filter character regex pattern used filter features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, features exactly names selected (applied individually conditions). exclude_feature_filter character regex pattern used exclude features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, features exactly names excluded (applied individually conditions). min_median_value Minimum median feature value (determined variable) across samples selected QC types must met feature included PCA analysis. NA (default) means filtering applied. parameter provides fast way exclude noisy features analysis. However, recommended use filter_data filter_features_qc(). show_labels logical value indicating whether show analysis_id labels points outside k * MAD selected PCA dimensions. Default TRUE. labels_threshold_mad numeric value determining threshold showing labels based median absolute deviation (MAD). Default 3. Set NULL suppress labels. shared_labeltext_hide character string representing text shared across labels hidden (case-sensitive). results non-unique analysis_id's, error raised. label_font_size Number indicating font size labels 'mm'. Note unit different font_base_size 'pt'. point_size numeric value indicating size points millimeters. Default 2. point_alpha numeric value indicating transparency points (0-1). Default 0.5. font_base_size numeric value indicating base font size plot text elements. Default 8. ellipse_confidence_level numeric value indicating confidence level ellipses. Default 0.95. ellipse_linewidth numeric value indicating line width ellipses. Default 1. ellipse_fill logical value indicating whether fill ellipses. ellipse_fillcolor vector specifying fill colors ellipse corresponding different ellipse_variable levels. can either unnamed vector named vector, names corresponding leves ellipse_variable. Unused fill colors ignored. Default NA corresponds default fill colors case ellipse_variable = qc_type, automatically generated colors otherwise. ellipse_alpha numeric value indicating transparency ellipse fill (0-1). Default 0.3.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PCA Plot for Quality Control — plot_pca","text":"ggplot object PCA plot","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_byclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot QC Filtering Summary by Feature Class — plot_qc_summary_byclass","title":"Plot QC Filtering Summary by Feature Class — plot_qc_summary_byclass","text":"function provides summary feature QC filtering based feature class, showing number features passed failed various quality control criteria. visualizes filtering hierarchical sequence. Features first evaluated lower-level filters signal--blank (S/B) ratios limit detection (LOD), followed higher-level filters like coefficient variation (CV) linear regression results. means feature classified failing given criterion (e.g., CV) passed hierarchically lower filters (e.g., S/B ratio LOD).","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_byclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot QC Filtering Summary by Feature Class — plot_qc_summary_byclass","text":"","code":"plot_qc_summary_byclass(data = NULL, font_base_size = 8)"},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_byclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot QC Filtering Summary by Feature Class — plot_qc_summary_byclass","text":"data MidarExperiment object font_base_size base font size plot. Default 8.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_byclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot QC Filtering Summary by Feature Class — plot_qc_summary_byclass","text":"ggplot2 object showing feature QC filtering summary feature class.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_overall.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","title":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","text":"function generates summary feature QC filtering process, visualizing number features passed failed various QC criteria. includes Venn diagram showing features excluded due different filtering criteria signal--blank ratios, CV thresholds, linearity. criteria applied hierarchically, meaning feature must pass lower-tier filters considered failure higher-tier filters. See plot_qc_summary_byclass() information.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_overall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","text":"","code":"plot_qc_summary_overall(data = NULL, with_venn = TRUE, font_base_size = 8)"},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_overall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","text":"data MidarExperiment object with_venn Whether include Venn diagram summarizing features excluded due different QC criteria. Default TRUE. font_base_size base font size plot. Default 8.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_overall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","text":"ggplot2 object showing feature QC filtering summary without Venn diagram.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qc_summary_overall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Overall QC Filtering Summary — plot_qc_summary_overall","text":"QC filtering process follows hierarchical structure, features first evaluated lower-level filters signal--blank ratios limit detection (LOD). features pass basic criteria subjected higher-level filters like coefficient variation (CV) linear regression results. feature fail higher-level filter (CV R-squared) passed previous lower-level filters. ensures features evaluated progressively, starting fundamental quality checks stringent filtering criteria.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"function generates scatter plots comparing two QC metrics variables across feature classes. list available QC metrics available calc_qc_metrics() documentation.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"","code":"plot_qcmetrics_comparison(   data = NULL,   x_variable,   y_variable,   facet_by_class = FALSE,   filter_data = FALSE,   include_qualifier = TRUE,   equality_line = FALSE,   threshold_value = NA,   xlim = c(0, NA),   ylim = c(0, NA),   ncol = 5,   point_size = 1,   point_alpha = 0.5,   font_base_size = 8 )"},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"data MidarExperiment object containing pre-calculated QC metrics. x_variable name QC metric variable plotted x-axis. y_variable name QC metric variable plotted y-axis. facet_by_class TRUE, facets plot feature_class, defined feature metadata. filter_data Logical; whether use data (default) QC-filtered data (filtered via filter_features_qc()). include_qualifier Logical; whether include qualifier features (default TRUE). equality_line Logical; whether show line indicating identical values compared variables (default FALSE). threshold_value Numeric; threshold value shown dashed lines axes plot (default NA). xlim Numeric vector length 2 x-axis limits. Use NA auto-scaling (default c(0, NA)). ylim Numeric vector length 2 y-axis limits. Use NA auto-scaling (default c(0, NA)). ncol Integer; number facet columns per page (default 5). point_size Numeric; size points millimeters (default 1). point_alpha Numeric; transparency points (default 0.5). font_base_size Numeric; base font size points (default 8).","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"ggplot2 object representing scatter plot.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"x_variable y_variable must available QC metrics table. Please refer help page calc_qc_metrics() information available QC metric variables. facet_by_class = TRUE, feature_class must defined metadata retrieved via specific functions, e.g., get_lipid_class_names().","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/plot_qcmetrics_comparison.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparison of two feature QC metrics variables — plot_qcmetrics_comparison","text":"","code":"# Example usage mexp <- lipidomics_dataset mexp <- calc_qc_metrics(mexp) plot_qcmetrics_comparison(data = mexp,             filter_data = FALSE,             x_variable = \"precursor_mz\",             y_variable = \"rt_median_SPL\",             include_qualifier = TRUE)"},{"path":"https://slinghub.github.io/midar/reference/plot_responsecurves.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Response Curves — plot_responsecurves","title":"Plot Response Curves — plot_responsecurves","text":"function plots response curves feature. Multiple response curves, linear regression line, can plotted graph. feature displayed separate facet.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_responsecurves.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Response Curves — plot_responsecurves","text":"","code":"plot_responsecurves(   data = NULL,   variable = \"intensity\",   filter_data = FALSE,   include_qualifier = TRUE,   include_istd = TRUE,   include_feature_filter = NA,   exclude_feature_filter = NA,   max_regression_value = NA,   output_pdf = FALSE,   path = NA,   return_plots = FALSE,   color_curves = NULL,   point_size = 1.5,   line_width = 0.7,   font_base_size = 7,   rows_page = 4,   cols_page = 5,   specific_page = NA,   page_orientation = \"LANDSCAPE\",   show_progress = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/plot_responsecurves.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Response Curves — plot_responsecurves","text":"data MidarExperiment object containing dataset metadata. variable variable plot y-axis. filter_data Whether use data (default) QC-filtered data (filtered via filter_features_qc()). include_qualifier Logical, whether include qualifier features. Default TRUE. include_istd Logical, whether include internal standard (ISTD) features. Default TRUE. include_feature_filter regex pattern vector feature names used filter features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names selected (applied individually conditions). exclude_feature_filter regex pattern vector feature names exclude features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names excluded (applied individually conditions). max_regression_value maximum sample_amount (x) value fitting regression line. NA, regression based data points. output_pdf TRUE, saves generated plots PDF file. Wjen FALSE, plots directly plotted. path file path saving PDF. Must defined output_pdf TRUE. return_plots Logical. TRUE, returns plots list ggplot2 objects. color_curves vector colors curves. NULL (default), colors curve generated automatically. colors provided, number colors must match number curves. point_size Size points millimeters. line_width Width regression lines. font_base_size Base font size text. Default 7. rows_page Number rows plots per page. cols_page Number columns plots per page. specific_page integer specifying specific page plot. NA (default), pages plotted. page_orientation Orientation PDF paper: \"LANDSCAPE\" \"PORTRAIT\". show_progress Logical. TRUE, displays progress bar plot creation.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_responsecurves.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Response Curves — plot_responsecurves","text":"return_plots TRUE, list ggplot2 objects returned. Otherwise, function saves plot output return anything.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_responsecurves.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Response Curves — plot_responsecurves","text":"Features plotting can filtered using QC filters defined via filter_features_qc() include_feature_filter exclude_feature_filter arguments. resulting plots offer extensive customization options, including point size, line width, point color, point fill, point shape, line color, ribbon fill, font base size. Plots divided multiple pages number features exceeds product rows_page cols_page settings. function supports direct plotting within R saving plots PDF files. Additionally, plots can returned list ggplot2 objects manipulation integration analyses.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_rla_boxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","title":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","text":"Relative log abundance (RLA) plots show standardized feature abundances across samples. Standardization done removing either within-batch across-batch median feature RLA plots useful visualizing technical effects impact features similar manner, batch effects due changes instrument response, pipetting errors, sample spillage. Unlike plots raw normalized abundances, RLA plots robust types effects.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_rla_boxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","text":"","code":"plot_rla_boxplot(   data = NULL,   rla_type_batch = c(\"within\", \"across\"),   variable = c(\"intensity\", \"norm_intensity\", \"conc\", \"conc_raw\", \"area\", \"height\",     \"fwhm\"),   filter_data = FALSE,   qc_types = NA,   include_qualifier = TRUE,   include_istd = TRUE,   include_feature_filter = NA,   exclude_feature_filter = NA,   plot_range = NA,   show_timestamp = FALSE,   min_feature_intensity = 0,   y_lim = NA,   ignore_outliers = FALSE,   show_batches = TRUE,   batch_zebra_stripe = FALSE,   batch_line_color = \"#b6f0c5\",   batch_fill_color = \"grey93\",   x_gridlines = FALSE,   linewidth = 0.2,   base_font_size = 8,   relative_log_abundances = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/plot_rla_boxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","text":"data MidarExperiment rla_type_batch Character, must either \"within\" \"across\", defining whether use within-batch across-batch RLA variable Variable plot, must one \"intensity\", \"norm_intensity\", \"conc\", \"area\", \"height\", \"fwhm\", one \"intensity_raw\", \"intensity_before\", \"norm_intensity_raw\", \"norm_intensity_before\", \"conc_raw\", \"conc_before\" filter_data Logical, whether use QC-filtered data based criteria set via filter_features_qc(). qc_types QC types plotted. Can vector QC types regular expression pattern. NA (default) displays available QC/Sample types. include_qualifier Logical, whether include qualifier features. Default TRUE. include_istd Logical, whether include internal standard (ISTD) features. Default TRUE. include_feature_filter regex pattern vector feature names used filter features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names selected (applied individually conditions). exclude_feature_filter regex pattern vector feature names exclude features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names excluded (applied individually conditions). plot_range Numeric vector length 2, specifying start end indices analysis order plotted. NA plots samples. show_timestamp Logical, whether use acquisition timestamp x-axis instead run sequence number min_feature_intensity Numeric, exclude features overall median signal value y_lim Numeric vector length 2, specifying lower upper y-axis limits. Default NA, uses limits calculated based ignore_outliers. ignore_outliers Logical, whether exclude outlier values based 4x MAD (median absolute deviation) fences show_batches Logical, whether show batch separators plot batch_zebra_stripe Logical, whether show batches shaded areas instead line separators batch_line_color Character, color batch separator lines batch_fill_color Character, color batch shaded areas x_gridlines Logical, whether show major x-axis gridlines linewidth Numeric, line width used whiskers boxplot base_font_size Numeric, base font size plot relative_log_abundances Logical, whether use relative log abundances (RLA) just log-transformed values","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_rla_boxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","text":"ggplot object representing RLA plot","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_rla_boxplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Relative Log Abundance (RLA) Plot — plot_rla_boxplot","text":"De Livera et al. (2012) Normalizing integrating metabolomics data. Analytical Chemistry 10768-10776 DOI: 10.1021/ac302748b De Livera et al. (2015) Statistical Methods Handling Unwanted Variation Metabolomics Data. Analytical Chemistry 87(7):3606-3615 DOI: 10.1021/ac502439y","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runscatter.html","id":null,"dir":"Reference","previous_headings":"","what":"RunScatter Plot — plot_runscatter","title":"RunScatter Plot — plot_runscatter","text":"runscatter function visualizes raw processed feature signals across different sample/QC types along analysis sequence. helps identify trends, detect outliers, assess analytical performance. Available feature variables, retention time (RT) full width half maximum (FWHM), can plotted analysis order timestamps. default, QC types present dataset plotted. QC types predefined colors shapes assigned black shapes. User-defined QC types predefined colors shapes midar. assigned black shapes. predefined color shape, assigned shapes black. show specific QC types use qc_types argument. plot feature values last applied drift/batch correction, add *_before variable name, e.g., intensity_before conc_before. plot uncorrected feature values (drift/batch correction), add *_raw variable name, e.g., intensity_raw conc_raw. show corresponding fit curves, set show_trend = TRUE. function also supports visualizing analysis batches, reference lines (mean \\(\\pm\\) SD), trends. offers customization options display batch separators, apply outlier capping, show smoothed trend curves, add reference lines, incorporate features. Outlier capping particularly useful focus QC study sample trends might otherwise obscured extreme values high variability. runscatter function serves central QC tool workflow, providing critical insights data quality.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runscatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RunScatter Plot — plot_runscatter","text":"","code":"plot_runscatter(   data = NULL,   variable = c(\"intensity\", \"norm_intensity\", \"conc\", \"rt\", \"area\", \"height\", \"fwhm\",     \"intensity_raw\", \"intensity_before\", \"norm_intensity_raw\", \"norm_intensity_before\",     \"conc_raw\", \"conc_before\"),   filter_data = FALSE,   qc_types = NA,   include_qualifier = TRUE,   include_istd = TRUE,   include_feature_filter = NA,   exclude_feature_filter = NA,   plot_range = NA,   output_pdf = FALSE,   path = NA,   return_plots = FALSE,   show_batches = TRUE,   batch_zebra_stripe = FALSE,   batch_line_color = \"#cdf7d9\",   batch_fill_color = \"grey93\",   cap_outliers = FALSE,   cap_sample_k_mad = 4,   cap_qc_k_mad = 4,   cap_top_n_outliers = NA,   show_reference_lines = FALSE,   ref_qc_types = NA,   reference_k_sd = 2,   reference_batchwise = FALSE,   reference_line_color = \"#04bf9a\",   reference_sd_shade = FALSE,   reference_fill_color = NA,   reference_linewidth = 0.75,   show_trend = FALSE,   trend_color = \"#22e06b\",   y_min = 0,   y_max = NA,   log_scale = FALSE,   show_gridlines = FALSE,   point_size = 1.5,   point_transparency = 1,   point_border_width = 1,   base_font_size = 11,   rows_page = 3,   cols_page = 3,   specific_page = NA,   page_orientation = \"LANDSCAPE\",   y_label_text = NA,   show_progress = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/plot_runscatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RunScatter Plot — plot_runscatter","text":"data MidarExperiment object containing dataset metadata. variable variable plot y-axis, one 'intensity', 'norm_intensity', 'conc', 'conc', 'rt', 'fwhm', 'area', 'height', response'. Add _before variable name plot feature values last applied drift/batch correction, (e.g., conc_before). Add _raw variable name plot raw uncorrected feature values (e.g., conc_raw). filter_data Logical, whether use QC-filtered data based criteria set via filter_features_qc(). qc_types QC types plotted. Can vector QC types regular expression pattern. NA (default) displays available QC/Sample types. include_qualifier Logical, whether include qualifier features. Default TRUE. include_istd Logical, whether include internal standard (ISTD) features. Default TRUE. include_feature_filter regex pattern vector feature names used filter features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names selected (applied individually conditions). exclude_feature_filter regex pattern vector feature names exclude features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, supplied, features exactly names excluded (applied individually conditions). plot_range Numeric vector length 2, specifying start end indices analysis order plotted. NA plots samples. output_pdf Logical, whether save plot PDF file. path File name PDF output. return_plots Logical, whether return list ggplot objects. show_batches Logical, whether show batch separators plot. batch_zebra_stripe Logical, whether display batches alternating shaded non-shaded areas. batch_line_color Color batch separator lines. batch_fill_color Color shaded areas representing batches. cap_outliers Logical, whether cap upper outliers based MAD fences SPL QC samples. cap_sample_k_mad Numeric, k * MAD (median absolute deviation) outlier capping SPL samples. cap_qc_k_mad Numeric, k * MAD (median absolute deviation) outlier capping QC samples. cap_top_n_outliers Numeric, cap top n outliers regardless MAD fences. NA 0 ignores filter. show_reference_lines Whether display reference lines (mean \\(\\pm\\) n x SD). ref_qc_types QC type reference lines calculated. reference_k_sd Multiplier standard deviations define SD reference lines. reference_batchwise Whether calculate reference lines per batch. reference_line_color Color reference lines. reference_sd_shade TRUE plots colored band indicating \\(\\pm\\) n x SD reference range. FALSE (default) shows reference lines instead. reference_fill_color Fill color batch-wise reference ranges. NA (default), color assigned qc_type used. reference_linewidth Width reference lines. show_trend TRUE trend curves drift/batch correction shown. trend_color Color trend curve. y_min Lower y-axis value. Default 0. NA, minimum value set automatically per facet based data y_max Upper y-axis value. Default NA. NA, maximum value set automatically per facet based data. log_scale Logical, whether use log10 scale y-axis. show_gridlines Whether show major x y gridlines. point_size Size data points. point_transparency Alpha transparency data points. point_border_width Width data point borders. base_font_size Base font size plot. rows_page Number rows per page. cols_page Number columns per page. specific_page Show/save specific page number . NA plots/saves pages. page_orientation Page orientation, \"LANDSCAPE\" \"PORTRAIT\". y_label_text Override default y-axis label text. show_progress Logical, whether show progress bar.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runscatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RunScatter Plot — plot_runscatter","text":"list ggplot2 plots, NULL `return","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runscatter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RunScatter Plot — plot_runscatter","text":"outlier capping feature (cap_outliers) allows cap upper outliers based median absolute deviation (MAD) fences SPL QC samples, remove top n points. can help focus trends interest outlier high variability data, e.g. study samples. using log-scale (log_scale = TRUE), zero negative values replaced minimum positive value divided 5 avoid log 0 errors Reference lines/ranges corresponding mean \\(\\pm\\) k x SD can shown across within batches lines shaded stripes. Trend curves can displayed drift/batch correction. either case, drift /batch correction must applied data enable plotting trend curves. show trend curves used last drift batch correction, add \"_before\" variable name, e.g. conc_before intensity_before set show_trend = TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runsequence.html","id":null,"dir":"Reference","previous_headings":"","what":"RunSequence Plot — plot_runsequence","title":"RunSequence Plot — plot_runsequence","text":"RunSequence plot provides overview analysis design timelines, can useful subsequent processing steps. plot illustrates batch structure, quality control (QC) samples included respective positions, additional information regarding date, duration, run time analysis. Setting show_timestamp = TRUE allows check interruptions analysis timeline.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runsequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RunSequence Plot — plot_runsequence","text":"","code":"plot_runsequence(   data = NULL,   qc_types = NA,   show_batches = TRUE,   show_timestamp = FALSE,   add_info_title = TRUE,   single_row = FALSE,   segment_linewidth = 0.5,   batch_zebra_stripe = FALSE,   batch_line_color = \"#b6f0c5\",   batch_fill_color = \"grey90\",   base_font_size = 8 )"},{"path":"https://slinghub.github.io/midar/reference/plot_runsequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RunSequence Plot — plot_runsequence","text":"data MidarExperiment object qc_types QC types plotted. Can vector QC types regular expression pattern. NA (default) displays available QC/Sample types. show_batches Logical, whether show batch separators plot. show_timestamp Logical, whether use acquisition timestamp x-axis instead run sequence number. add_info_title Logical, whether add title experiment title, analysis date, analysis times. single_row Logical, whether show QC types single row. segment_linewidth Width segment lines, default 0.5. batch_zebra_stripe Logical, whether show batches shaded areas instead line separators. batch_line_color Color batch separator lines. batch_fill_color Color batch shaded areas. base_font_size Numeric, base font size plot.","code":""},{"path":"https://slinghub.github.io/midar/reference/plot_runsequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RunSequence Plot — plot_runsequence","text":"ggplot object representing run sequence plot.","code":""},{"path":"https://slinghub.github.io/midar/reference/quant_lcms_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"LC-MS Dataset with External Calibration Curve and Metadata — quant_lcms_dataset","title":"LC-MS Dataset with External Calibration Curve and Metadata — quant_lcms_dataset","text":"demo dataset included use function examples user testing. subset LC-MS analysis plasma steroids, containing external calibration curve analyte, QC samples known concentrations, unknown samples.","code":""},{"path":"https://slinghub.github.io/midar/reference/quant_lcms_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LC-MS Dataset with External Calibration Curve and Metadata — quant_lcms_dataset","text":"","code":"quant_lcms_dataset"},{"path":"https://slinghub.github.io/midar/reference/quant_lcms_dataset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"LC-MS Dataset with External Calibration Curve and Metadata — quant_lcms_dataset","text":"MidarExperiment object following data metadata: dataset_orig Original data (peak datas). dataset Annotated data annot_analyses Analysis-level metadata annot_features Feature-level annotations annot_istds ISTD concentrations annot_qcconcentrations Calibrant (CAL) QC concentrations","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate concentrations based on external calibration — quantify_by_calibration","title":"Calculate concentrations based on external calibration — quantify_by_calibration","text":"Concentrations features analyses determined using ISTD-normalized intensities corresponding external calibration curves. Calibration curves calculated feature based calibration sample concentrations defined qc_concentrations metadata. regression fit model (linear quadratic) weighting method (either \"none\", \"1/x\", \"1/x^2\") can defined globally via arguments fit_model fit_weighting features, overwrite_fit_param TRUE. Alternatively, model weighting can defined individually feature feature metadata (columns curve_fit_model fit_weighting). details missing metadata, default values provided via fit_model fit_weighting used.","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate concentrations based on external calibration — quantify_by_calibration","text":"","code":"quantify_by_calibration(   data = NULL,   include_qualifier = TRUE,   overwrite_fit_param = FALSE,   fit_model = c(\"linear\", \"quadratic\"),   fit_weighting = c(\"none\", \"1/x\", \"1/x^2\"),   ignore_failed_calibration = FALSE,   ignore_missing_annotation = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/quantify_by_calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate concentrations based on external calibration — quantify_by_calibration","text":"data MidarExperiment object include_qualifier logical value. TRUE, function include quantifier features calibration curve calculations. overwrite_fit_param TRUE, function ignore fit method weighting settings defined metadata use provided fit_model fit_weighting values analytes. fit_model character string specifying default regression fit method use calibration curve. Must one \"linear\" \"quadratic\". method applied specific fit method defined feature metadata, overwrite_fit_param = TRUE. fit_weighting character string specifying default weighting method regression points calibration curve. Must one \"none\", \"1/x\", \"1/x^2\". method applied specific weighting method defined feature metadata, overwrite_fit_param = TRUE. ignore_failed_calibration FALSE, raises error calibration curve fit fails feature. TRUE, failed fits ignored, resulting feature concentration NA. ignore_missing_annotation FALSE, raises error following information missing: calibration curve data, ISTD mix volume sample amounts feature. TRUE, missing annotations ignored, resulting feature concentration NA","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate concentrations based on external calibration — quantify_by_calibration","text":"modified MidarExperiment object updated concentration values.","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_calibration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate concentrations based on external calibration — quantify_by_calibration","text":"concentrations added dataset table feature_conc column. results regression calculated LoD LoQ values stored metrics_calibration table returned MidarExperiment object.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/quantify_by_istd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","title":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","text":"function calculates analyte concentrations based internal standard (ISTD) normalized intensities corresponding spiked-ISTD amount, normalized sample amount.","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_istd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","text":"","code":"quantify_by_istd(   data = NULL,   concentration_unit = \"molar\",   ignore_missing_annotation = FALSE,   ignore_istds = FALSE )"},{"path":"https://slinghub.github.io/midar/reference/quantify_by_istd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","text":"data MidarExperiment object concentration_unit Character string indicating type concentration calculate export. Must either \"molar\" molar concentrations (e.g., µmol/L) \"mass\" mass concentrations (e.g., µg/L). ignore_missing_annotation FALSE, error raised following information missing: ISTD concentration, ISTD mix volume, sample amounts feature. TRUE, missing annotations ignored, resulting feature concentration NA ignore_istds TRUE, ISTD features ignored concentration calculation resulting concentration NA. Default FALSE.","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_istd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","text":"MidarExperiment object calculated analyte concentrations added dataset table feature_conc column.","code":""},{"path":"https://slinghub.github.io/midar/reference/quantify_by_istd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Analyte Concentrations Using Internal Standards — quantify_by_istd","text":"default, concentrations returned molar units (e.g., µmol/L). return concentrations mass units (e.g., µg/L), set concentration_unit = \"mass\". requires either chemical formula molecular weight feature specified feature metadata. Internal standard concentrations can also provided ng/mL. cases, function convert concentrations molar units internal calculations. , either chemical formula molecular weight must defined ISTD feature metadata. unit calculated concentrations determined concentration_unit argument sample_amount_unit field analysis metadata MidarExperiment object. function automatically adjust sample amount appropriate unit based provided concentration_unit. example, concentration_unit = \"molar\" sample_amount_unit = \"uL\", calculated concentrations µmol/L. concentration_unit = \"mass\", concentrations µg/L. calculated concentrations added dataset table new column named feature_conc..","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/save_dataset_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Export Data to CSV file — save_dataset_csv","title":"Export Data to CSV file — save_dataset_csv","text":"function exports specific unprocessed pr ocessed feature variable (e.g. intensities concentrations) MidarExperiment object CSV file. Allows selection features optional QC filtering.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_dataset_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export Data to CSV file — save_dataset_csv","text":"","code":"save_dataset_csv(   data = NULL,   path,   variable,   filter_data = FALSE,   qc_types = NA,   include_qualifier = NA,   include_istd = NA,   include_feature_filter = NA,   exclude_feature_filter = NA,   add_qctype = NA )"},{"path":"https://slinghub.github.io/midar/reference/save_dataset_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export Data to CSV file — save_dataset_csv","text":"data MidarExperiment object path File name path exported CSV file variable Variable exported, must present data \"area\", \"height\", \"intensity\", \"norm_intensity\", \"response\", \"conc\", \"conc_raw\", \"rt\", \"fwhm\". filter_data logical value indicating whether use data (default) QC-filtered data (filtered via filter_features_qc()). Default FALSE. qc_types QC types plotted. Can vector QC types regular expression pattern. NA (default) displays available QC/Sample types. include_qualifier logical value indicating whether include qualifier features. Default NA, automatically set FALSE variable conc conc_raw, FALSE otherwise. include_istd logical value indicating whether include internal standard (ISTD) features. Default NA, automatically set FALSE variable ”norm_intensity, concorconc_raw, TRUE` otherwise. include_feature_filter character regex pattern used filter features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, features exactly names selected (applied individually conditions). exclude_feature_filter character regex pattern used exclude features feature_id. NA empty string (\"\") provided, filter ignored. vector length > 1 supplied, features exactly names excluded (applied individually conditions). add_qctype Add QC type column","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/save_feature_qc_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Feature QC Metrics to CSV — save_feature_qc_metrics","title":"Save Feature QC Metrics to CSV — save_feature_qc_metrics","text":"function exports feature information QC (Quality Control) metrics MidarExperiment object CSV file.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_feature_qc_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Feature QC Metrics to CSV — save_feature_qc_metrics","text":"","code":"save_feature_qc_metrics(data = NULL, path)"},{"path":"https://slinghub.github.io/midar/reference/save_feature_qc_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Feature QC Metrics to CSV — save_feature_qc_metrics","text":"data MidarExperiment object containing QC metrics. path string specifying file path CSV file saved.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_feature_qc_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save Feature QC Metrics to CSV — save_feature_qc_metrics","text":"tibble QC metrics exported.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_metadata_msorganiser_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves a MiDAR Metadata Organizer template — save_metadata_msorganiser_template","title":"Saves a MiDAR Metadata Organizer template — save_metadata_msorganiser_template","text":"function saves XLSX file metadata template specified location.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_metadata_msorganiser_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves a MiDAR Metadata Organizer template — save_metadata_msorganiser_template","text":"","code":"save_metadata_msorganiser_template(path = \"metadata_msorganiser_template.xlsm\")"},{"path":"https://slinghub.github.io/midar/reference/save_metadata_msorganiser_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves a MiDAR Metadata Organizer template — save_metadata_msorganiser_template","text":"path File path MiDAR Metadata Organizer file saved. left empty (default), file saved current working directory file \"metadata_msorganiser_template.xlsm\"","code":""},{"path":"https://slinghub.github.io/midar/reference/save_metadata_templates.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves a Excel (xlsx) file with metadata templates — save_metadata_templates","title":"Saves a Excel (xlsx) file with metadata templates — save_metadata_templates","text":"function saves XLSX file metadata template specified location.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_metadata_templates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves a Excel (xlsx) file with metadata templates — save_metadata_templates","text":"","code":"save_metadata_templates(path = \"metadata_template.xlsx\")"},{"path":"https://slinghub.github.io/midar/reference/save_metadata_templates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves a Excel (xlsx) file with metadata templates — save_metadata_templates","text":"path File path XLSX file templates saved. left empty (default), file saved current working directory file \"metadata_template.xlsx\"","code":""},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":null,"dir":"Reference","previous_headings":"","what":"Write Data Processing Report (EXCEL) — save_report_xlsx","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"Generates data processing report MidarExperiment object writes Excel file. report includes information data processing steps, quality control metrics, feature concentrations, metadata. Following tables created sheets EXCEL file:","code":""},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"","code":"save_report_xlsx(   data = NULL,   path,   filtered_variable = \"conc\",   normalized_variable = NA,   overwrite = TRUE )"},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"data MidarExperiment object containing original processed data metadata. path character string specifying file name path Excel file. path include .xlsx extension, added automatically. filtered_variable character string specifying variable name filtered data exported. must one \"conc\", \"intensity\", \"norm_intensity\", \"response\", \"area\", \"height\", \"conc_raw\", \"rt\", \"fwhm\". defined variable name included sheet name. Default \"conc\". normalized_variable character string indicating normalized feature values  (reference sample) include report.See also [calibrate_by_reference()]. overwrite logical value indicating whether overwrite file already exists. Default TRUE.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"function return value. writes report specified Excel file.","code":""},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"Info: General  information including date, author, MiDAR version, processing status feature concentration unit. Feature_QC_metrics: Quality control metrics features. QCfilt_x_StudySamples: Feature (QC)-filtered data (variable defiend via filtered_variable) study samples ('SPL'). Filter set via filter_features_qc(). x corresponds filtered_variable argument. QCfilt_x_AllSamples: Feature (QC)-filtered data (variable defiend via filtered_variable) samples. Filter set via filter_features_qc(). x corresponds filtered_variable argument. Conc_FullDataset: Final feature concentrations full, non-filtered dataset. Raw_Intensity_FullDataset: Raw feature intensities full, non-filtered dataset. Norm_Intensity_FullDataset: Normalized feature intensities full, non-filtered dataset. SampleMetadata:  Analysis metadata imported used processing steps FeatureMetadata: Feature metadata imported used processing steps InternalStandards: Internal standards metadata concentrations BatchInfo: Information batches positions first last analysis/sample batch #' certain data sets available, function includes empty tables corresponding dataset. Concentration corresponds final concentration values applying isotope correction, drift batch correction, applicable. corrections, drift batch correction, applied raw normalized intensities, exported values reflect corrections.","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/reference/save_report_xlsx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write Data Processing Report (EXCEL) — save_report_xlsx","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming `midarexp` is a MidarExperiment object and `output_path` is a valid path save_report_xlsx(data = midarexp, path = \"output_path/report.xlsx\") } # }"},{"path":"https://slinghub.github.io/midar/reference/set_analysis_order.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Analysis Order — set_analysis_order","title":"Set Analysis Order — set_analysis_order","text":"Determines sequence analyses using either instrument timestamps, order imported raw data file, order defined Analysis metadata. Note: changing analysis order, post processing steps must rerun.","code":""},{"path":"https://slinghub.github.io/midar/reference/set_analysis_order.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Analysis Order — set_analysis_order","text":"","code":"set_analysis_order(   data = NULL,   order_by = c(\"timestamp\", \"resultfile\", \"metadata\") )"},{"path":"https://slinghub.github.io/midar/reference/set_analysis_order.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Analysis Order — set_analysis_order","text":"data MidarExperiment object order_by Character string specifying ordering method. Must one \"timestamp\" (requires timestamp data imported results), \"resultfile\" (uses order imported data file), \"metadata\" (uses order analysis metadata)","code":""},{"path":"https://slinghub.github.io/midar/reference/set_analysis_order.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Analysis Order — set_analysis_order","text":"updated MidarExperiment object ordered analyses","code":""},{"path":"https://slinghub.github.io/midar/reference/set_analysis_order.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set Analysis Order — set_analysis_order","text":"","code":"file_path <- system.file(\"extdata\", \"MRMkit_demo.tsv\", package = \"midar\") mexp <- MidarExperiment() mexp <- import_data_mrmkit(mexp, path = file_path, import_metadata = TRUE) #> ✔ Imported 499 analyses with 28 features #> ℹ `feature_area` selected as default feature intensity. Modify with `set_intensity_var()`. #> ✔ Analysis metadata associated with 499 analyses. #> ✔ Feature metadata associated with 28 features.  # Order by timestamp (if available) mexp <- set_analysis_order(mexp, \"timestamp\") #> ✔ Analysis order set to \"timestamp\"  # Order by metadata definition mexp <- set_analysis_order(mexp, \"metadata\") #> ✔ Analysis order set to \"metadata\""},{"path":"https://slinghub.github.io/midar/reference/set_intensity_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default variable to be used as feature raw signal value — set_intensity_var","title":"Set default variable to be used as feature raw signal value — set_intensity_var","text":"Sets raw signal variable used calculations starting raw signal values (.e., normalization) Note set variable must part orginally imported data. Processed data variables (e.g., normalized intensities concentrations) can set default feature intensity variable.","code":""},{"path":"https://slinghub.github.io/midar/reference/set_intensity_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default variable to be used as feature raw signal value — set_intensity_var","text":"","code":"set_intensity_var(   data = NULL,   variable_name,   auto_select = FALSE,   warnings = TRUE,   ... )"},{"path":"https://slinghub.github.io/midar/reference/set_intensity_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set default variable to be used as feature raw signal value — set_intensity_var","text":"data MidarExperiment object variable_name Feature variable used default feature intensity downstream processing. auto_select TRUE first available used default: \"intensity\", \"response\", \"area\", \"height\". warnings Suppress warnings ... Feature variables best search one--one auto-detect = TRUE","code":""},{"path":"https://slinghub.github.io/midar/reference/set_intensity_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set default variable to be used as feature raw signal value — set_intensity_var","text":"MidarExperiment object","code":""},{"path":[]},{"path":"https://slinghub.github.io/midar/news/index.html","id":"midar-020","dir":"Changelog","previous_headings":"","what":"midar 0.2.0","title":"midar 0.2.0","text":"Fully revised extended functions, data classes, unit tests, documentation.","code":""},{"path":"https://slinghub.github.io/midar/news/index.html","id":"midar-010","dir":"Changelog","previous_headings":"","what":"midar 0.1.0","title":"midar 0.1.0","text":"Initial version t","code":""}]
