---
title: "Lipidomics Data Processing"
output: 
  rmarkdown::html_vignette:
    fig_width: 6
    fig_height: 2
description: |
  MiDAR: Postprocessing and Quality Control of Small-Molecule Mass Spectrometry Data 
vignette: >
  %\VignetteIndexEntry{Lipidomics Data Processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, results = TRUE, message = TRUE, comment = "#>", out.width = "100%")
set.seed(1041)
options(dplyr.print_max = 10)
```

This tutorial illustrates a postprocessing and quality control workflow
starting from a preprocessing data from an lipidomics analysis. Starting
from peak areas, the iam is to produce a curated dataset with lipid
species concentrations that is ready for subsequent statistical
analysss. This post-processing will include an assessment of the
analytical and data quality of the lipidomics analysis, followed by
normalisation/quantification, feature filtering and reporting of the
dataset.

```{r, results = FALSE, message = FALSE}
library(midar)
```

## 1. Importing analysis results

We begin by importing the MRMkit result file, which contains the areas
of the integrated peaks (features) in all the processed raw data files.
In addition, the MRMkit result file also contains peak retention times
and widths, as well as metadata extracted from the mzML files, such as
acquisition time stamp and m/z values. We import these metadata by
setting `import_metadata = TRUE`.

<details>

<summary>Exercises</summary>

> Type `print(myexp)` in the console to get a summary of the status. You
> can explore the `myexp` object in RStudio by clicking it in the
> Environment panel on the top right.

</details>

```{r load-rawdata}
myexp <- midar::MidarExperiment(title = "sPerfect")

data_path <- "datasets/sPerfect_MRMkit.tsv"
myexp <- import_data_mrmkit(data = myexp, path = data_path, import_metadata = TRUE)
```

## 2. A glimpse on the imported data

Let us examine the imported data by executing the code below or by
entering the command `View(myexp@dataset_orig)` in the console. As can
be observed, the data is in long format, thereby enabling the user to
view multiple parameters for each analysis-feature pair.

<details>

<summary>Exercises</summary>

> Explore the imported table using in the RStudio table viewer with the
> filter functionality.

</details>

```{r view-rawdata}
print(myexp@dataset) # Better use `get_rawdata(mexp, "original")`
```

## 3. Analytical design and timeline

An overview of the analysis design and timelines can provide useful
information for subsequent processing steps. The plot below illustrates
the batch structure, the quality control (QC) samples included with
their respective positions, and additional information regarding the
date, duration, and run time of the analysis.

<details>

<summary>Exercises</summary>

> Show analysis timestamps with `show_timestamp = TRUE`. Have there been
> long interruptions within and between the batches?

</details>

```{r runsequence}
#| fig.alt: >
#|   RunSequence plot
plot_runsequence(
  myexp, 
  qc_types = NA, 
  show_batches = TRUE, 
  batch_zebra_stripe = TRUE, 
  batch_fill_color = "#fffbdb", 
  segment_linewidth = 0.5,
  show_timestamp = FALSE)

```

## 4. Signal trends of Internal Standards

We can look at the internal standards (ISTDs) in all samples across all
six batches to see how the analyses went. The same ISTD amount was
spiked into each sample (except `SBLK`) so we should expect the same
intensities in all samples and sample types.

<details>

<summary>Exercises</summary>

> What do you observe? You can set `output_pdf = TRUE` to save the plots
> as PDF (see subfolder `output`).

</details>

```{r runscatter}
#| message: true
#| fig.alt: >
#|   RunScatter plot
plot_runscatter(
  data = myexp,
  variable = "intensity",
  qc_types = c("BQC", "TQC", "SPL", "PBLK", "SBLK"),
  analysis_range = NA, #get_batch_boundaries(myexp, c(1,6)), 
  include_feature_filter = "ISTD", 
  exclude_feature_filter = "Hex|282",
  cap_outliers = TRUE,
  log_scale = FALSE, 
  show_batches = TRUE,base_font_size = 5,
  output_pdf = FALSE,
  path = "./output/runscatter_istd.pdf",
  cols_page = 4, rows_page = 3
)
```

## 5. Adding detailed metadata

To proceed with further processing, we require additional metadata
describing the samples and features. The `MiDAR Excel template` provides
a solution for the collection, organisation and pre-validation of
analysis metadata. Import metadata from this template using the function
below. If there are errors in the metadata (e.g. duplicate or missing
ID), the import will fail with an error message and summary of the
errors. If the metadata is error-free, a summary of warnings and notes
about the metadata will be shown in a table, if present. Check your
metadata by working through these warnings, or proceed using
`ignore_warnings = TRUE`.

<details>

<summary>Exercises</summary>

> Open the `XLSM` file in the `data` folder to explore the metadata
> structure (click 'Disable Macros').

</details>

```{r import-metadat}

file_path <- "datasets/sPerfect_Metadata.xlsm"
myexp <- import_metadata_msorganiser(myexp, path = file_path, ignore_warnings = TRUE)
myexp <- set_analysis_order(myexp, order_by = "timestamp")
myexp <- set_intensity_var(myexp, variable_name = "area")

```

## 6. Overall trends and possible outlier

To examine overall technical trends and issues affecting the majority of
analytes (features), the RLA (Relative Log Abundance) plot is a useful
tool (De Livera et al., Analytical Chemistry, 2015). In this plot, all
features are normalised (by across or within-batch medians) and plotted
as a boxplot per sample. This plot can help to identify potential
pipetting errors, sample spillage, injection volume changes or
instrument sensitivity changes.

<details>

<summary>Exercises</summary>

> First, run the code below as it is. What observations can be made?
> Then, examine batch 6, by uncommenting the line
> `#plot_range_indices =`. What do you see in this batch? Identify the
> potential outlier sample by setting `x_axis_variable = "analysis_id"`.
> Next, set the y-axis limits manually `y_lim = c(-2,2)` and display all
> analyses/batches again to inspect the data for other trends or
> fluctuations.

</details>

```{r rla-plot}
#| fig.alt: >
#|   RLA plot
midar::plot_rla_boxplot(
  data = myexp,
  rla_type_batch = c("within"),
  variable = "intensity",
  qc_types = c("BQC", "SPL", "RQC", "TQC", "PBLK"), 
  filter_data = FALSE, 
  #plot_range_indices = get_batch_boundaries(myexp, batch_ids = c(6,6)), 
  #y_lim = c(-3,3),
  show_timestamp = FALSE,
  ignore_outliers = FALSE, x_gridlines = FALSE,
  batch_zebra_stripe = FALSE,
  linewidth = 0.1
)
```

## 7. PCA plot of all QC types

A principal component analysis (PCA) plot provides an alternative method
for obtaining an overview of the study and quality control (QC) samples,
as well as for identifying potential issues, such as batch effects,
technical outliers, and differences between the sample types.

<details>

<summary>Exercises</summary>

> Add blanks and sample dilutions to the plot, by including
> `"PBLK", "RQC"` to `qc_types =` below. What do you think the resulting
> PCA plot suggests now?

</details>

```{r pca-before}
#| fig.alt: >
#|   PCA plot
plot_pca(
  data = myexp, 
  variable = "feature_intensity", 
  filter_data = FALSE,
  pca_dim = c(1,2),
  labels_threshold_mad = 3, 
  qc_types = c("SPL", "BQC", "TQC"),
  log_transform = TRUE,  
  point_size = 2, point_alpha = 0.7, font_base_size = 8, ellipse_alpha = 0.3, 
  include_istd = FALSE)
```

## 8. Exclude technical outliers

Based on the above RLA and PCA plots, we flagged a technical outlier and
decided to remove it from all downstream processing via the function
`exclude()`.

<details>

<summary>Exercises</summary>

> What do we now see in the new PCA plot? Explore also different PCA
> dimensions (by modifying `pca_dim`).

</details>

```{r outlier-removal}
#| fig.alt: >
#|   PCA plot
 # Exclude the sample from the processing
myexp <- exclude_analyses(myexp, analyses = c("Longit_batch6_51"), clear_existing  = TRUE)

# Replot the PCA
plot_pca(
  data = myexp,
  variable = "intensity",
  filter_data = FALSE,
  pca_dim = c(1,2),
  labels_threshold_mad = 3,
  qc_types = c("SPL", "BQC", "TQC"),
  log_transform = TRUE,
  point_size = 2, point_alpha = 0.7, font_base_size = 8, ellipse_alpha = 0.3,
  include_istd = FALSE,
  shared_labeltext_hide = NA)
```

## 9. Response curves

A linear response in quantification is a prerequisite for to compared
differences in analyte concentrations between samples. Given the
considerable dynamic range of plasma lipid species abundances and the
fact that the class-specific ISTD is spiked at a single concentration,
verifying the linear response can be a valuable aspect of the analytical
quality assessment. While optimising the injected sample amount is
primarily a matter of quality assurance (QA), differences in instrument
performance can affect the dynamic range. Therefore, we measured
injection volume series at the start and end of this analysis as a QC.

<details>

<summary>Exercises</summary>

> Look at the response curves below. What do we see from these results?
> Change the plotted lipid species by modifying `include_feature_filter`
> (it can use regular expressions). Save a PDF of all lipids by setting
> `output_pdf = TRUE` and commenting out (add a `#` in front of)
> `include_feature_filter`

</details>

```{r responsecurves}
#| fig.alt: >
#|   Response curve plots
# Exclude very low abundant features
myexp <- midar::filter_features_qc(myexp, 
                                   include_qualifier = FALSE,
                                   include_istd = TRUE,
                                   min.intensity.median.spl = 200)

#Plot the curves
plot_responsecurves(
  data = myexp,
  variable = "intensity",
  filter_data = TRUE,
  include_feature_filter = "^PC 3[0-5]", # here we use regular expressions
  output_pdf = FALSE, path = "response-curves.pdf",
  cols_page = 5, rows_page = 4,
)
```

## 10. Isotope interference correction

As demonstrated in the course presentation, there are several instances
where the peaks of interest were co-integrated with the interfering
isotope peaks of other lipid species. These intereferences can be
subtracted from the raw intensities (areas) using the below function,
which utilises information from the metadata. The relative abundances
for the interfering fragments were obtained using LICAR
(<https://github.com/SLINGhub/LICAR>).

<details>

<summary>Exercises</summary>

> Check the sheet "Features (Analytes)" in the metadata file (folder
> `data`). Which species were affected? Which information will you need?
> Why should we correct for M+3 isotope interference?

</details>

```{r isotope-correction}
myexp <- midar::correct_interferences(myexp)
```

## 11. Normalization and quantification based on ISTDs

The first step is to normalize each lipid species with its corresponding
internal standard (ISTD). Subsequently, the concentrations are
calculated based on the volume of the spiked-in ISTD solution, the
concentration of the ISTDs in this solution, and the sample volume.

<details>

<summary>Exercises</summary>

> Visit the metadata template to view the corresponding details. You can
> also try to re-run e.g. above RLA and PCA plots with
> `variable = "norm_intensity"` or `variable = "conc"` to plot the
> normalized data.

</details>

```{r normalization}
myexp <- midar::normalize_by_istd(myexp)
myexp <- midar::quantify_by_istd(myexp)

```

## 12. Examine the effects of class-wide ISTD normalization

The use of class-specific ISTDs is common practice in lipidomics.
However, non-authentic internal standards may elute at different times,
which can result in them being subject to different matrix effects and
thus different responses compared to the analytes. They may also differ
in their fragmentation properties, which can also affect the response.
Consequently, the use of non-authentic ISTDs for normalization can lead
to the introduction of artefacts, which can manifest as increases in
sample variability, rather than the expected reduction. It it therefore
important to assess ISTDs during QA in particular, but also as QC, and
to consider using alternative ISTDs when observing artefacts. One
approach to detecting potential ISTD-related artefacts is to compare the
variability of QC and samples before and after normalization.

<details>

<summary>Exercises</summary>

> What would you expect from such comarisons of CV? Do you notice
> potential issues with any of the ISTDs below? What could be possible
> explanations for such an effect? And what would you do in this
> situation?

</details>

```{r norm-effects}
#| fig.alt: >
#|   Normalization QC plot
myexp <- midar::filter_features_qc(myexp, 
                                   include_qualifier = FALSE,
                                   include_istd = TRUE,
                                   min.intensity.median.spl = 1000)
midar::plot_normalization_qc(
  data = myexp, 
  filter_data = FALSE, 
  facet_by_class = TRUE,
  qc_type = "SPL", 
  before_norm_var = "intensity", 
  after_norm_var = "norm_intensity")
```

## 13. Drift correction

We're going to use a Gaussian kernel smoothing based on the study sample
to correct for any drifts in the concentration data within each batch.
The summary return by the function below isn't meant as actual
diagnostics of the fit, but rather to understand if the fit caused any
major artefacts. There is also an option to scale along the fit by
setting `scale_smooth = TRUE`.

```{r drift-corr}

myexp <- midar::correct_drift_gaussiankernel(
  data = myexp,
  ignore_istd = TRUE,
  variable = "conc",
  ref_qc_types = c("SPL"),
  batch_wise = TRUE,
  replace_previous = TRUE,
  recalc_trend_after = TRUE,
  kernel_size = 10,
  outlier_filter = FALSE,
  outlier_ksd = 5,
  location_smooth = TRUE,
  scale_smooth = FALSE, 
  show_progress = FALSE  # set to FALSE when rendering
)
```

In order to demonstrate the correction, we will plot an example (PC
40:8) before and after the drift and batch correction. As we will be
using the same plot on several occasions, we create a simple function
that wraps the plot with many parameters preset.

```{r trendplot-fun}
#| fig.alt: >
#|   RunScatter plots with trends before and after corrections

# Define a wrapper function

my_trend_plot <- function(variable, feature){
  plot_runscatter(
    data = myexp,
    variable = variable,
    qc_types = c("BQC", "TQC", "SPL"),
    include_feature_filter = feature,
    exclude_feature_filter = "ISTD",
    cap_outliers = TRUE,
    log_scale = FALSE,
    show_trend = TRUE,
    output_pdf = FALSE,
    path = "./output/runscatter_PC408_beforecorr.pdf",
    cols_page = 1, rows_page = 1, 
  )
}
```

<details>

<summary>Exercises</summary>

> Let's use this before defined function to plot the trends of one
> selected example before and after within-batch smoothing. What may
> have caused such a drift in the raw concentrations? Do the QC samples
> follow the trend of the sample? Look also at other lipid species.
>
> Try changing `batch_wise = FALSE` in the code chunk above with
> `correct_drift_gaussiankernel()` to run the run the smoothing across
> all batches. Would this be a valid alternative? NOTE: don't forget to
> change back to `batch_wise = TRUE` after the test.

</details>

```{r plot-trends}
#| fig.alt: >
#|   RunScatter plots with trends before after corrections  
my_trend_plot("conc_before", "PC 40:8")
my_trend_plot("conc", "PC 40:8")
```

## 14. Batch-effect correction

As we observed, the trend lines of the different batches are not
aligned. We will use `correct_batcheffects()` to correct for median
center (location) and scale differences between the batches. The define
that the correction should be based on the study samples medians. An
optional scale correction can be performed by setting
`correct_scale = FALSE`. After the correction we directly plot our
example lipid species again.

<details>

<summary>Exercises</summary>

> Change the sample type to `qc_type = "BQC"` to use the BQC to center
> the batches. What do you observe?

</details>

```{r batch-effect-corr}
#| fig.alt: >
#|   RunScatter plots with trends after corrections
myexp <- midar::correct_batch_centering(
  myexp, 
  variable = "conc",
  ref_qc_types = "SPL",
  replace_previous = TRUE,
  correct_location = TRUE, 
  correct_scale = TRUE, 
  log_transform_internal = TRUE)

my_trend_plot("conc", "PC 40:8")
```

## 15. Saving *runscatter* plots of all features as PDF

For additional inspection and documentation, we can save plots for all
or a selected subset of species. It is often preferable to exclude
blanks, as they can exhibit random concentrations when signals of
features and internal standards are in close proximity or below the
limit of detection. The corresponding PDF can be accessed within the
`output` subfolder. Use `filt_` arguments to include or exclude specific
analytes. The filter can use regular expressions (regex). (Hint: try
using ChatGPT to generate more complex regex-based filters).

<details>

<summary>Exercises</summary>

Explore the effect of setting `cap_outliers` to `TRUE`or `FALSE`. Run
`?runscatter` in the console or press `F2` on the function name to see
all available options for `plot_runscatter()`.

</details>

```{r saving-runscatter}
#| eval: false
#| fig.alt: >
#|   Runscatter plot
plot_runscatter(
  data = myexp,
  variable = "conc",
  qc_types = c("BQC", "TQC", "SPL"),
  include_feature_filter =  NA,
  exclude_feature_filter = "ISTD",
  cap_outliers = TRUE,
  log_scale = FALSE,
  show_trend = TRUE,
  output_pdf = TRUE,
  path = "./output/runscatter_after-drift-batch-correction.pdf",
  cols_page = 2, 
  rows_page = 2,
  show_progress = TRUE
)
```

## 16. QC-based feature filtering

Finally, we apply a set of filters to exclude features that don't meet
specific QC criteria. The available criteria can be seen by pressing
`TAB` after the first open bracket of `filter_features_qc()` function,
or by to viewing the help page. by running `?filter_features_qc` in the
console. The filter function can be applied multiple times, either
overwriting or amending (`clear_existing = FALSE`) previously set
filters.

<details>

<summary>Exercises</summary>

> Explore the effects of the different filtering criteria and filtering
> thresholds. The plot below in section 17 can be run in order to
> examine the effects visually.

</details>

```{r qc-filter}

myexp <- filter_features_qc(
  data = myexp, 
  clear_existing = TRUE,
  use_batch_medians = TRUE,
  include_qualifier = FALSE,
  include_istd = FALSE,
  response.curves.selection = c(1,2),
  response.curves.summary = "mean",
  min.rsquare.response = 0.8,
  min.slope.response = 0.75,
  max.yintercept.response = 0.5,
  min.signalblank.median.spl.pblk = 10,
  min.intensity.median.spl = 100,
  max.cv.conc.bqc = 25,
  features.to.keep = c("CE 20:4", "CE 22:5", "CE 22:6", "CE 16:0", "CE 18:0")
)

```

## 17. Summary of the QC filtering

The plot below provides an overview of the data quality and the feature
filtering. The segments in green indicate the number of species that
passed all previously defined quality control (QC) filtering criteria.
The rest are the number of species that failed the different filtering
criteria. It should be noted that the criteria are hierarchically
organised; a feature is only classified as failing a criterion (e.g.,
`CV`) when it has passed the hierarchically lower filters (e.g., `S/B`
and `LOD`).

<details>

<summary>Exercises</summary>

> Are there any differences between lipid classes in terms of their
> analytical performance? What are the identified QC issues and what are
> possible explanations for these? What could be the implications if you
> want to run the next analysis?

</details>

```{r qc-summary-1}
#| fig.alt: >
#|   Feature QC filter plot by class
midar::plot_qc_summary_byclass(myexp)
```

The following plot provides a further summary of the feature filtering
process, indicating the total number of features that have been
successfully filtered. As previously stated, the classification is based
on the hierarchical application of filters. The Venn diagram on the
right illustrates the number of features that have been excluded by a
particular filtering criterion.

<details>

<summary>Exercises</summary>

> Take a look at the Venn diagram. If a feature shows a bad or
> non-linear response (e.g. r2 \< 0.8), what could be the reasons for
> this?

</details>

```{r qc-summary-2}
#| fig.alt: >
#|   Feature QC filter plot overall
midar::plot_qc_summary_overall(myexp)
```

## 18. Saving a report with data, metadata and processing details

A detailed summary of the data post-processing can be generated in the
form of an formatted `Excel` workbook comprising multiple sheets, each
containing raw and processed datasets, associated metadata, feature
quality control metrics, and information about the applied processing
steps.

<details>

<summary>Exercises</summary>

> Explore the report that was saved in the `output` folder.

</details>

```{r save-report}
midar::save_report_xlsx(myexp, path = "./output/myexp-midar_report.xlsx")
```

You can also save specific data subsets as a clean flat, wide CSV file.
This is how we shared the data for the statistical analysis that will be
presented in the next part of this workshop!

<details>

<summary>Exercises</summary>

> Specify which data to export using function arguments and check the
> generated CSV files.

</details>

```{r save-csv}
midar::save_dataset_csv(
  data = myexp, 
  path = "./output/sperfect_filt_uM.csv",
  variable = "conc", 
  qc_types = "SPL", 
  include_qualifier = FALSE,
  filter_data = TRUE)
```

## 19. Sharing the `MidarExperiment` dataset

The `myexp` object can be saved as an `RDS` file and shared. `RDS` files
are serialized R variables/objects that can be opened in R by anyone,
even in the absence of `midar` package. The imported `MidarExperiment`
object can also be utilized for re-processing, plotting, or inspection
using the `midar` package.

<details>

<summary>Exercises</summary>

> Save the dataset to the disk and re-open it under a different name.
> Check the status comparing it with the dataset generated in the
> workflow above (`mexp`)

</details>

```{r save-rds}
saveRDS(myexp, file = "./output/myexp-midar.rds", compress = TRUE)
my_saved_exp <- readRDS(file = "./output/myexp-midar.rds")
print(myexp)
```
